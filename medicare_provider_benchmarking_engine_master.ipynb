{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().resolve()\n",
    "\n",
    "DATA = (ROOT / \"data\").resolve()\n",
    "\n",
    "PROV_SVC_DATA = (DATA / \"prov_svc\").resolve()\n",
    "\n",
    "PROV_DATA = (DATA / \"prov\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Reading the Data in Using Pandas (Later Skipped / Commented Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Provider Service Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2021 = pd.read_csv(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D21_Prov_Svc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2021[\"Year\"] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2021.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2022 = pd.read_csv(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D22_Prov_Svc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2022[\"Year\"] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2023 = pd.read_csv(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D23_Prov_Svc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2023[\"Year\"] = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all = pd.concat([prov_svc_2021, prov_svc_2022, prov_svc_2023], axis= 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Provider Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2021 = pd.read_csv(PROV_DATA / \"MUP_PHY_R25_P07_V20_D21_Prov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2021[\"Year\"] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2021.columns if \"Cancer\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2021.columns if \"Bene_CC_PH\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2021.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2022 = pd.read_csv(PROV_DATA / \"MUP_PHY_R25_P07_V20_D22_Prov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2022[\"Year\"] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2022.columns if \"Cancer\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2022.columns if \"Bene_CC_PH\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2023 = pd.read_csv(PROV_DATA / \"MUP_PHY_R25_P05_V20_D23_Prov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2023[\"Year\"] = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2023.columns if \"Cancer\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_2023.columns if \"Bene_CC_PH\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_all = pd.concat([prov_2021, prov_2022, prov_2023], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in prov_all.columns if \"Cancer\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all[\"Rndrng_Prvdr_Ent_Cd\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onco_prvdr_type = [s for s in prov_svc_all[\"Rndrng_Prvdr_Type\"].value_counts().index.to_list() if \"onco\" in s.lower()]\n",
    "# onco_prvdr_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_df = prov_svc_all[\"Rndrng_Prvdr_Type\"].value_counts().reset_index().rename(columns={\"count\": \"Count\"})\n",
    "\n",
    "# onco_counts = counts_df[counts_df[\"Rndrng_Prvdr_Type\"].isin(onco_prvdr_type)]\n",
    "\n",
    "# onco_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all_cdI_typeOnco = prov_svc_all[(prov_svc_all[\"Rndrng_Prvdr_Ent_Cd\"]==\"I\") & prov_svc_all[\"Rndrng_Prvdr_Type\"].isin(onco_prvdr_type)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all_cdI_typeOnco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_svc_all_cdI_typeOnco[\"Rndrng_Prvdr_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "Above steps were too memory-intensive, so I switched to DuckDB altogether for loading and inspecting the each individual dataset. \n",
    "\n",
    "Above, I only read in Provider Service and Provider Datasets. \n",
    "\n",
    "Using DuckDB, I will create a database that creates views for Provider Service, Provider, RCBS Taxonomy, and NPPES datasets. I'll sanity checks and quality control to ensure the the intended data is loaded correctly, the views are filtered for target analysis, appropriate views are joined and the final metadata is saved as a table, a Pandas dataframe and a parquet file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# SWITCH TO DUCKDB FOR EFFICIENCY (USE THE FOR THE REST OF THE NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=DATA / \"medicare.duckdb\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Provider-service union (3 years)\n",
    "# ----------------------------\n",
    "\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_all AS\n",
    "SELECT *, 2021 AS Year\n",
    "FROM read_csv_auto('{(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D21_Prov_Svc.csv\").as_posix()}')\n",
    "UNION ALL\n",
    "SELECT *, 2022 AS Year \n",
    "FROM read_csv_auto('{(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D22_Prov_Svc.csv\").as_posix()}')\n",
    "UNION ALL\n",
    "SELECT *, 2023 As Year\n",
    "FROM read_csv_auto('{(PROV_SVC_DATA / \"MUP_PHY_R25_P05_V20_D23_Prov_Svc.csv\").as_posix()}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Visit [Medicare Physician & Other Practitioners - by Provider and Service Data Dictionary](https://data.cms.gov/resources/medicare-physician-other-practitioners-by-provider-and-service-data-dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oncology provider types: contains \"onco\"\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_onco AS\n",
    "SELECT *\n",
    "FROM prov_svc_all\n",
    "WHERE Rndrng_Prvdr_Ent_Cd = 'I'\n",
    "  AND Rndrng_Prvdr_Type IN (\n",
    "    'Hematology-Oncology',\n",
    "    'Medical Oncology',\n",
    "    'Radiation Oncology',\n",
    "    'Gynecological Oncology',\n",
    "    'Surgical Oncology'\n",
    "  );\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_onco_core AS\n",
    "SELECT *,\n",
    "  CASE\n",
    "    WHEN Rndrng_Prvdr_Type IN ('Hematology-Oncology', 'Medical Oncology', 'Radiation Oncology')\n",
    "      THEN 1 ELSE 0\n",
    "  END AS is_core_scope\n",
    "FROM prov_svc_onco;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT Rndrng_Prvdr_Type, is_core_scope, COUNT(*) AS n\n",
    "FROM prov_svc_onco_core\n",
    "GROUP BY 1,2\n",
    "ORDER BY n DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    f\"\"\"\n",
    "CREATE OR REPLACE VIEW prov_all AS\n",
    "SELECT *, 2021 AS Year \n",
    "FROM read_csv_auto('{(PROV_DATA / \"MUP_PHY_R25_P07_V20_D21_Prov.csv\").as_posix()}')\n",
    "UNION ALL\n",
    "SELECT *, 2022 AS Year\n",
    "FROM read_csv_auto('{(PROV_DATA / \"MUP_PHY_R25_P07_V20_D22_Prov.csv\").as_posix()}')\n",
    "UNION ALL \n",
    "SELECT *, 2023 AS Year\n",
    "FROM read_csv_auto('{(PROV_DATA / \"MUP_PHY_R25_P05_V20_D23_Prov.csv\").as_posix()}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Visit: [Medicare Physician & Other Practitioners - by Provider Data Dictionary](https://data.cms.gov/resources/medicare-physician-other-practitioners-by-provider-data-dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_onco_core_prov_all AS\n",
    "SELECT\n",
    "  ps.*,\n",
    "  p.* EXCLUDE (Rndrng_NPI, Year)\n",
    "FROM prov_svc_onco_core AS ps\n",
    "LEFT JOIN prov_all AS p\n",
    "  ON ps.Rndrng_NPI = p.Rndrng_NPI\n",
    " AND ps.Year = p.Year;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Let's confirm we didn’t accidentally create duplicate provider rows in `prov_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT Year, COUNT(*) AS n_rows, COUNT(DISTINCT Rndrng_NPI) AS n_npi\n",
    "FROM prov_all\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Let's check match rate after the left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT COUNT(*) AS n_rows,\n",
    "       AVG(CASE WHEN Tot_Benes IS NULL THEN 1 ELSE 0 END) AS pct_missing_provider_summary\n",
    "FROM prov_svc_onco_core_prov_all\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBCS_DATA = (DATA / \"rbcs\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    f\"\"\"\n",
    "CREATE OR REPLACE VIEW rbcs AS\n",
    "SELECT *\n",
    "FROM read_csv_auto('{(RBCS_DATA / \"RBCS_Taxonomy_RY2025.csv\").as_posix()}');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "***CRITICAL NOTE: At the end of \"EDA 6. Specialty comparisons (our 5 oncology types)\" I discovered that the original `rbcs` dataset has duplicates that led to fatal downstream duplication.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "The code below fixes the `rbcs` dataset by removing duplicates and generating a clean dataset called `rbcs_dedup`. \n",
    "\n",
    "We will rebuild the `prov_svc_onco_core_prov_all_rbcs` dataset with the clean `rbcs_dedup` and run the entire notebook from start to finish to ensure the duplication issue is completely resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW rbcs_dedup AS\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT\n",
    "    r.*,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY HCPCS_Cd\n",
    "      ORDER BY\n",
    "        RBCS_Latest_Assignment DESC,\n",
    "        RBCS_Analysis_Start_Dt DESC NULLS LAST,\n",
    "        RBCS_Analysis_End_Dt DESC NULLS LAST,\n",
    "        CASE WHEN RBCS_FamNumb = '000' THEN 1 ELSE 0 END\n",
    "    ) AS rn\n",
    "  FROM rbcs r\n",
    ")\n",
    "WHERE rn = 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "After deduping, confirm RBCS is now unique on HCPCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rbcs_dedup_rows,\n",
    "  COUNT(DISTINCT HCPCS_Cd) AS distinct_hcpcs\n",
    "FROM rbcs_dedup;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Visit: [Restructured Berenson-Eggers Type of Service (BETOS) Classification System (RBCS) Data Dictionary](https://data.cms.gov/sites/default/files/2022-05/RBCS%20Mapping%20Data%20Dictionary.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "***CRITICAL NOTE: DO NOT UNCOMMENT THE CODE BELOW. THIS IS KEPT FOR \"REFERENCE ONLY\". UNCOMMENTING IT MIGHT CAUSE DUPLICATION ISSUES.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE IS DEPRICATED! DO NOT UNCOMMENT THIS!\n",
    "\n",
    "# con.execute(\n",
    "#     \"\"\"\n",
    "# CREATE OR REPLACE VIEW prov_svc_onco_core_prov_all_rbcs AS\n",
    "# SELECT p.*, r.* EXCLUDE(HCPCS_Cd)\n",
    "# FROM prov_svc_onco_core_prov_all AS p\n",
    "# LEFT JOIN rbcs AS r\n",
    "#   ON p.HCPCS_Cd = r.HCPCS_Cd;\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Let's reconstruct the `prov_svc_onco_core_prov_all_rbcs` using the clean `rbcs_dedup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_onco_core_prov_all_rbcs AS\n",
    "SELECT p.*, r.* EXCLUDE(HCPCS_Cd)\n",
    "FROM prov_svc_onco_core_prov_all AS p\n",
    "LEFT JOIN rbcs_dedup AS r\n",
    "  ON p.HCPCS_Cd = r.HCPCS_Cd;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "**Must-run check after the rebuild:** The specific offender should stop doubling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  'pre'  AS stage, COUNT(*) n_rows, SUM(Tot_Srvcs) sum_srvcs\n",
    "FROM prov_svc_onco_core_prov_all\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'post' AS stage, COUNT(*) n_rows, SUM(Tot_Srvcs) sum_srvcs\n",
    "FROM prov_svc_onco_core_prov_all_rbcs\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Let's check whether the join is matching codes as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT COUNT(*) AS n_rows,\n",
    "AVG(CASE WHEN RBCS_Id IS NULL THEN 1 ELSE 0 END) AS pct_missing_rbcs\n",
    "FROM prov_svc_onco_core_prov_all_rbcs;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPPES_DATA = (DATA / \"nppes\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    f\"\"\"\n",
    "CREATE OR REPLACE VIEW nppes_raw AS \n",
    "SELECT * \n",
    "FROM read_csv_auto('{(NPPES_DATA / \"npidata_pfile_20050523-20260111.csv\").as_posix()}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM nppes_raw\n",
    "LIMIT 4\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"DESCRIBE SELECT * FROM nppes_raw\").df().head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Let's create a slim NPPES view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW nppes AS \n",
    "SELECT NPI,\n",
    "       \"Entity Type Code\" AS entity_type_code,\n",
    "       \"Provider Enumeration Date\" AS enumeration_date\n",
    "FROM nppes_raw\n",
    "WHERE Entity_Type_Code = 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM nppes\n",
    "LIMIT 4\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT * \n",
    "FROM nppes\n",
    "\"\"\"\n",
    ").df().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "#### Let's do a quick sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  MIN(enumeration_date) AS min_date,\n",
    "  MAX(enumeration_date) AS max_date\n",
    "FROM nppes;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "#### Let's left join the `prov_svc_onco_core_prov_all_rbcs` table with the `nppes` table on `Rndrng_NPI` on the left side and `NPI` on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_onco_core_prov_all_rbcs_nppes AS\n",
    "SELECT\n",
    "    t.*,\n",
    "    n.enumeration_date,\n",
    "    CASE\n",
    "        WHEN n.enumeration_date IS NULL\n",
    "        THEN NULL\n",
    "        ELSE (t.Year - EXTRACT(year FROM n.enumeration_date))::INTEGER\n",
    "    END AS years_since_enumeration\n",
    "FROM prov_svc_onco_core_prov_all_rbcs AS t\n",
    "LEFT JOIN nppes AS n\n",
    "    ON CAST(t.Rndrng_NPI AS BIGINT) = n.NPI;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(CASE WHEN enumeration_date IS NULL THEN 1 ELSE 0 END) AS pct_missing_enumeration_date,\n",
    "  MIN(years_since_enumeration) AS min_years,\n",
    "  MAX(years_since_enumeration) AS max_years\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE TABLE prov_svc_onco_core_prov_all_rbcs_nppes_tbl AS\n",
    "SELECT * FROM prov_svc_onco_core_prov_all_rbcs_nppes;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PARQUET = (DATA / \"prov_svc_onco_core_prov_all_rbcs_nppes.parquet\").as_posix()\n",
    "\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "COPY prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "TO '{OUT_PARQUET}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "#### Reading the master dataset in using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(DATA / \"prov_svc_onco_core_prov_all_rbcs_nppes.parquet\")\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = con.sql(\n",
    "    \"\"\"\n",
    "DESCRIBE \n",
    "    SELECT *\n",
    "    FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl;\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "desc.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "#### Table 1: provider_year_features (small, stable, best for EDA + clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE provider_year_features AS\n",
    "SELECT\n",
    "  Rndrng_NPI,\n",
    "  Year,\n",
    "\n",
    "  -- provider identity (should be constant within NPI-Year)\n",
    "  MAX(Rndrng_Prvdr_Type) AS provider_type,\n",
    "  MAX(is_core_scope) AS is_core_scope,\n",
    "  MAX(Rndrng_Prvdr_State_Abrvtn) AS state,\n",
    "  MAX(Rndrng_Prvdr_Zip5) AS zip5,\n",
    "  MAX(Rndrng_Prvdr_RUCA) AS ruca,\n",
    "  MAX(Rndrng_Prvdr_RUCA_Desc) AS ruca_desc,\n",
    "\n",
    "  -- provider-year totals (from provider summary)\n",
    "  MAX(Tot_HCPCS_Cds) AS tot_hcpcs_cds,\n",
    "  MAX(Tot_Benes_1) AS tot_benes,\n",
    "  MAX(Tot_Srvcs_1) AS tot_srvcs,\n",
    "  MAX(Tot_Sbmtd_Chrg) AS tot_sbmtd_chrg,\n",
    "  MAX(Tot_Mdcr_Alowd_Amt) AS tot_mdcr_allowed_amt,\n",
    "  MAX(Tot_Mdcr_Pymt_Amt) AS tot_mdcr_payment_amt,\n",
    "  MAX(Tot_Mdcr_Stdzd_Amt) AS tot_mdcr_stdzd_amt,\n",
    "\n",
    "  -- derived unit costs at provider-year level\n",
    "  MAX(Tot_Mdcr_Stdzd_Amt) / NULLIF(MAX(Tot_Srvcs_1), 0) AS stdzd_amt_per_service,\n",
    "  MAX(Tot_Mdcr_Pymt_Amt) / NULLIF(MAX(Tot_Srvcs_1), 0) AS payment_amt_per_service,\n",
    "  MAX(Tot_Mdcr_Alowd_Amt) / NULLIF(MAX(Tot_Srvcs_1), 0) AS allowed_amt_per_service,\n",
    "\n",
    "  -- drug vs medical totals (optional but useful)\n",
    "  MAX(Drug_Tot_Srvcs) AS drug_tot_srvcs,\n",
    "  MAX(Drug_Mdcr_Stdzd_Amt) AS drug_mdcr_stdzd_amt,\n",
    "  MAX(Med_Tot_Srvcs) AS med_tot_srvcs,\n",
    "  MAX(Med_Mdcr_Stdzd_Amt) AS med_mdcr_stdzd_amt,\n",
    "\n",
    "  -- case-mix proxies\n",
    "  MAX(Bene_Avg_Risk_Scre) AS bene_avg_risk_score,\n",
    "\n",
    "  -- demographics counts (optional)\n",
    "  MAX(Bene_Avg_Age) AS bene_avg_age,\n",
    "  MAX(Bene_Feml_Cnt) AS bene_female_cnt,\n",
    "  MAX(Bene_Male_Cnt) AS bene_male_cnt,\n",
    "  MAX(Bene_Dual_Cnt) AS bene_dual_cnt,\n",
    "  MAX(Bene_Ndual_Cnt) AS bene_nondual_cnt,\n",
    "\n",
    "  -- chronic condition percentages (keep as features, even if they are BIGINT)\n",
    "  MAX(Bene_CC_PH_Cancer6_V2_Pct) AS pct_cancer6,\n",
    "  MAX(Bene_CC_PH_Diabetes_V2_Pct) AS pct_diabetes,\n",
    "  MAX(Bene_CC_PH_CKD_V2_Pct) AS pct_ckd,\n",
    "  MAX(Bene_CC_PH_COPD_V2_Pct) AS pct_copd,\n",
    "  MAX(Bene_CC_PH_Hypertension_V2_Pct) AS pct_htn,\n",
    "\n",
    "  -- experience proxy (from NPPES join)\n",
    "  MAX(years_since_enumeration) AS years_since_enumeration\n",
    "\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "GROUP BY 1, 2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = (DATA / \"provider_year_features.parquet\").as_posix()\n",
    "con.execute(f\"COPY provider_year_features TO '{OUT}' (FORMAT PARQUET);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "#### Table 2: provider_service_features (modeling table for regression benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE provider_service_features AS\n",
    "SELECT\n",
    "  Rndrng_NPI,\n",
    "  Year,\n",
    "  MAX(Rndrng_Prvdr_Type) AS provider_type,\n",
    "  MAX(is_core_scope) AS is_core_scope,\n",
    "\n",
    "  -- service grouping\n",
    "  RBCS_FamNumb,\n",
    "  MAX(RBCS_Family_Desc) AS rbcs_family_desc,\n",
    "  MAX(RBCS_Cat) AS rbcs_cat,\n",
    "  MAX(RBCS_Cat_Subcat) AS rbcs_cat_subcat,\n",
    "\n",
    "  -- context\n",
    "  Place_Of_Srvc,\n",
    "  MAX(Rndrng_Prvdr_State_Abrvtn) AS state,\n",
    "  MAX(Rndrng_Prvdr_Zip5) AS zip5,\n",
    "  MAX(Rndrng_Prvdr_RUCA) AS ruca,\n",
    "\n",
    "  -- volume and exposure\n",
    "  SUM(Tot_Srvcs) AS services,\n",
    "  SUM(Tot_Benes) AS benes,\n",
    "  SUM(Tot_Bene_Day_Srvcs) AS bene_day_services,\n",
    "\n",
    "  -- weighted average “price” targets (per service)\n",
    "  SUM(Avg_Mdcr_Stdzd_Amt * Tot_Srvcs) / NULLIF(SUM(Tot_Srvcs), 0) AS stdzd_amt_per_service,\n",
    "  SUM(Avg_Mdcr_Alowd_Amt * Tot_Srvcs) / NULLIF(SUM(Tot_Srvcs), 0) AS allowed_amt_per_service,\n",
    "  SUM(Avg_Mdcr_Pymt_Amt * Tot_Srvcs) / NULLIF(SUM(Tot_Srvcs), 0) AS payment_amt_per_service,\n",
    "  SUM(Avg_Sbmtd_Chrg * Tot_Srvcs) / NULLIF(SUM(Tot_Srvcs), 0) AS submitted_charge_per_service,\n",
    "\n",
    "  -- provider-level features (repeated across service rows, so take MAX)\n",
    "  MAX(Bene_Avg_Risk_Scre) AS bene_avg_risk_score,\n",
    "  MAX(years_since_enumeration) AS years_since_enumeration,\n",
    "\n",
    "  -- a few case-mix features (add more later if we want)\n",
    "  MAX(Bene_CC_PH_Cancer6_V2_Pct) AS pct_cancer6,\n",
    "  MAX(Bene_CC_PH_Diabetes_V2_Pct) AS pct_diabetes,\n",
    "  MAX(Bene_CC_PH_CKD_V2_Pct) AS pct_ckd,\n",
    "  MAX(Bene_CC_PH_COPD_V2_Pct) AS pct_copd,\n",
    "  MAX(Bene_CC_PH_Hypertension_V2_Pct) AS pct_htn\n",
    "\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "WHERE RBCS_FamNumb IS NOT NULL  -- keep only rows mapped to RBCS\n",
    "GROUP BY 1,2,5,9;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = (DATA / \"provider_service_features.parquet\").as_posix()\n",
    "con.execute(f\"COPY provider_service_features TO '{OUT}' (FORMAT PARQUET);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "## QC or sanity checks on the newly created dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### QC A. Row counts and uniqueness at the intended grain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "1) provider_year_features should be unique on (Rndrng_NPI, Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  COUNT(DISTINCT (Rndrng_NPI, Year)) AS n_unique_keys,\n",
    "  COUNT(*) - COUNT(DISTINCT (Rndrng_NPI, Year)) AS n_duplicate_keys\n",
    "FROM provider_year_features;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "2) provider_service_features should be unique on (Rndrng_NPI, Year, RBCS_FamNumb, Place_Of_Srvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  COUNT(DISTINCT (Rndrng_NPI, Year, RBCS_FamNumb, Place_Of_Srvc)) AS n_unique_keys,\n",
    "  COUNT(*) - COUNT(DISTINCT (Rndrng_NPI, Year, RBCS_FamNumb, Place_Of_Srvc)) AS n_duplicate_keys\n",
    "FROM provider_service_features;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "### QC B. Missingness and “must-have” fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "3) Provider-year: check missing core fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  AVG(CASE WHEN tot_benes IS NULL THEN 1 ELSE 0 END) AS pct_missing_tot_benes,\n",
    "  AVG(CASE WHEN tot_srvcs IS NULL THEN 1 ELSE 0 END) AS pct_missing_tot_srvcs,\n",
    "  AVG(CASE WHEN tot_mdcr_stdzd_amt IS NULL THEN 1 ELSE 0 END) AS pct_missing_tot_stdzd_amt,\n",
    "  AVG(CASE WHEN bene_avg_risk_score IS NULL THEN 1 ELSE 0 END) AS pct_missing_risk,\n",
    "  AVG(CASE WHEN years_since_enumeration IS NULL THEN 1 ELSE 0 END) AS pct_missing_years_since_enum\n",
    "FROM provider_year_features;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "4) Provider-service: check mapping and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  AVG(CASE WHEN RBCS_FamNumb IS NULL THEN 1 ELSE 0 END) AS pct_missing_family,\n",
    "  AVG(CASE WHEN services IS NULL OR services = 0 THEN 1 ELSE 0 END) AS pct_zero_services,\n",
    "  AVG(CASE WHEN stdzd_amt_per_service IS NULL THEN 1 ELSE 0 END) AS pct_missing_stdzd,\n",
    "  AVG(CASE WHEN allowed_amt_per_service IS NULL THEN 1 ELSE 0 END) AS pct_missing_allowed,\n",
    "  AVG(CASE WHEN payment_amt_per_service IS NULL THEN 1 ELSE 0 END) AS pct_missing_payment\n",
    "FROM provider_service_features;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "### QC C. Validate the weighted-average math behaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "5) Spot-check that the “per service” amounts are in sane ranges\n",
    "\n",
    "Run percentiles to detect garbage (like negative, huge, or all zeros):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  quantile_cont(stdzd_amt_per_service, 0.01) AS p01_stdzd,\n",
    "  quantile_cont(stdzd_amt_per_service, 0.50) AS p50_stdzd,\n",
    "  quantile_cont(stdzd_amt_per_service, 0.99) AS p99_stdzd,\n",
    "  MIN(stdzd_amt_per_service) AS min_stdzd,\n",
    "  MAX(stdzd_amt_per_service) AS max_stdzd\n",
    "FROM provider_service_features\n",
    "WHERE services >= 11;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  quantile_cont(allowed_amt_per_service, 0.01) AS p01_stdzd,\n",
    "  quantile_cont(allowed_amt_per_service, 0.50) AS p50_stdzd,\n",
    "  quantile_cont(allowed_amt_per_service, 0.99) AS p99_stdzd,\n",
    "  MIN(allowed_amt_per_service) AS min_stdzd,\n",
    "  MAX(allowed_amt_per_service) AS max_stdzd\n",
    "FROM provider_service_features\n",
    "WHERE services >= 11;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  quantile_cont(payment_amt_per_service, 0.01) AS p01_stdzd,\n",
    "  quantile_cont(payment_amt_per_service, 0.50) AS p50_stdzd,\n",
    "  quantile_cont(payment_amt_per_service, 0.99) AS p99_stdzd,\n",
    "  MIN(payment_amt_per_service) AS min_stdzd,\n",
    "  MAX(payment_amt_per_service) AS max_stdzd\n",
    "FROM provider_service_features\n",
    "WHERE services >= 11;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "Check how often the target is exactly zero (because the p01 is 0.0 across all three targets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  AVG(CASE WHEN stdzd_amt_per_service = 0 THEN 1 ELSE 0 END) AS pct_zero_stdzd,\n",
    "  AVG(CASE WHEN allowed_amt_per_service = 0 THEN 1 ELSE 0 END) AS pct_zero_allowed,\n",
    "  AVG(CASE WHEN payment_amt_per_service = 0 THEN 1 ELSE 0 END) AS pct_zero_payment\n",
    "FROM provider_service_features;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "### QC D. Reconciliation checks (to ensure we didn’t accidentally double-count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "6) Provider-year totals vs sum of provider-service “reconstructed totals”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "WITH svc_recon AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    SUM(stdzd_amt_per_service * services) AS recon_stdzd_amt,\n",
    "    SUM(services) AS recon_services\n",
    "  FROM provider_service_features\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    y.Rndrng_NPI,\n",
    "    y.Year,\n",
    "    y.tot_mdcr_stdzd_amt,\n",
    "    y.tot_srvcs,\n",
    "    s.recon_stdzd_amt,\n",
    "    s.recon_services,\n",
    "    (s.recon_stdzd_amt / NULLIF(y.tot_mdcr_stdzd_amt, 0)) AS ratio_stdzd_amt,\n",
    "    (s.recon_services / NULLIF(y.tot_srvcs, 0)) AS ratio_services\n",
    "  FROM provider_year_features y\n",
    "  LEFT JOIN svc_recon s\n",
    "    ON y.Rndrng_NPI = s.Rndrng_NPI\n",
    "   AND y.Year = s.Year\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n,\n",
    "  AVG(CASE WHEN ratio_stdzd_amt BETWEEN 0.5 AND 1.5 THEN 1 ELSE 0 END) AS pct_ratio_stdzd_in_0_5_to_1_5,\n",
    "  quantile_cont(ratio_stdzd_amt, 0.50) AS median_ratio_stdzd,\n",
    "  quantile_cont(ratio_services, 0.50) AS median_ratio_services\n",
    "FROM joined\n",
    "WHERE tot_mdcr_stdzd_amt > 0 AND tot_srvcs > 0;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "### QC E. Quick sanity distributions by year and specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "  Year,\n",
    "  provider_type,\n",
    "  COUNT(*) AS n_providers,\n",
    "  AVG(stdzd_amt_per_service) AS avg_stdzd_per_service,\n",
    "  AVG(bene_avg_risk_score) AS avg_risk\n",
    "FROM provider_year_features\n",
    "GROUP BY 1,2\n",
    "ORDER BY 1, n_providers DESC;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "## Creating the EDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = (DATA / \"eda_dataset.parquet\").as_posix()\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE eda_dataset AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    -- keys\n",
    "    ps.Rndrng_NPI,\n",
    "    ps.Year,\n",
    "    ps.RBCS_FamNumb,\n",
    "    ps.Place_Of_Srvc,\n",
    "\n",
    "    -- labels for readability (not for modeling)\n",
    "    ps.rbcs_family_desc,\n",
    "    ps.rbcs_cat,\n",
    "    ps.rbcs_cat_subcat,\n",
    "\n",
    "    -- provider context\n",
    "    ps.provider_type,\n",
    "    ps.is_core_scope,\n",
    "    ps.state,\n",
    "    ps.zip5,\n",
    "    ps.ruca,\n",
    "\n",
    "    -- derived RUCA bucket (simplifies plots and modeling later)\n",
    "    CASE\n",
    "      WHEN ps.ruca IS NULL THEN 'Unknown'\n",
    "      WHEN ps.ruca <= 3 THEN 'Urban'\n",
    "      WHEN ps.ruca <= 6 THEN 'Suburban'\n",
    "      ELSE 'Rural'\n",
    "    END AS ruca_bucket,\n",
    "\n",
    "    -- exposure\n",
    "    ps.services,\n",
    "    ps.benes,\n",
    "    ps.bene_day_services,\n",
    "\n",
    "    -- observed “price” outcomes (per service)\n",
    "    ps.stdzd_amt_per_service,\n",
    "    ps.allowed_amt_per_service,\n",
    "    ps.payment_amt_per_service,\n",
    "    ps.submitted_charge_per_service,\n",
    "\n",
    "    -- observed totals (useful for spend concentration plots)\n",
    "    ps.stdzd_amt_per_service * ps.services AS stdzd_spend,\n",
    "    ps.allowed_amt_per_service * ps.services AS allowed_spend,\n",
    "    ps.payment_amt_per_service * ps.services AS payment_spend,\n",
    "    ps.submitted_charge_per_service * ps.services AS submitted_spend,\n",
    "\n",
    "    -- log transforms for EDA and later modeling\n",
    "    ln(1 + ps.stdzd_amt_per_service) AS log_stdzd_amt_per_service,\n",
    "    ln(1 + ps.services) AS log_services,\n",
    "    ln(1 + ps.benes) AS log_benes,\n",
    "\n",
    "    -- case-mix and experience\n",
    "    ps.bene_avg_risk_score,\n",
    "    ps.years_since_enumeration,\n",
    "\n",
    "    -- condition percentage features (keep both raw and scaled)\n",
    "    ps.pct_cancer6,\n",
    "    ps.pct_diabetes,\n",
    "    ps.pct_ckd,\n",
    "    ps.pct_copd,\n",
    "    ps.pct_htn,\n",
    "\n",
    "    (CAST(ps.pct_cancer6 AS DOUBLE) / 100.0) AS p_cancer6,\n",
    "    (CAST(ps.pct_diabetes AS DOUBLE) / 100.0) AS p_diabetes,\n",
    "    (CAST(ps.pct_ckd AS DOUBLE) / 100.0) AS p_ckd,\n",
    "    (CAST(ps.pct_copd AS DOUBLE) / 100.0) AS p_copd,\n",
    "    (CAST(ps.pct_htn AS DOUBLE) / 100.0) AS p_htn,\n",
    "\n",
    "    -- optional provider-year totals for context checks\n",
    "    py.tot_benes,\n",
    "    py.tot_srvcs,\n",
    "    py.tot_mdcr_stdzd_amt,\n",
    "    py.stdzd_amt_per_service AS provider_year_stdzd_amt_per_service\n",
    "\n",
    "  FROM provider_service_features AS ps\n",
    "  LEFT JOIN provider_year_features AS py\n",
    "    ON ps.Rndrng_NPI = py.Rndrng_NPI\n",
    "   AND ps.Year = py.Year\n",
    "\n",
    "  WHERE ps.services >= 11\n",
    "    AND ps.stdzd_amt_per_service IS NOT NULL\n",
    "    AND ps.stdzd_amt_per_service >= 0\n",
    "),\n",
    "q AS (\n",
    "  -- exact percentile (can swap to APPROX_QUANTILE for speed)\n",
    "  SELECT quantile_cont(stdzd_amt_per_service, 0.99) AS q99\n",
    "  FROM base\n",
    ")\n",
    "SELECT\n",
    "  b.*,\n",
    "\n",
    "  -- mirror pandas: is_top_1pct_stdzd_amt_per_service = stdzd_amt_per_service >= q99\n",
    "  (b.stdzd_amt_per_service >= q.q99) AS is_top_1pct_stdzd_amt_per_service,\n",
    "\n",
    "  -- mirror pd.cut(... right=False): left-inclusive, right-exclusive bins\n",
    "  CASE\n",
    "    WHEN b.services < 11 THEN '<11'\n",
    "    WHEN b.services >= 11 AND b.services < 25 THEN '11-25'\n",
    "    WHEN b.services >= 25 AND b.services < 50 THEN '25-50'\n",
    "    WHEN b.services >= 50 AND b.services < 100 THEN '50-100'\n",
    "    WHEN b.services >= 100 AND b.services < 500 THEN '100-500'\n",
    "    ELSE '500+'\n",
    "  END AS svc_bucket\n",
    "\n",
    "FROM base b\n",
    "CROSS JOIN q;\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"COPY eda_dataset TO '{OUT}' (FORMAT PARQUET);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "A sanity check that the top 1% flag is about right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  AVG(CASE WHEN is_top_1pct_stdzd_amt_per_service THEN 1 ELSE 0 END) AS pct_flagged\n",
    "FROM eda_dataset;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "And verify bucket boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT svc_bucket, MIN(services) AS min_s, MAX(services) AS max_s, COUNT(*) AS n\n",
    "FROM eda_dataset\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "## EDA 0. Setup and data load\n",
    "\n",
    "**Code**\n",
    "\n",
    "- Load parquet\n",
    "- Print shape, dtypes\n",
    "- Show the grain: confirm unique key counts\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- What is the unit of analysis?\n",
    "- How big is the dataset after feasibility filters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = pd.read_parquet(DATA/\"eda_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "`tot_benes`: How many distinct beneficiaries did this provider see in this year across all services and places of service\n",
    "\n",
    "`benes`: How many distinct beneficiaries received at least one service in this specific family and POS from this provider in this year?\n",
    "\n",
    "So, we cannot sum `benes` and expect to get `tot_benes` for a specific provider-year pair. Let's demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"Rndrng_NPI\"].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"Year\"].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.query(\"Rndrng_NPI == 1629379565 and Year == 2022\")[[\"benes\",\"tot_benes\",\"Year\", \"Rndrng_NPI\",\"Place_Of_Srvc\",\"rbcs_family_desc\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "\n",
    "- `tot_benes` = 354 means:\n",
    "    - Provider 1629379565 had 354 unique Medicare beneficiaries in 2022 across all services and places of service that feed into your provider-year table.\n",
    "\n",
    "- Row-level `benes` means:\n",
    "    - Within each provider-year + family + place of service slice, how many unique beneficiaries had at least one service in that slice.\n",
    "\n",
    "So in our sample rows:\n",
    "- Office E&M Established, POS=O: 51 unique beneficiaries had at least one such service.\n",
    "- IMRT, POS=O: 245 unique beneficiaries had at least one IMRT service.\n",
    "- Office E&M New, POS=O: 66 unique beneficiaries had at least one new-patient E&M service.\n",
    "- Conventional Radiation Treatment, POS=O: 327 unique beneficiaries had at least one conventional radiation service.\n",
    "- Telephone Services, POS=O: 23 unique beneficiaries had at least one telephone service.\n",
    "\n",
    "And crucially:\n",
    "Those beneficiary sets can overlap heavily (likely they do here).\n",
    "That is why you can see big `benes` values across multiple families while `tot_benes` stays 354.\n",
    "\n",
    "Same idea applies to `services` vs `tot_srvcs`. \n",
    "Let's quickly check:\n",
    "\n",
    "Interpretation:\n",
    "- share ≈ 1 means your row table and provider-year totals align (same universe, no duplication).\n",
    "- share < 1 usually means your row table is a subset (filters).\n",
    "- share > 1 is a red flag for duplication or a universe mismatch where row table includes more than provider-year table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(services) AS sum_services_rows,\n",
    "  MAX(tot_srvcs) AS tot_srvcs_py,\n",
    "  SUM(services) * 1.0 / NULLIF(MAX(tot_srvcs), 0) AS share\n",
    "FROM eda_dataset\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141",
   "metadata": {},
   "source": [
    "**What these numbers say:**\n",
    "\n",
    "- `tot_srvcs_py` = `11817` means: provider `1629379565` delivered `11,817` total services in `2022` in the provider-year summary table’s universe.\n",
    "- `sum_services_rows` = `11410` means: when you sum services across all rows you kept in `eda_dataset` for that provider-year, you capture `11,410` services.\n",
    "\n",
    "So you are missing:\n",
    "- 11817 - 11410 = 407 services\n",
    "- Share captured = 11410 / 11817 = 0.9656 (about 96.6%)\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "This is a good sign.\n",
    "\n",
    "- Share < 1 means our row-level table is not “more” than the provider-year total. So it is not behaving like a duplication problem.\n",
    "- Share close to 1 means our row-level table covers most of the provider-year services, but not all. That is consistent with our filters and/or scope restrictions.\n",
    "\n",
    "What could explain the missing 3.4% (407 services)?\n",
    "Most likely one of these, and our pipeline already suggests them:\n",
    "\n",
    "1. We filtered to core oncology specialties (is_core_scope)\n",
    "\n",
    "- If `tot_srvcs` was computed for the provider-year regardless of specialty restrictions, our EDA table would drop some services.\n",
    "\n",
    "2. Service-family mapping coverage\n",
    "\n",
    "- Some HCPCS lines might not land in our included RBCS families or might fall into categories we excluded upstream.\n",
    "- Even “No RBCS Family” does not guarantee we captured every HCPCS, depending on how our family tables were built.\n",
    "\n",
    "3. Place-of-service scope differences\n",
    "\n",
    "- If our EDA rows only include certain POS codes (even implicitly, based on what exists in the service table we used), we might miss some POS contributions that still count in provider-year totals.\n",
    "\n",
    "4. Other feasibility filters\n",
    "\n",
    "- We filtered out null or negative `stdzd_amt_per_service` (and we require `services >= 11` at the row grain). Those filters can remove some rows that still contribute to the provider-year totals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "**One quick follow-up diagnostic:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  Place_Of_Srvc,\n",
    "  SUM(services) AS sum_services,\n",
    "  MAX(tot_srvcs) AS tot_srvcs_py,\n",
    "  SUM(services) * 1.0 / NULLIF(MAX(tot_srvcs), 0) AS share\n",
    "FROM eda_dataset\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022\n",
    "GROUP BY 1\n",
    "ORDER BY sum_services DESC;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  rbcs_family_desc,\n",
    "  SUM(services) AS sum_services\n",
    "FROM eda_dataset\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022\n",
    "GROUP BY 1\n",
    "ORDER BY sum_services DESC\n",
    "LIMIT 30;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {},
   "source": [
    "We did the “within eda_dataset” breakdown correctly. The reason you still cannot see the missing 407 there is simple:\n",
    "- Our POS table is computed from `eda_dataset`, and `eda_dataset` already only contains rows that passed your EDA filters (`ps.services >= 11`, `stdzd_amt_per_service IS NOT NULL`, `stdzd_amt_per_service >= 0`, plus whatever is upstream in provider_service_features).\n",
    "- So the 407 `services` are not in `eda_dataset` at all. That is why they do not show up under any POS or any family in our POS and family tables.\n",
    "\n",
    "Let's run this on `provider_service_features` (the table we SELECT FROM to build `eda_dataset`):\n",
    "\n",
    "- If `services_that_would_enter_eda_dataset` = `11410` and `services_in_provider_service_features` = 11817, then the 407 are being dropped by the EDA filters.\n",
    "- If `services_in_provider_service_features` is already 11410 (or close), then the 407 never made it into `provider_service_features` in the first place. That points to an upstream scope restriction (specialty filtering, family mapping, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "**Step 1. Confirm the loss happens at the EDA filtering step (most likely)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT *\n",
    "  FROM provider_service_features\n",
    "  WHERE Rndrng_NPI = 1629379565 AND Year = 2022\n",
    ")\n",
    "SELECT\n",
    "  SUM(services) AS services_in_provider_service_features,\n",
    "\n",
    "  SUM(CASE\n",
    "        WHEN services >= 11\n",
    "         AND stdzd_amt_per_service IS NOT NULL\n",
    "         AND stdzd_amt_per_service >= 0\n",
    "        THEN services ELSE 0 END) AS services_that_would_enter_eda_dataset,\n",
    "\n",
    "  SUM(services) - SUM(CASE\n",
    "        WHEN services >= 11\n",
    "         AND stdzd_amt_per_service IS NOT NULL\n",
    "         AND stdzd_amt_per_service >= 0\n",
    "        THEN services ELSE 0 END) AS services_dropped_by_eda_filters\n",
    "FROM base;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "**Step 2. Attribute the dropped services to specific reasons**\n",
    "\n",
    "If `dropped_services_lt_11` is about 407, we have our answer: they are low-volume slices that we intentionally excluded for reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT *\n",
    "  FROM provider_service_features\n",
    "  WHERE Rndrng_NPI = 1629379565 AND Year = 2022\n",
    ")\n",
    "SELECT\n",
    "  SUM(CASE WHEN services < 11 THEN services ELSE 0 END) AS dropped_services_lt_11,\n",
    "\n",
    "  SUM(CASE WHEN services >= 11 AND stdzd_amt_per_service IS NULL THEN services ELSE 0 END) AS dropped_services_stdzd_null,\n",
    "\n",
    "  SUM(CASE WHEN services >= 11 AND stdzd_amt_per_service < 0 THEN services ELSE 0 END) AS dropped_services_stdzd_neg,\n",
    "\n",
    "  SUM(services) AS total_services_in_base\n",
    "FROM base;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150",
   "metadata": {},
   "source": [
    "**Step 3. Show the exact dropped rows (so it’s not a mystery)**\n",
    "\n",
    "This is the “where did they go” table.\n",
    "\n",
    "This will show us the specific families and POS where those services live, and which rule excluded them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  Place_Of_Srvc,\n",
    "  rbcs_family_desc,\n",
    "  RBCS_FamNumb,\n",
    "  services,\n",
    "  benes,\n",
    "  stdzd_amt_per_service,\n",
    "  allowed_amt_per_service,\n",
    "  payment_amt_per_service,\n",
    "  submitted_charge_per_service\n",
    "FROM provider_service_features\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022\n",
    "  AND (\n",
    "       services < 11\n",
    "    OR stdzd_amt_per_service IS NULL\n",
    "    OR stdzd_amt_per_service < 0\n",
    "  )\n",
    "ORDER BY services DESC\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152",
   "metadata": {},
   "source": [
    "**Step 4. If the loss is upstream, compare against the raw service table**\n",
    "\n",
    "Since Step 1 showed `provider_service_features` already below 11817, then we want to compare raw totals:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(Tot_Srvcs) AS raw_sum_tot_srvcs\n",
    "FROM prov_svc_all_prov_all\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(services) AS services_in_provider_service_features\n",
    "FROM provider_service_features\n",
    "WHERE Rndrng_NPI = 1629379565 AND Year = 2022;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "WITH\n",
    "psf AS (\n",
    "  SELECT SUM(services) AS svc\n",
    "  FROM provider_service_features\n",
    "  WHERE Rndrng_NPI=1629379565 AND Year=2022\n",
    "),\n",
    "eda AS (\n",
    "  SELECT SUM(services) AS svc\n",
    "  FROM eda_dataset\n",
    "  WHERE Rndrng_NPI=1629379565 AND Year=2022\n",
    "),\n",
    "raw AS (\n",
    "  SELECT SUM(Tot_Srvcs) AS svc\n",
    "  FROM prov_svc_all_prov_all\n",
    "  WHERE Rndrng_NPI=1629379565 AND Year=2022\n",
    "),\n",
    "py AS (\n",
    "  SELECT MAX(tot_srvcs) AS svc\n",
    "  FROM provider_year_features\n",
    "  WHERE Rndrng_NPI=1629379565 AND Year=2022\n",
    ")\n",
    "SELECT\n",
    "  psf.svc AS services_provider_service_features,\n",
    "  eda.svc AS services_eda_dataset,\n",
    "  raw.svc AS services_raw_table_sum,\n",
    "  py.svc  AS tot_srvcs_provider_year_features\n",
    "FROM psf\n",
    "CROSS JOIN eda\n",
    "CROSS JOIN raw\n",
    "CROSS JOIN py;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156",
   "metadata": {},
   "source": [
    "Perfect. This is exactly the outcome we were trying to isolate.\n",
    "\n",
    "What this proves (very clearly)\n",
    "\n",
    "For this provider-year (NPI 1629379565, 2022):\n",
    "- Raw service-line table sum = 11410\n",
    "- provider_service_features sum = 11410\n",
    "- eda_dataset sum = 11410\n",
    "\n",
    "So our service-line universe is internally consistent end-to-end.\n",
    "\n",
    "But:\n",
    "- `provider_year_features.tot_srvcs` = 11817\n",
    "\n",
    "So the “missing 407 services” are not missing from our service-line tables at all. They are only “missing” relative to the provider-year total table, which is using a broader definition of total services than what ended up in `prov_svc_all_prov_all` (and therefore in `provider_service_features` and `eda_dataset`).\n",
    "\n",
    "Numerically:\n",
    "- 11817 − 11410 = 407 services\n",
    "- That is about 3.44% of the provider-year total (407 / 11817).\n",
    "\n",
    "Why this happens (most likely)\n",
    "\n",
    "`provider_year_features.tot_srvcs` is probably calculated from a different upstream table or rule set, for example:\n",
    "- includes non-oncology specialties, non-core-scope, or non-included HCPCS/RBCS mappings\n",
    "- includes rows you filtered out earlier in the pipeline (not at EDA time, but earlier during “oncology-core” construction)\n",
    "- includes POS buckets or claim types not present in our final service-line extract\n",
    "- includes services outside our RBCS mapping universe (even though you’re keeping “No RBCS Family” inside the service-line table).\n",
    "\n",
    "We want to identify the universe used to compute `provider_year_features.tot_srvcs`. The fastest diagnostic is:\n",
    "\n",
    "A) Find the exact table used to build `provider_year_features`\n",
    "Where did `provider_year_features` come from in our notebook? Search for its CREATE TABLE statement and check which source table it aggregates.\n",
    "\n",
    "B) Quantify the gap by computing provider-year totals from the same base as eda_dataset\n",
    "If you want totals that reconcile by construction, compute a `“tot_srvcs_from_psf”` (or from the same service-line base) and carry that alongside the existing `tot_srvcs`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "Let's check the unique row count per the our eda grain: Provider, Year, RBCS family, Place of service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[[\"Rndrng_NPI\",\"Year\",\"RBCS_FamNumb\",\"Place_Of_Srvc\"]].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "Checking the number of uniqe values each variables has "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.nunique().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "Let's prove what one row represents in our eda dataset by checking that the columns we claim define a row are unique.\n",
    "\n",
    "In the EDA dataset, the grain is supposed to be:\n",
    "\n",
    "1 row = (Rndrng_NPI, Year, RBCS_FamNumb, Place_Of_Srvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"Rndrng_NPI\",\"Year\",\"RBCS_FamNumb\",\"Place_Of_Srvc\"]\n",
    "\n",
    "n_rows = eda_df.shape[0]\n",
    "n_unique = eda_df[key_cols].drop_duplicates().shape[0]\n",
    "n_dupe = n_rows - n_unique\n",
    "\n",
    "print(\"n_rows:\", n_rows)\n",
    "print(\"n_unique_keys:\", n_unique)\n",
    "print(\"n_duplicate_rows:\", n_dupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163",
   "metadata": {},
   "source": [
    "**KEY NOTE: In EDA 8, we found that rows in the top 1% of `stdzd_amt_per_service` have a median service volume of 41. The median `stdzd_amt_per_service` among the top 1% is ~736.7, compared with ~70.3 for the bottom 99%.**\n",
    "\n",
    "After this discovery, I decided to define tail flags and make them reusable. \n",
    "\n",
    "So let's create indicators once and use them everywhere:\n",
    "- `is_top_1pct_stdzd_amt_per_service`\n",
    "- and a service-volume (i.e., `services`) bucket: `svc_bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "q99 = eda_df[\"stdzd_amt_per_service\"].quantile(0.99)\n",
    "\n",
    "eda_df = eda_df.assign(\n",
    "    is_top_1pct_stdzd_amt_per_service = eda_df[\"stdzd_amt_per_service\"] >= q99,\n",
    "    svc_bucket = pd.cut(\n",
    "        eda_df[\"services\"],\n",
    "        bins=[0, 11, 25, 50, 100, 500, np.inf],\n",
    "        labels=[\"<11\", \"11-25\", \"25-50\", \"50-100\", \"100-500\", \"500+\"],\n",
    "        right=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"is_top_1pct_stdzd_amt_per_service\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "## EDA 1. Data quality and completeness\n",
    "\n",
    "**Plots / tables**\n",
    "\n",
    "1. Missingness table (percent missing per column)\n",
    "2. Category sanity tables:\n",
    "    - counts of `provider_type`\n",
    "    - counts of `Place_Of_Srvc`\n",
    "    - counts of `ruca_bucket`\n",
    "    - top 20 `rbcs_family_desc` by rows\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- Are there missing values that could bias modeling?\n",
    "- Do we have unexpected categories or weird values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_cnt = eda_df.isna().sum().rename(\"n_missing\")\n",
    "miss_pct = (eda_df.isna().mean()*100).rename(\"pct_missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss=(\n",
    "    pd.concat([miss_cnt,miss_pct],axis=1)\n",
    "    .reset_index(names=\"column\")\n",
    "    .query(\"n_missing>0\")\n",
    "    .sort_values(\"n_missing\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, max(4,0.5*len(miss))))\n",
    "\n",
    "g = sns.barplot(data=miss, x=\"n_missing\", y=\"column\", orient=\"h\", color=\"#000080\")\n",
    "\n",
    "max_missing = miss[\"n_missing\"].max()\n",
    "\n",
    "g.set(\n",
    "    title=\"Missing values by column\",\n",
    "    xlabel=\"Number of missing values\",\n",
    "    ylabel=\"\"\n",
    ")\n",
    "\n",
    "# 3) Annotate % missing\n",
    "for i, (cnt, pct) in enumerate(zip(miss[\"n_missing\"], miss[\"pct_missing\"])):\n",
    "    # Offset text slightly to the right of the bar\n",
    "    g.text(cnt + (max_missing * 0.002), i, f\"{pct:.1f}%\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"is_top_1pct_stdzd_amt_per_service\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_top_1pct_eda_df = eda_df.loc[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]==True, :]\n",
    "\n",
    "miss_cnt_is_top_1pct = is_top_1pct_eda_df.isna().sum().rename(\"n_missing\")\n",
    "miss_pct_is_top_1pct = (is_top_1pct_eda_df.isna().mean()*100).rename(\"pct_missing\")\n",
    "\n",
    "miss_top_1pct=(\n",
    "    pd.concat([miss_cnt_is_top_1pct,miss_pct_is_top_1pct],axis=1)\n",
    "    .reset_index(names=\"column\")\n",
    "    .query(\"n_missing>0\")\n",
    "    .sort_values(\"n_missing\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, max(4,0.5*len(miss_top_1pct))))\n",
    "\n",
    "g = sns.barplot(data=miss_top_1pct, x=\"n_missing\", y=\"column\", orient=\"h\", color=\"#000080\")\n",
    "\n",
    "max_missing = miss_top_1pct[\"n_missing\"].max()\n",
    "\n",
    "g.set(\n",
    "    title=\"Missing values by column (top 1%)\",\n",
    "    xlabel=\"Number of missing values\",\n",
    "    ylabel=\"\"\n",
    ")\n",
    "\n",
    "# 3) Annotate % missing\n",
    "for i, (cnt, pct) in enumerate(zip(miss_top_1pct[\"n_missing\"], miss_top_1pct[\"pct_missing\"])):\n",
    "    # Offset text slightly to the right of the bar\n",
    "    g.text(cnt + (max_missing * 0.002), i, f\"{pct:.1f}%\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bottom_99pct_eda_df = eda_df.loc[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]==False, :]\n",
    "\n",
    "miss_cnt_is_bottom_99pct = is_bottom_99pct_eda_df.isna().sum().rename(\"n_missing\")\n",
    "miss_pct_is_bottom_99pct = (is_bottom_99pct_eda_df.isna().mean()*100).rename(\"pct_missing\")\n",
    "\n",
    "miss_bottom_99pct=(\n",
    "    pd.concat([miss_cnt_is_bottom_99pct,miss_pct_is_bottom_99pct],axis=1)\n",
    "    .reset_index(names=\"column\")\n",
    "    .query(\"n_missing>0\")\n",
    "    .sort_values(\"n_missing\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, max(4,0.5*len(miss_bottom_99pct))))\n",
    "\n",
    "g = sns.barplot(data=miss_bottom_99pct, x=\"n_missing\", y=\"column\", orient=\"h\", color=\"#000080\")\n",
    "\n",
    "max_missing = miss_bottom_99pct[\"n_missing\"].max()\n",
    "\n",
    "g.set(\n",
    "    title=\"Missing values by column (bottom 99%)\",\n",
    "    xlabel=\"Number of missing values\",\n",
    "    ylabel=\"\"\n",
    ")\n",
    "\n",
    "# 3) Annotate % missing\n",
    "for i, (cnt, pct) in enumerate(zip(miss_bottom_99pct[\"n_missing\"], miss_bottom_99pct[\"pct_missing\"])):\n",
    "    # Offset text slightly to the right of the bar\n",
    "    g.text(cnt + (max_missing * 0.002), i, f\"{pct:.1f}%\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[[\"provider_type\",\"Place_Of_Srvc\",\"ruca_bucket\",\"rbcs_family_desc\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"provider_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"Place_Of_Srvc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"ruca_bucket\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"rbcs_family_desc\"].unique()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178",
   "metadata": {},
   "source": [
    "Important realization: `“No RBCS Family”` showing up in `rbcs_family_desc` is not automatically wrong, but it is worth verifying what it corresponds to. It might be a real label in the RBCS file, or it might indicate some mapping fallback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "Quick check: If it’s truly mapped, RBCS_FamNumb should still be present and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  rbcs_family_desc,\n",
    "  COUNT(*) AS n,\n",
    "  MIN(RBCS_FamNumb) AS min_fam,\n",
    "  MAX(RBCS_FamNumb) AS max_fam\n",
    "FROM provider_service_features\n",
    "WHERE rbcs_family_desc = 'No RBCS Family'\n",
    "GROUP BY 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181",
   "metadata": {},
   "source": [
    "`\"No RBCS Family\"` looks like a real, intentional value in our RBCS mapping, not a join failure.\n",
    "\n",
    "Because:\n",
    "\n",
    "- We have **RBCS_FamNumb = ‘000’** for every one of those rows (min and max both `000`), and the description is consistently `\"No RBCS Family\"`.\n",
    "- If this were a join miss, we would typically see `RBCS_FamNumb` as `NULL` (or missing) after the join, not a stable sentinel like `000`.\n",
    "- We also previously saw `pct_missing_rbcs = 0.0`, which strongly suggests the taxonomy file contains entries for these HCPCS codes and is assigning them to a “none/other/unclassified” bucket.\n",
    "\n",
    "So it is probably a legitimate “catch-all” category: “this HCPCS code is in the taxonomy file but not assigned to a meaningful family.” But we have to confirm this finding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182",
   "metadata": {},
   "source": [
    "Quick checks: How big is it relative to the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_all,\n",
    "  SUM(CASE WHEN RBCS_FamNumb='000' THEN 1 ELSE 0 END) AS n_000,\n",
    "  1.0 * SUM(CASE WHEN RBCS_FamNumb='000' THEN 1 ELSE 0 END) / COUNT(*) AS pct_000\n",
    "FROM provider_service_features;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184",
   "metadata": {},
   "source": [
    "Quick checks: Does it have very different cost/exposure and spend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  CASE WHEN RBCS_FamNumb='000' THEN '000_NoFamily' ELSE 'OtherFamilies' END AS grp,\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(services) AS avg_services,\n",
    "  quantile_cont(log_stdzd_amt_per_service, 0.50) AS med_log_stdzd_amt_per_service,\n",
    "  quantile_cont(log_stdzd_amt_per_service, 0.95) AS p95_log_stdzd_amt_per_service\n",
    "FROM eda_dataset\n",
    "GROUP BY 1;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186",
   "metadata": {},
   "source": [
    "Let's calculate the % of total standardized spend coming from RBCS_FamNumb = ‘000':\n",
    "\n",
    "1. of the meta dataset `prov_svc_onco_core_prov_all_rbcs_nppes_tbl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS total_stdzd_spend_all,\n",
    "  SUM(CASE WHEN RBCS_FamNumb='000' THEN Tot_Srvcs * Avg_Mdcr_Stdzd_Amt ELSE 0 END) AS total_stdzd_spend_000,\n",
    "  1.0 * SUM(CASE WHEN RBCS_FamNumb='000' THEN Tot_Srvcs * Avg_Mdcr_Stdzd_Amt ELSE 0 END)\n",
    "      / NULLIF(SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt), 0) AS pct_stdzd_spend_000\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188",
   "metadata": {},
   "source": [
    "2. of the EDA dataset `eda_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(stdzd_spend) AS total_stdzd_spend_all,\n",
    "  SUM(CASE WHEN RBCS_FamNumb='000' THEN stdzd_spend ELSE 0 END) AS total_stdzd_spend_000,\n",
    "  1.0 * SUM(CASE WHEN RBCS_FamNumb='000' THEN stdzd_spend ELSE 0 END)\n",
    "      / NULLIF(SUM(stdzd_spend), 0) AS pct_stdzd_spend_000\n",
    "FROM eda_dataset;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190",
   "metadata": {},
   "source": [
    "This is exactly the kind of check that makes the story credible. Based on our results, I would treat RBCS_FamNumb = #### '000' as a real, meaningful segment and handle it explicitly.\n",
    "\n",
    "**What these numbers are saying**\n",
    "\n",
    "**Size**\n",
    "\n",
    "- 000 is **7.9%** of rows (25,993 out of 329,571). That’s too big to ignore as a “quirk”, but small enough that it #### could distort things if it behaves differently.\n",
    "\n",
    "**Exposure (services)**\n",
    "\n",
    "- 000_NoFamily has **much higher average services** per row: ~12,234 vs ~2,836.\n",
    "- That is a big structural difference. It suggests 000 rows are not “typical families”, they might be umbrella #### billing codes, very high volume codes, or catch-all codes that aggregate a lot of activity.\n",
    "\n",
    "**Cost level (log standardized cost per service)**\n",
    "\n",
    "- Median log cost is **lower** for 000 (3.38) vs others (4.29).\n",
    "    - On the original scale, that’s roughly exp(3.38) ≈ 29 vs exp(4.29) ≈ 73 (this is approximate because we used log1p, but the conclusion holds).\n",
    "- The **95th percentile is similar-ish** (6.14 vs 5.78). So the tail is not wildly different, but the center is.\n",
    "\n",
    "So yes, I would call it meaningfully different. Even if the p95 is close, the median and the services volume difference are telling us this group is a different “kind” of row.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191",
   "metadata": {},
   "source": [
    "**Quick extra check before locking the decision**\n",
    "\n",
    "The one thing I’d verify is whether 000 is concentrated in a specific place of service or provider type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  Place_Of_Srvc,\n",
    "  provider_type,\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(services) AS avg_services,\n",
    "  quantile_cont(log_stdzd_amt_per_service, 0.50) AS med_log_stdzd\n",
    "FROM eda_df\n",
    "WHERE RBCS_FamNumb = '000'\n",
    "GROUP BY 1,2\n",
    "ORDER BY n_rows DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193",
   "metadata": {},
   "source": [
    "This table makes it very clear that **RBCS_FamNumb = '000'** is not just a harmless “misc” label. It behaves like multiple different sub-populations depending on place of service and provider type.\n",
    "\n",
    "**What these result implies**\n",
    "\n",
    "**1) The biggest driver is Place_Of_Srvc = O for HemOnc and MedOnc**\n",
    "\n",
    "Look at these two rows:\n",
    "\n",
    "- **O, Hematology-Oncology:** 10,741 rows, **avg_services ~ 22,765**, **median log cost ~ 1.16**\n",
    "- **O, Medical Oncology:** 3,508 rows, **avg_services ~ 18,157**, **median log cost ~ 1.20**\n",
    "\n",
    "That median log cost is extremely low relative to the rest of our dataset. These look like very high-volume, very low standardized cost-per-service rows, which is exactly the kind of pattern we get from “special” codes, aggregation-type codes, or something that is not comparable to a standard service family.\n",
    "\n",
    "**2) The F rows look much more “normal”**\n",
    "\n",
    "When Place_Of_Srvc = F, the median log costs are around ~4 to 6, and avg_services are tens, not tens of thousands. Example:\n",
    "\n",
    "- **F, HemOnc:** avg_services ~ 79, med log ~ 4.10\n",
    "- **F, RadOnc:** avg_services ~ 76, med log ~ 4.09\n",
    "- **F, GynOnc:** avg_services ~ 39, med log ~ 6.24 (higher)\n",
    "\n",
    "So 000 is not one thing. It’s at least two very different things depending on place of service.\n",
    "\n",
    "**What to do with 000 now**\n",
    "\n",
    "Two possible strategies:\n",
    "\n",
    "**Option A (recommended): Keep 000, but model it explicitly with interactions**\n",
    "\n",
    "Do all of this:\n",
    "\n",
    "1. Add a flag\n",
    "- is_no_rbcs_family = 1 if RBCS_FamNumb == '000' else 0\n",
    "2. Add an interaction-type feature (either explicit or via model)\n",
    "- For Ridge: we can explicitly create a feature like is_no_rbcs_family * is_place_O (or just rely on one-hot plus linear interaction if we build it).\n",
    "- For XGBoost: we don’t need to manually create interactions. It will split on RBCS_FamNumb == '000' and Place_Of_Srvc naturally.\n",
    "3. In EDA and reporting, always show metrics stratified by:\n",
    "- is_no_rbcs_family and Place_Of_Srvc\n",
    "\n",
    "This gives us the clean story: “000 codes behave differently, especially in outpatient settings. We keep them but let the model treat them differently.”\n",
    "\n",
    "**Option B (cleanest benchmarking narrative): Separate-track modeling**\n",
    "\n",
    "- **Main benchmark model:** train on RBCS_FamNumb != '000' only.\n",
    "- **Secondary model:** train on RBCS_FamNumb == '000' only (and maybe even split by Place_Of_Srvc inside it).\n",
    "\n",
    "This avoids mixing apples and oranges. It also prevents those huge-volume low-cost O rows from influencing the main model’s learned relationships.\n",
    "\n",
    "**Which option fits our goal best?**\n",
    "\n",
    "Since we want the headline metric to be **O/E standardized cost per service** and we want the benchmarking story to be clean, here’s the best alignment:\n",
    "\n",
    "- If the report/dashboard is meant to be “benchmark real oncology service families,” then **Option B** is the cleanest.\n",
    "- If the product goal is “give every provider-year-service row an expected cost,” then **Option A** is better.\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194",
   "metadata": {},
   "source": [
    "**One more tiny QC that will make the decision obvious**\n",
    "\n",
    "Let's check whether those crazy high avg_services rows also dominate total volume. If (O, HemOnc) and (O, MedOnc) are most of the services too, then separating 000 is usually the safest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  Place_Of_Srvc,\n",
    "  provider_type,\n",
    "  SUM(services) AS total_services,\n",
    "  COUNT(*) AS n_rows,\n",
    "  1.0 * SUM(services) / (SELECT SUM(services) FROM eda_df WHERE RBCS_FamNumb='000') AS pct_of_000_services\n",
    "FROM eda_df\n",
    "WHERE RBCS_FamNumb='000'\n",
    "GROUP BY 1,2\n",
    "ORDER BY total_services DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196",
   "metadata": {},
   "source": [
    "This confirms it very strongly.\n",
    "\n",
    "**What this table says in plain English**\n",
    "\n",
    "For the “No RBCS Family” bucket (RBCS_FamNumb = '000'):\n",
    "\n",
    "- **Outpatient HemOnc (O, Hematology-Oncology)** accounts for **~76.9%** of *all* services in the 000 bucket.\n",
    "- **Outpatient MedOnc (O, Medical Oncology)** accounts for **~20.0%**.\n",
    "- Together, those two rows account for **~97%** of all 000 services.\n",
    "\n",
    "Everything else is tiny by comparison.\n",
    "\n",
    "So **RBCS_FamNumb='000'** is not just 7.9% of rows. It is a bucket whose *service volume* is overwhelmingly dominated by a very specific pattern (Outpatient + HemOnc/MedOnc). That means if we keep 000 in the main model without special handling, it can easily distort training, calibration, and the O/E story.\n",
    "\n",
    "**Best recommendation**\n",
    "\n",
    "Use **Option B (separate-track modeling)** as the default.\n",
    "\n",
    "**Why Option B is the cleanest for our stated goal**\n",
    "\n",
    "narrative usually assumes “we’re comparing like-with-like service families.” The 000 bucket is not behaving like a normal service family. It’s acting like a special aggregation or fallback code bucket with huge volume and very different cost behavior.\n",
    "\n",
    "So:\n",
    "\n",
    "1. **Main benchmark model (the one we show by default)**\n",
    "- Train and score on **RBCS_FamNumb != '000'** only.\n",
    "- This becomes our primary O/E story.\n",
    "2. **Secondary model (optional add-on)**\n",
    "- Train a separate model for **RBCS_FamNumb = '000'*, and honestly this could be restricted to just:\n",
    "- (Place_Of_Srvc='O' AND provider_type IN ('Hematology-Oncology','Medical Oncology'))\n",
    "- because that’s basically the whole 000 volume anyway.\n",
    "- Or we can still include all provider types, but the key is keeping it separate from the main benchmark.\n",
    "\n",
    "**What to do in the dataset**\n",
    "\n",
    "Keep 000 rows in our data, but tag them and split the pipeline:\n",
    "\n",
    "- model_track = 'main' if RBCS_FamNumb != '000'\n",
    "- model_track = 'no_family' if RBCS_FamNumb = '000'\n",
    "\n",
    "Then we build:\n",
    "\n",
    "- model_dataset_main.parquet\n",
    "- model_dataset_no_family.parquet (optional, can come later)\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197",
   "metadata": {},
   "source": [
    "**One more quick QC that’s worth doing**\n",
    "\n",
    "Check whether 000 is also concentrated in **specific HCPCS codes** (often a sign it’s a special code pattern):\n",
    "\n",
    "If we see a small number of HCPCS codes dominating, that further supports “special bucket” behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  p.HCPCS_Cd,\n",
    "  MAX(p.HCPCS_Desc) AS hcpcs_desc,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(p.Tot_Srvcs) AS total_services\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl p\n",
    "WHERE p.RBCS_FamNumb = '000'\n",
    "GROUP BY 1\n",
    "ORDER BY total_services DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199",
   "metadata": {},
   "source": [
    "It seems like most of the descriptions are injections. We should confirm this by running a regex to show what percentage of all **RBCS_FamNumb = '000'** are described as \"injections\" at any context of specific drug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "Fast check: “Injection” share by rows and by services\n",
    "\n",
    "If pct_services_injection is very high (for example > 0.7), then the “000 bucket” is essentially “drug units/injections” in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201",
   "metadata": {},
   "source": [
    "Slightly broader keyword net\n",
    "\n",
    "Some injection-related codes might not literally contain the word “injection” (for example contrast materials). We can create a broader “drug or injectable” bucket:\n",
    "\n",
    "This will tell us whether “injection” alone explains most of the services, or if it’s “injection + contrast + unclassified drug” etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN lower(HCPCS_Desc) LIKE '%injection%' THEN 1\n",
    "      ELSE 0\n",
    "    END AS is_injection,\n",
    "    Tot_Srvcs\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb = '000'\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(is_injection) AS n_injection_rows,\n",
    "  1.0 * SUM(is_injection) / COUNT(*) AS pct_rows_injection,\n",
    "\n",
    "  SUM(Tot_Srvcs) AS total_services,\n",
    "  SUM(CASE WHEN is_injection = 1 THEN Tot_Srvcs ELSE 0 END) AS injection_services,\n",
    "  1.0 * SUM(CASE WHEN is_injection = 1 THEN Tot_Srvcs ELSE 0 END) / NULLIF(SUM(Tot_Srvcs), 0) AS pct_services_injection\n",
    "FROM base;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203",
   "metadata": {},
   "source": [
    "Bonus: Let's use `HCPCS_Drug_Ind` in our `prov_svc_onco_core_prov_all_rbcs_nppes_tbl`\n",
    "\n",
    "Our big table appears to have `HCPCS_Drug_Ind`. If it’s reliable, it’s cleaner than regex:\n",
    "\n",
    "**What this means for our modeling decision**\n",
    "\n",
    "If we confirm that 000 is mostly drug-unit injection codes:\n",
    "\n",
    "- It strengthens the case to **exclude RBCS_FamNumb='000' from the main service-family benchmark model** (our Option B main track).\n",
    "- Then we can treat 000 as a **secondary “drug units” track** later, with its own modeling logic and careful interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    lower(HCPCS_Desc) AS d,\n",
    "    Tot_Srvcs\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb = '000'\n",
    "),\n",
    "tagged AS (\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN d LIKE '%injection%' THEN 'injection'\n",
    "      WHEN d LIKE '%contrast%' THEN 'contrast'\n",
    "      WHEN d LIKE '%unclassified drug%' OR d LIKE '%unclassified drugs%' THEN 'unclassified_drug'\n",
    "      WHEN d LIKE '%chemotherap%' THEN 'chemo'\n",
    "      WHEN d LIKE '%imaging%' OR d LIKE '%gadol%' OR d LIKE '%radiology%' THEN 'imaging_related'\n",
    "      ELSE 'other'\n",
    "    END AS bucket,\n",
    "    Tot_Srvcs\n",
    "  FROM base\n",
    ")\n",
    "SELECT\n",
    "  bucket,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(Tot_Srvcs) AS total_services,\n",
    "  1.0 * SUM(Tot_Srvcs) / (SELECT SUM(Tot_Srvcs) FROM tagged) AS pct_services\n",
    "FROM tagged\n",
    "GROUP BY 1\n",
    "ORDER BY total_services DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  HCPCS_Drug_Ind,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(Tot_Srvcs) AS total_services,\n",
    "  1.0 * SUM(Tot_Srvcs) / (SELECT SUM(Tot_Srvcs)\n",
    "                          FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "                          WHERE RBCS_FamNumb='000') AS pct_services\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "WHERE RBCS_FamNumb='000'\n",
    "GROUP BY 1\n",
    "ORDER BY total_services DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206",
   "metadata": {},
   "source": [
    "It seems that most of the RBCS_FamNumb='000'  are actually related to injections.\n",
    "\n",
    "These three checks line up perfectly, and they give us a very defensible conclusion.\n",
    "What our results mean\n",
    "\n",
    "1) “Injection” dominates by services (the important lens)\n",
    "\n",
    "<br>\n",
    "\n",
    "Only 53.4% of rows contain the word “injection”.\n",
    "But those rows account for 91.3% of total services in the 000 bucket.\n",
    "So the 000 bucket is not “half injections” in the sense that matters for modeling. It’s overwhelmingly injection volume.\n",
    "\n",
    "<br>\n",
    "\n",
    "2) Our broader keyword tagging confirms the same story\n",
    "\n",
    "Injection: 91.3% of services\n",
    "Contrast: 6.8% of services\n",
    "Everything else combined is small.\n",
    "This is very consistent with “drug units and related items” rather than standard “service families.”\n",
    "\n",
    "<br>\n",
    "\n",
    "3) The drug indicator seals it\n",
    "\n",
    "<br>\n",
    "\n",
    "HCPCS_Drug_Ind = 'Y' is 98.5% of services in 000.\n",
    "That is huge. It means RBCS_FamNumb='000' is basically a drug-related bucket in our extracted oncology universe.\n",
    "What we should do (clear recommendation)\n",
    "Use the split-track approach:\n",
    "Main benchmarking model (our portfolio headline)\n",
    "Train and score ONLY on rows where:\n",
    "RBCS_FamNumb IS NOT NULL\n",
    "RBCS_FamNumb <> '000'\n",
    "This is our clean “apples-to-apples service-family benchmarking engine.”\n",
    "Secondary “drug unit” track (optional add-on)\n",
    "\n",
    "<br>\n",
    "\n",
    "Keep RBCS_FamNumb='000' rows separate.\n",
    "If we include it later, frame it honestly as “drug unit and related codes (injections, contrast).”\n",
    "It can be its own model or a descriptive module. It does not need to be part of the core benchmark story.\n",
    "This aligns with our goal: make the primary narrative clean and interview-safe for Garner/Oscar.\n",
    "How to describe this decision in our write-up\n",
    "\n",
    "<br>\n",
    "\n",
    "We can say something like:\n",
    "“RBCS family ‘000’ represents non-standard family assignments in RBCS. In our oncology subset, it is overwhelmingly drug-related volume: 98.5% of services have HCPCS_Drug_Ind='Y', and 91.3% of services are codes whose description includes ‘injection’. Because drug unit billing behaves differently from service-family costs, we exclude RBCS ‘000’ from the main service-family benchmark model and treat it as a separate track.”\n",
    "That sounds thoughtful, not like data cleaning hand-waving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207",
   "metadata": {},
   "source": [
    "Let's now calculate within `RBCS_FamNumb='000'` what is the % of standardized spend from injection vs other\n",
    "\n",
    "A) Text-based (“injection” in description), using the HCPCS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    CASE WHEN lower(HCPCS_Desc) LIKE '%injection%' THEN 'injection' ELSE 'other' END AS bucket,\n",
    "    Tot_Srvcs * Avg_Mdcr_Stdzd_Amt AS stdzd_spend\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb='000'\n",
    ")\n",
    "SELECT\n",
    "  bucket,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(stdzd_spend) AS total_stdzd_spend,\n",
    "  1.0 * SUM(stdzd_spend) / NULLIF((SELECT SUM(stdzd_spend) FROM base), 0) AS pct_stdzd_spend\n",
    "FROM base\n",
    "GROUP BY 1\n",
    "ORDER BY total_stdzd_spend DESC;\n",
    "\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209",
   "metadata": {},
   "source": [
    "B) Drug-indicator-based (often cleaner than text):\n",
    "\n",
    "This uses `HCPCS_Drug_Ind` variable instead of relying on character matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    CASE WHEN HCPCS_Drug_Ind='Y' THEN 'drug_ind_Y' ELSE 'drug_ind_N' END AS bucket,\n",
    "    Tot_Srvcs * Avg_Mdcr_Stdzd_Amt AS stdzd_spend\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb='000'\n",
    ")\n",
    "SELECT\n",
    "  bucket,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(stdzd_spend) AS total_stdzd_spend,\n",
    "  1.0 * SUM(stdzd_spend) / NULLIF((SELECT SUM(stdzd_spend) FROM base), 0) AS pct_stdzd_spend\n",
    "FROM base\n",
    "GROUP BY 1\n",
    "ORDER BY total_stdzd_spend DESC;\n",
    "\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211",
   "metadata": {},
   "source": [
    "**The interesting part: why “injection dominates services” but not “spend”**\n",
    "\n",
    "Earlier, we found within 000:\n",
    "\n",
    "- ~**98% of services** are “injection” (text match), and ~**98.6% of services** have `HCPCS_Drug_Ind='Y'`.\n",
    "\n",
    "But now we see **only ~42% to 45% of spend** is injection or drug-indicated.\n",
    "\n",
    "That usually means: **the injection/drug rows have massive unit counts (Tot_Srvcs) but low standardized amount per unit**, while the non-injection or non-drug rows have fewer units but higher standardized amounts per unit.\n",
    "\n",
    "To make that relationship explicit, let's run this:\n",
    "\n",
    "That will quantify the “lots of units, cheap per unit” vs “few units, expensive per unit” pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    CASE WHEN lower(HCPCS_Desc) LIKE '%injection%' THEN 'injection' ELSE 'other' END AS bucket,\n",
    "    Tot_Srvcs AS services,\n",
    "    (Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS stdzd_spend\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb='000'\n",
    ")\n",
    "SELECT\n",
    "  bucket,\n",
    "  SUM(services) AS total_services,\n",
    "  SUM(stdzd_spend) AS total_stdzd_spend,\n",
    "  SUM(stdzd_spend) / NULLIF(SUM(services), 0) AS implied_stdzd_amt_per_service,\n",
    "  1.0 * SUM(services) / NULLIF((SELECT SUM(services) FROM base),0) AS pct_services,\n",
    "  1.0 * SUM(stdzd_spend) / NULLIF((SELECT SUM(stdzd_spend) FROM base),0) AS pct_spend\n",
    "FROM base\n",
    "GROUP BY 1\n",
    "ORDER BY total_stdzd_spend DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213",
   "metadata": {},
   "source": [
    "What each column is telling us\n",
    "\n",
    "Bucket totals\n",
    "- Injection\n",
    "    - total_services: 240,415,048.9 (98.13% of services)\n",
    "    - total_stdzd_spend: $287,613,028.58 (45.36% of spend)\n",
    "    - implied_stdzd_amt_per_service: $1.20 per service\n",
    "- Other\n",
    "    - total_services: 4,573,314.8 (1.87% of services)\n",
    "    - total_stdzd_spend: $346,436,797.62 (54.64% of spend)\n",
    "    - implied_stdzd_amt_per_service: $75.75 per service\n",
    "\n",
    "The main takeaway\n",
    "\n",
    "Within RBCS_FamNumb='000':\n",
    "- Almost all of the service volume is “injection” (98.13%).\n",
    "- But most of the standardized spend is “other” (54.64%).\n",
    "- The reason is the per-service cost difference:\n",
    "    - “Injection” averages ~$1.20 per unit\n",
    "    - “Other” averages ~$75.75 per unit\n",
    "    - That’s about a 63x difference (75.75 / 1.20 ≈ 63.3).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214",
   "metadata": {},
   "source": [
    "Those huge injection service counts are often because many drug HCPCS codes are billed in tiny units (mg, mcg, 1 mg units, etc.). To show that explicitly, let's pull the top injection HCPCS in 000 by services and look at their descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  HCPCS_Cd,\n",
    "  MAX(HCPCS_Desc) AS hcpcs_desc,\n",
    "  SUM(Tot_Srvcs) AS total_services,\n",
    "  SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS total_stdzd_spend,\n",
    "  SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) / NULLIF(SUM(Tot_Srvcs),0) AS implied_amt_per_service\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "WHERE RBCS_FamNumb='000'\n",
    "  AND lower(HCPCS_Desc) LIKE '%injection%'\n",
    "GROUP BY 1\n",
    "ORDER BY total_services DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216",
   "metadata": {},
   "source": [
    "Let's quantify how much of injection volume comes from “per 1 mg / microgram / mcg / 0.1 ml” unit-style descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH inj AS (\n",
    "  SELECT\n",
    "    lower(HCPCS_Desc) AS d,\n",
    "    Tot_Srvcs AS services\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes_tbl\n",
    "  WHERE RBCS_FamNumb='000'\n",
    "    AND lower(HCPCS_Desc) LIKE '%injection%'\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN d LIKE '% 1 mg%' OR d LIKE '%per 1 mg%' THEN 'per_1mg'\n",
    "    WHEN d LIKE '%microgram%' OR d LIKE '% mcg%' THEN 'microgram_or_mcg'\n",
    "    WHEN d LIKE '% 0.1 ml%' THEN 'per_0.1ml'\n",
    "    ELSE 'other_injection_units'\n",
    "  END AS unit_bucket,\n",
    "  SUM(services) AS total_services,\n",
    "  1.0 * SUM(services) / (SELECT SUM(services) FROM inj) AS pct_injection_services\n",
    "FROM inj\n",
    "GROUP BY 1\n",
    "ORDER BY total_services DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218",
   "metadata": {},
   "source": [
    "## EDA 2. Outcome distributions and log justification\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. Histogram: `stdzd_amt_per_service` (raw)\n",
    "2. Histogram: `log_stdzd_amt_per_service`\n",
    "3. Box plot: `stdzd_amt_per_service` by `Place_Of_Srvc` (overall)\n",
    "4. Percentiles table for standardized, allowed, payment, submitted:\n",
    "    - p01, p50, p90, p95, p99, max\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- How skewed are costs?\n",
    "- Does log transform stabilize the distribution?\n",
    "- Are there extreme outliers that will dominate training if we do not log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(eda_df[\"stdzd_amt_per_service\"])\n",
    "plt.title(\"Histogram of stdzd_amt_per_service variable (original scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(is_bottom_99pct_eda_df[\"stdzd_amt_per_service\"])\n",
    "plt.title(\"Histogram of stdzd_amt_per_service variable (original scale) (bottom 99%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(eda_df[\"stdzd_amt_per_service\"]))\n",
    "plt.title(\"Histogram of stdzd_amt_per_service variable (np.log1p-transformed scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(data=eda_df,\n",
    "                x = \"Place_Of_Srvc\",\n",
    "                y=\"log_stdzd_amt_per_service\")\n",
    "g.set_title(\"log_stdzd_amt_per_service by Place_Of_Srvc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"stdzd_amt_per_service\", \"allowed_amt_per_service\", \"payment_amt_per_service\"]\n",
    "\n",
    "percentiles = eda_df[cols].quantile([0.01, 0.5, 0.9, 0.95, 0.99])\n",
    "\n",
    "max_vals = eda_df[cols].max().to_frame().T\n",
    "max_vals.index = [1.0]\n",
    "\n",
    "result = pd.concat([percentiles, max_vals])\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225",
   "metadata": {},
   "source": [
    "Let's also calculate share of total spend contributed by top 1% rows” and “share of services contributed by top 1%”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby(\"is_top_1pct_stdzd_amt_per_service\")\n",
    " .agg(\n",
    "     total_spend=(\"stdzd_spend\", \"sum\"),\n",
    "     total_services=(\"services\", \"sum\"),\n",
    " )\n",
    " .assign(\n",
    "     pct_total_spend=lambda x: x[\"total_spend\"] / x[\"total_spend\"].sum(),\n",
    "     pct_total_services=lambda x: x[\"total_services\"] / x[\"total_services\"].sum(),\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227",
   "metadata": {},
   "source": [
    "## EDA 3. Exposure, reliability, and threshold selection\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. Histogram: services\n",
    "2. CDF plot: cumulative share of rows by services\n",
    "3. Scatter: `services` vs `stdzd_amt_per_service` (use log x-axis)\n",
    "4. Optional: binned variance plot\n",
    "    - bin services into ranges and show cost variance per bin\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- How much of the dataset is low-volume and noisy?\n",
    "- Is services >= 11 reasonable for training?\n",
    "- What threshold should we use later for “flagging” outliers (like 50+)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228",
   "metadata": {},
   "source": [
    "Histogram of services: The distribution of exposure (how many services went into each row’s per-service cost).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(eda_df[\"services\"])\n",
    "plt.title(\"Histogram of services variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230",
   "metadata": {},
   "source": [
    "The histogram is xtremely right-skewed. Most rows have relatively low services, and a small number of rows have massive service counts (up to ~500k). That is normal in claims-like utilization data.\n",
    "\n",
    "Low-service rows have noisier “per service” averages. High-service rows have very stable averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(data = eda_df, x=\"services\")\n",
    "plt.title(\"CDF of Services: Cumulative Share of Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"log_services\"] = np.log1p(eda_df[\"services\"])\n",
    "\n",
    "g = sns.scatterplot(data=eda_df, x = \"log_services\", y=\"log_stdzd_amt_per_service\", alpha=0.1, s=10)\n",
    "g.set_title(\"log_stdzd_amt_per_service vs log_services\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a binned version of 'services' (e.g., 5 equal-width bins)\n",
    "eda_df['services_bins'] = pd.cut(eda_df['services'], bins=5)\n",
    "\n",
    "# 2. Plot variance per bin\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=eda_df, x='services_bins', y='log_stdzd_amt_per_service', estimator=np.var)\n",
    "\n",
    "plt.title('Cost Variance per Services Bin')\n",
    "plt.ylabel('Variance of log_stdzd_amt_per_service')\n",
    "plt.xlabel('Services Bins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom edges: 0 to 11, 11 to 25, 25 to 50, 50 to 100, and 100+\n",
    "custom_bins = [0, 11, 25, 50, 100, np.inf]\n",
    "custom_labels = ['0-11', '12-25', '26-50', '51-100', '100+']\n",
    "\n",
    "# Create the binned column\n",
    "eda_df['services_custom'] = pd.cut(\n",
    "    eda_df['services'], \n",
    "    bins=custom_bins, \n",
    "    labels=custom_labels, \n",
    "    include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=eda_df, \n",
    "    x='services_custom', \n",
    "    y='log_stdzd_amt_per_service', \n",
    "    estimator=np.var\n",
    ")\n",
    "\n",
    "plt.title('Cost Variance by Custom Service Thresholds')\n",
    "plt.ylabel('Variance (log_stdzd_amt_per_service)')\n",
    "plt.xlabel('Services Bins')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236",
   "metadata": {},
   "source": [
    "**Adding counts per bin**\n",
    "\n",
    "We need to know if 100+ has a small number of rows (unstable estimate) or tons (real pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.groupby(\"services_custom\").agg(\n",
    "    n_rows=(\"log_stdzd_amt_per_service\",\"size\"),\n",
    "    var_y=(\"log_stdzd_amt_per_service\", np.var),\n",
    "    mean_y=(\"log_stdzd_amt_per_service\",\"mean\"),\n",
    "    p95=(\"log_stdzd_amt_per_service\", lambda s: np.quantile(s, 0.95))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238",
   "metadata": {},
   "source": [
    "**Split 100+ into sub-bins**\n",
    "\n",
    "Keep our early bins, but break 100+ into a few more. For example:\n",
    "\n",
    "- 101–250\n",
    "- 251–1,000\n",
    "- 1,001–10,000\n",
    "- 10,000+\n",
    "\n",
    "If the variance spike is really coming from, say, the “10k+” group, that is an important story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins2 = [0, 11, 25, 50, 100, 250, 1000, 10000, np.inf]\n",
    "labels2 = [\"0-11\",\"12-25\",\"26-50\",\"51-100\",\"101-250\",\"251-1k\",\"1k-10k\",\"10k+\"]\n",
    "\n",
    "eda_df[\"services_custom2\"] = pd.cut(eda_df[\"services\"], bins=bins2, labels=labels2, include_lowest=True)\n",
    "\n",
    "sns.barplot(data=eda_df, x=\"services_custom2\", y=\"log_stdzd_amt_per_service\", estimator=np.var)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240",
   "metadata": {},
   "source": [
    "**1) The “100+” bin is not “more reliable”. It’s a different regime.**\n",
    "\n",
    "Look at these side by side:\n",
    "\n",
    "- **51–100:** var ≈ **0.679**, IQR ≈ **0.780**, mean ≈ **4.47**, p95 ≈ **5.80**\n",
    "- **100+:** var ≈ **1.874**, IQR ≈ **1.571**, mean ≈ **3.51**, p95 ≈ **5.04**\n",
    "\n",
    "So 100+ is:\n",
    "\n",
    "- **much more spread out** (variance and IQR both jump a lot),\n",
    "- with a **lower mean** and **lower p95** than the smaller bins.\n",
    "\n",
    "That means the huge variance is not just a few outliers. It’s telling us that 100+ rows are a heterogeneous mix (different families, different billing patterns, different settings), which is exactly what the sub-bin plot is showing.\n",
    "\n",
    "**2) The split confirms the variance spike is concentrated in a middle-high range**\n",
    "\n",
    "From the plot:\n",
    "\n",
    "- 0–11 through 51–100 are all in the same ballpark (stable-ish).\n",
    "- **101–250 and 251–1k** start drifting up a bit.\n",
    "- **1k–10k** is the giant spike (the main problem).\n",
    "- **10k+** drops again (still higher than low bins, but much lower than 1k–10k).\n",
    "\n",
    "That is a classic “mixture” story: the 1k–10k segment likely contains specific high-volume drug administration patterns that have very different per-service cost behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241",
   "metadata": {},
   "source": [
    "**Let's also use IQR as a robustness check**\n",
    "\n",
    "Variance can be misleading. IQR tells us the “middle spread.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(s):\n",
    "    return np.quantile(s, 0.75) - np.quantile(s, 0.25)\n",
    "\n",
    "eda_df.groupby(\"services_custom\").agg(\n",
    "    n_rows=(\"log_stdzd_amt_per_service\",\"size\"),\n",
    "    iqr_y=(\"log_stdzd_amt_per_service\", iqr),\n",
    "    var_y=(\"log_stdzd_amt_per_service\", np.var)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.groupby(\"services_custom2\").agg(\n",
    "    n_rows=(\"log_stdzd_amt_per_service\",\"size\"),\n",
    "    iqr_y=(\"log_stdzd_amt_per_service\", lambda s: np.quantile(s,0.75)-np.quantile(s,0.25)),\n",
    "    var_y=(\"log_stdzd_amt_per_service\", np.var)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244",
   "metadata": {},
   "source": [
    "**The key takeaway**\n",
    "\n",
    "Our dataset is **row-heavy in the low and mid volumes**, but **service-heavy in the ultra-high volumes**.\n",
    "\n",
    "- **10k+ is only 7.27% of rows** (23,947 rows)\n",
    "- But it contains **84.17% of all services** (992M services)\n",
    "\n",
    "So if we care about “what drives total oncology service volume”, the 10k+ group dominates. If we we about “typical provider-service records”, the smaller bins dominate.\n",
    "\n",
    "This is exactly why we need a deliberate weighting strategy and why we should report results stratified by volume bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (\n",
    "    eda_df.groupby(\"services_custom2\")\n",
    "    .agg(\n",
    "        n_rows=(\"services\",\"size\"),\n",
    "        total_services=(\"services\",\"sum\")\n",
    "    )\n",
    ")\n",
    "tmp[\"pct_rows\"] = tmp[\"n_rows\"] / tmp[\"n_rows\"].sum()\n",
    "tmp[\"pct_services\"] = tmp[\"total_services\"] / tmp[\"total_services\"].sum()\n",
    "tmp.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246",
   "metadata": {},
   "source": [
    "## EDA 4. Service mix and spend concentration (core storytelling)\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. Top 15 families by total services:\n",
    "    - bar: `SUM(services)` by `rbcs_family_desc`\n",
    "2. Top 15 families by total standardized spend:\n",
    "    - bar: `SUM(stdzd_spend)` by `rbcs_family_desc`\n",
    "3. Pareto chart:\n",
    "    - cumulative percent of spend captured by top families\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- Which service families drive volume?\n",
    "- Which service families drive spend?\n",
    "- Where is the biggest opportunity for steerage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247",
   "metadata": {},
   "source": [
    "**1A. Top 15 families by total services (the entire `eda_df` dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_srvc_by_rbcs_family_desc = (eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "          .agg(services_sum=(\"services\", \"sum\"))\n",
    "          .sort_values(\"services_sum\", ascending=False))\n",
    "\n",
    "sum_srvc_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249",
   "metadata": {},
   "source": [
    "This table is already telling a clear story, and the “No RBCS Family” row is not a red flag anymore given what we already proved earlier.\n",
    "\n",
    "**How to interpret the table**\n",
    "\n",
    "Each row is an **RBCS family bucket** (a service category), and services_sum is the **total number of services** in our EDA dataset for that family.\n",
    "\n",
    "So this is basically answering:\n",
    "\n",
    "**“Which oncology service families account for the most delivered volume?”**\n",
    "\n",
    "**What jumps out immediately**\n",
    "\n",
    "1) The top of the list is dominated by “drug administration and supportive meds”\n",
    "\n",
    "- Erythropoiesis stimulating agents (largest)\n",
    "- Chemotherapeutic agents\n",
    "- Injection colony stimulating factors\n",
    "- Injection administration\n",
    "- IV infusion, hydration\n",
    "- Immune globulin injections\n",
    "\n",
    "That pattern is very consistent with outpatient oncology operations (lots of repeated drug-related units).\n",
    "\n",
    "2) “No RBCS Family” being #2 is expected, and it has a specific meaning in our data\n",
    "\n",
    "From our earlier QC:\n",
    "\n",
    "- rbcs_family_desc = 'No RBCS Family' corresponds to **RBCS_FamNumb = '000'**\n",
    "- And **~84% of services inside that group are injections**, and **~98% of its services are HCPCS_Drug_Ind = ‘Y’**\n",
    "\n",
    "So we should interpret **“No RBCS Family”** as:\n",
    "\n",
    "> “A large set of mostly drug-related injection HCPCS codes that are not assigned to a standard RBCS family in the mapping.”\n",
    "\n",
    "It is not “missing data” in the usual sense. It is a real bucket that our RBCS mapping defines as “unclassified or not mapped to a standard family”.\n",
    "\n",
    "3) Evaluation & Management (E&M) is high volume, not surprising\n",
    "\n",
    "- Office E&M new\n",
    "- Office E&M established\n",
    "\n",
    "These are common visit codes and will produce lots of service counts even if cost per service is not huge.\n",
    "\n",
    "4) Pathology and imaging show up as high volume too\n",
    "\n",
    "- Surgical pathology examination\n",
    "- Contrast agent\n",
    "- Plus radiation-related families\n",
    "\n",
    "That is plausible because oncology care triggers a lot of labs, imaging, and radiation planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250",
   "metadata": {},
   "source": [
    "**1B. Top 15 families by total services (the top 1% for standardized cost per service part of the `eda_df` dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_srvc_by_rbcs_family_desc = (is_top_1pct_eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "          .agg(services_sum=(\"services\", \"sum\"))\n",
    "          .sort_values(\"services_sum\", ascending=False))\n",
    "\n",
    "sum_srvc_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252",
   "metadata": {},
   "source": [
    "**1C. Top 15 families by total services (the bottom 99% for standardized cost per service part of the `eda_df` dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_srvc_by_rbcs_family_desc = (is_bottom_99pct_eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "          .agg(services_sum=(\"services\", \"sum\"))\n",
    "          .sort_values(\"services_sum\", ascending=False))\n",
    "\n",
    "sum_srvc_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254",
   "metadata": {},
   "source": [
    "**2A. Top 15 families by total standardized spend (the entire `eda_df` dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stdzd_spend_by_rbcs_family_desc = (eda_df\n",
    "                                       .groupby(\"rbcs_family_desc\", as_index=False)\n",
    "                                       .agg(sum_stdzd_spend = (\"stdzd_spend\",\"sum\"))\n",
    "                                       .assign(sum_stdzd_spend_pct = lambda x: x[\"sum_stdzd_spend\"]/x[\"sum_stdzd_spend\"].sum())\n",
    "                                       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "sum_stdzd_spend_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Spend by family\n",
    "fam = (eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "       .agg(sum_stdzd_spend=(\"stdzd_spend\", \"sum\"))\n",
    "       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "# 2) Cumulative percent of spend\n",
    "fam[\"cum_spend\"] = fam[\"sum_stdzd_spend\"].cumsum()\n",
    "total_spend = fam[\"sum_stdzd_spend\"].sum()\n",
    "fam[\"cum_pct_spend\"] = fam[\"cum_spend\"] / total_spend\n",
    "\n",
    "# 3) Pick top N to display\n",
    "N = 25\n",
    "top = fam.head(N).copy()\n",
    "\n",
    "# 4) Plot: bars = spend, line = cumulative percent\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.bar(top[\"rbcs_family_desc\"], top[\"sum_stdzd_spend\"])\n",
    "ax1.set_ylabel(\"Total standardized spend (sum)\")\n",
    "ax1.set_title(f\"Pareto of standardized spend by RBCS family (Top {N})\")\n",
    "ax1.tick_params(axis=\"x\", rotation=75)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(top[\"rbcs_family_desc\"], top[\"cum_pct_spend\"] * 100, marker=\"o\")\n",
    "ax2.set_ylabel(\"Cumulative % of total spend\")\n",
    "\n",
    "# Optional reference lines (80/20 rule vibe)\n",
    "ax2.axhline(80, linestyle=\"--\")\n",
    "ax2.axhline(90, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: show the key numbers as a table\n",
    "top[[\"rbcs_family_desc\", \"sum_stdzd_spend\", \"cum_pct_spend\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Spend by family\n",
    "fam = (eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "       .agg(sum_stdzd_spend=(\"stdzd_spend\", \"sum\"))\n",
    "       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "# 2) Cumulative percent of spend\n",
    "fam[\"cum_spend\"] = fam[\"sum_stdzd_spend\"].cumsum()\n",
    "total_spend = fam[\"sum_stdzd_spend\"].sum()\n",
    "fam[\"cum_pct_spend\"] = fam[\"cum_spend\"] / total_spend\n",
    "\n",
    "# fam must already be sorted desc by sum_stdzd_spend and have cum_pct_spend computed\n",
    "N = 25\n",
    "top = fam.head(N).copy()\n",
    "\n",
    "# Reverse so biggest is at top in barh\n",
    "top = top.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "y = np.arange(len(top))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bars (spend)\n",
    "ax1.barh(y, top[\"sum_stdzd_spend\"])\n",
    "ax1.set_yticks(y)\n",
    "ax1.set_yticklabels(top[\"rbcs_family_desc\"], fontsize=9)\n",
    "ax1.set_xlabel(\"Total standardized spend (sum)\")\n",
    "ax1.set_title(f\"Pareto of standardized spend by RBCS family (Top {N})\")\n",
    "\n",
    "# Line (cumulative percent) on a top x-axis or secondary x-axis\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(top[\"cum_pct_spend\"] * 100, y, marker=\"o\", c = \"red\")\n",
    "ax2.set_xlabel(\"Cumulative % of total spend\")\n",
    "\n",
    "# Reference lines\n",
    "ax2.axvline(80, linestyle=\"--\")\n",
    "ax2.axvline(90, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Spend by family\n",
    "eda_mapped = eda_df[eda_df[\"RBCS_FamNumb\"] != \"000\"].copy()\n",
    "\n",
    "fam = (eda_mapped.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "       .agg(sum_stdzd_spend=(\"stdzd_spend\", \"sum\"))\n",
    "       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "# 2) Cumulative percent of spend\n",
    "fam[\"cum_spend\"] = fam[\"sum_stdzd_spend\"].cumsum()\n",
    "total_spend = fam[\"sum_stdzd_spend\"].sum()\n",
    "fam[\"cum_pct_spend\"] = fam[\"cum_spend\"] / total_spend\n",
    "\n",
    "# 3) Pick top N to display\n",
    "N = 25\n",
    "top = fam.head(N).copy()\n",
    "\n",
    "# 4) Plot: bars = spend, line = cumulative percent\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.bar(top[\"rbcs_family_desc\"], top[\"sum_stdzd_spend\"])\n",
    "ax1.set_ylabel(\"Total standardized spend (sum)\")\n",
    "ax1.set_title(f\"Pareto of standardized spend by RBCS family (Top {N}) ('RBCS_FamNumb =! 000')\")\n",
    "ax1.tick_params(axis=\"x\", rotation=75)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(top[\"rbcs_family_desc\"], top[\"cum_pct_spend\"] * 100, marker=\"o\")\n",
    "ax2.set_ylabel(\"Cumulative % of total spend\")\n",
    "\n",
    "# Optional reference lines (80/20 rule vibe)\n",
    "ax2.axhline(80, linestyle=\"--\")\n",
    "ax2.axhline(90, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: show the key numbers as a table\n",
    "top[[\"rbcs_family_desc\", \"sum_stdzd_spend\", \"cum_pct_spend\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Spend by family\n",
    "eda_mapped = eda_df[eda_df[\"RBCS_FamNumb\"] != \"000\"].copy()\n",
    "\n",
    "fam = (eda_mapped.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "       .agg(sum_stdzd_spend=(\"stdzd_spend\", \"sum\"))\n",
    "       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "# 2) Cumulative percent of spend\n",
    "fam[\"cum_spend\"] = fam[\"sum_stdzd_spend\"].cumsum()\n",
    "total_spend = fam[\"sum_stdzd_spend\"].sum()\n",
    "fam[\"cum_pct_spend\"] = fam[\"cum_spend\"] / total_spend\n",
    "\n",
    "# fam must already be sorted desc by sum_stdzd_spend and have cum_pct_spend computed\n",
    "N = 25\n",
    "top = fam.head(N).copy()\n",
    "\n",
    "# Reverse so biggest is at top in barh\n",
    "top = top.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "y = np.arange(len(top))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bars (spend)\n",
    "ax1.barh(y, top[\"sum_stdzd_spend\"])\n",
    "ax1.set_yticks(y)\n",
    "ax1.set_yticklabels(top[\"rbcs_family_desc\"], fontsize=9)\n",
    "ax1.set_xlabel(\"Total standardized spend (sum)\")\n",
    "ax1.set_title(f\"Pareto of standardized spend by RBCS family (Top {N}) ('RBCS_FamNumb != 000')\")\n",
    "\n",
    "# Line (cumulative percent) on a top x-axis or secondary x-axis\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(top[\"cum_pct_spend\"] * 100, y, marker=\"o\", c = \"red\")\n",
    "ax2.set_xlabel(\"Cumulative % of total spend\")\n",
    "\n",
    "# Reference lines\n",
    "ax2.axvline(80, linestyle=\"--\")\n",
    "ax2.axvline(90, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260",
   "metadata": {},
   "source": [
    "We implemented the Pareto correctly, and the outputs are telling a very clear story.\n",
    "\n",
    "**How to interpret the “Top families by total services” table**\n",
    "\n",
    "That table is basically answering: **“What kinds of things are being done the most often (by count of services)?”**\n",
    "\n",
    "- **Services_sum is volume**, not dollars.\n",
    "- So it is totally possible for something to be huge in services but not huge in spend (cheap but frequent), and vice versa (expensive but not frequent).\n",
    "\n",
    "**Why “No RBCS Family” is so high in services**\n",
    "\n",
    "Given what we already proved earlier, **RBCS_FamNumb = ‘000’ is mostly injection-related and drug-indicated** (about ~91% of services have “injection” in the description, and ~98% of services are HCPCS_Drug_Ind = Y). That usually implies:\n",
    "\n",
    "- These are **drug J-codes and related admin-type codes** that our RBCS mapping is not assigning to a regular family, so they fall into the **“000 / No family” bucket**.\n",
    "- It is likely a **real “unmapped/other” bucket**, not random noise, but it is also **not clinically interpretable as a real service family** like “Chemo agent” or “Radiation planning”.\n",
    "\n",
    "So interpret it as: **“A big chunk of volume is in drug injection codes that are not mapped into a specific RBCS family.”**\n",
    "\n",
    "That is not automatically “bad”. It just means we should treat it intentionally in EDA and modeling (more on that below).\n",
    "\n",
    "**How to interpret the “Top families by total standardized spend” table**\n",
    "\n",
    "This table answers: **“Where is the money?”**\n",
    "\n",
    "- Here, **Chemotherapeutic Agent is #1**, which makes sense because chemo drugs are expensive even if not always the #1 by pure service count.\n",
    "- **Office E&M** categories being near the top is also common because they combine meaningful volume with non-trivial cost.\n",
    "- **Radiation families** show up strongly because they are high-cost and systematic.\n",
    "\n",
    "**Where “No RBCS Family” fits here**\n",
    "\n",
    "It is **still large** (around 0.93B in our full table, top 6), but it becomes **less dominant than the big clinical families**.\n",
    "\n",
    "That matches our earlier diagnosis:\n",
    "\n",
    "- “000” is **massive volume**, but its **median log cost is lower than other families**.\n",
    "- Still, because volume is huge, it can become **material spend**.\n",
    "\n",
    "**How to interpret the Pareto tables and plots (the key story)**\n",
    "\n",
    "A Pareto answers: **“How concentrated is spend in a small number of families?”**\n",
    "\n",
    "From our table **including** “No RBCS Family”:\n",
    "\n",
    "- Top 1 family (Chemo agent) already gets us to **~23.5%** of spend.\n",
    "- Top 5 gets us to **~63.4%**.\n",
    "- Top 8 gets us to **~79.8%** (we’re basically at the 80% line).\n",
    "- Top 12 gets us to **~90.1%**.\n",
    "\n",
    "That is a very strong concentration story: **a small set of service families explains most total standardized spend**.\n",
    "\n",
    "When we **exclude** RBCS_FamNumb = ‘000’, the curve gets even “cleaner” conceptually:\n",
    "\n",
    "- Top 5 gets us to **~67.4%**.\n",
    "- Top 7 gets us to **~78.5%**.\n",
    "- Top 11 gets us to **~89.5%**.\n",
    "\n",
    "So “000” is not driving the whole Pareto story. The story holds either way.\n",
    "\n",
    "**What I would do with “No RBCS Family” going forward**\n",
    "\n",
    "We have two defensible paths. Pick one and be consistent.\n",
    "\n",
    "**Option 1 (recommended for clean storytelling)**\n",
    "\n",
    "**Exclude FamNumb = ‘000’ from the “service mix and spend concentration” plots**, and explicitly label it as “unmapped drug injection codes” elsewhere.\n",
    "\n",
    "Why:\n",
    "\n",
    "- Those plots are meant to tell a clinical/operational story about families.\n",
    "- “No RBCS Family” is not interpretable in the same way.\n",
    "\n",
    "We can still keep it in the dataset for modeling if we want, but keep the family-level “mix” charts clean.\n",
    "\n",
    "**Option 2 (keep it, but treat it as its own explicit bucket)**\n",
    "\n",
    "Keep it in plots, but **rename it in charts** to something like:\n",
    "\n",
    "- “Unmapped (000) drug injection codes”\n",
    "    \n",
    "    so readers do not think it is a meaningful service family.\n",
    "    \n",
    "\n",
    "**Quick next EDA steps that fit perfectly after our Pareto**\n",
    "\n",
    "1. **Make a second Pareto by Place_Of_Srvc** (F vs O).\n",
    "    \n",
    "    Question it answers: “Is spend concentration different in facility vs office settings?”\n",
    "    \n",
    "2. **Make the Pareto within provider_type** (HemOnc vs RadOnc, etc.).\n",
    "    \n",
    "    Question it answers: “Are different specialties driven by different spend families?”\n",
    "    \n",
    "3. **Add one table: top 10 families by spend, with median and p95 of log_stdzd_amt_per_service**\n",
    "    \n",
    "    Question it answers: “Which families are expensive because of unit cost vs expensive because of volume?”\n",
    "    \n",
    "\n",
    "If we want, paste our `eda_df` column list (or the EDA extract SQL we used), and I’ll give us the exact code blocks for these three so they drop into the notebook cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261",
   "metadata": {},
   "source": [
    "**2B. Top 15 families by total standardized spend (the top 1% for standardized cost per service part of the `eda_df` dataset)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stdzd_spend_by_rbcs_family_desc = (is_top_1pct_eda_df\n",
    "                                       .groupby(\"rbcs_family_desc\", as_index=False)\n",
    "                                       .agg(sum_stdzd_spend = (\"stdzd_spend\",\"sum\"))\n",
    "                                       .assign(sum_stdzd_spend_pct = lambda x: x[\"sum_stdzd_spend\"]/x[\"sum_stdzd_spend\"].sum())\n",
    "                                       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "sum_stdzd_spend_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263",
   "metadata": {},
   "source": [
    "**1C. Top 15 families by total standardized spend (the bottom 99% for standardized cost per service part of the `eda_df` dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stdzd_spend_by_rbcs_family_desc = (is_bottom_99pct_eda_df\n",
    "                                       .groupby(\"rbcs_family_desc\", as_index=False)\n",
    "                                       .agg(sum_stdzd_spend = (\"stdzd_spend\",\"sum\"))\n",
    "                                       .assign(sum_stdzd_spend_pct = lambda x: x[\"sum_stdzd_spend\"]/x[\"sum_stdzd_spend\"].sum())\n",
    "                                       .sort_values(\"sum_stdzd_spend\", ascending=False))\n",
    "\n",
    "sum_stdzd_spend_by_rbcs_family_desc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265",
   "metadata": {},
   "source": [
    "**One small improvement to make this airtight:**\n",
    "\n",
    "Let's add one more table that quantifies “tail enrichment” per family:\n",
    "\n",
    "For each rbcs_family_desc, compute:\n",
    "\n",
    "- share of spend in tail\n",
    "- share of spend overall\n",
    "- enrichment ratio = tail_share / overall_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) totals for normalization\n",
    "total_spend_all  = eda_df[\"stdzd_spend\"].sum()\n",
    "total_spend_tail = eda_df.loc[eda_df[\"is_top_1pct_stdzd_amt_per_service\"], \"stdzd_spend\"].sum()\n",
    "\n",
    "# 2) family-level spend (all vs tail)\n",
    "fam_all = (eda_df.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "           .agg(spend_all=(\"stdzd_spend\", \"sum\")))\n",
    "\n",
    "fam_tail = (eda_df.loc[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "            .groupby(\"rbcs_family_desc\", as_index=False)\n",
    "            .agg(spend_tail=(\"stdzd_spend\", \"sum\")))\n",
    "\n",
    "# 3) combine + compute shares and enrichment\n",
    "tail_enrichment = (fam_all.merge(fam_tail, on=\"rbcs_family_desc\", how=\"left\")\n",
    "                   .assign(\n",
    "                       spend_tail=lambda d: d[\"spend_tail\"].fillna(0.0),\n",
    "                       overall_share=lambda d: d[\"spend_all\"] / total_spend_all,\n",
    "                       tail_share=lambda d: np.where(\n",
    "                           total_spend_tail > 0, d[\"spend_tail\"] / total_spend_tail, np.nan\n",
    "                       ),\n",
    "                       enrichment_ratio=lambda d: d[\"tail_share\"] / d[\"overall_share\"],\n",
    "                       pct_spend_in_tail=lambda d: np.where(\n",
    "                           d[\"spend_all\"] > 0, d[\"spend_tail\"] / d[\"spend_all\"], np.nan\n",
    "                       ),\n",
    "                   )\n",
    "                   .sort_values(\"enrichment_ratio\", ascending=False))\n",
    "\n",
    "# look at the most tail-enriched families\n",
    "tail_enrichment.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267",
   "metadata": {},
   "source": [
    "The table above has, for each `rbcs_family_desc`:\n",
    "\n",
    "- `overall_share` = “Out of all standardized spend in the full dataset, what fraction belongs to this family?”\n",
    "\n",
    "- `tail_share` = “Out of standardized spend within the tail only (top 1% rows by `stdzd_amt_per_service`), what fraction belongs to this family?”\n",
    "\n",
    "- `enrichment_ratio` = `tail_share / overall_share`\n",
    "    - \">1\" means the family is overrepresented in the tail.\n",
    "    - \"<1\" means the family is underrepresented in the tail.\n",
    "\n",
    "- `pct_spend_in_tail` = “Of this family’s total spend, what percent is in the tail?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268",
   "metadata": {},
   "source": [
    "**A. The tail is not “spread around”. It is heavily concentrated in `PET- Oncology`.**\n",
    "\n",
    "Look at `PET- Oncology`:\n",
    "\n",
    "- `tail_share` = 0.580777 (about 58% of all tail spend)\n",
    "- `overall_share` = 0.02233379 (about 2.23% of all spend)\n",
    "- `enrichment_ratio` = 26.0 (about 26x overrepresented in the tail)\n",
    "- `pct_spend_in_tail` = 0.450119 (about 45% of PET spend is in the tail)\n",
    "\n",
    "*This tells a very clean story: the high-cost-per-service tail is largely a PET story.*\n",
    "\n",
    "**B. Some families are “almost entirely tail”, but they are tiny overall.**\n",
    "\n",
    "Examples:\n",
    "\n",
    "- `Vascular Embolization` has `pct_spend_in_tail` ~ 0.99, enrichment ~57x\n",
    "- `Arthroplasty Knee` and `Arthroplasty Hip` have `pct_spend_in_tail` ~ 0.96 and 0.94, enrichment ~55x\n",
    "\n",
    "*This means: these families have very small total spend (spend_all is tiny compared to PET or IMRT), but when they show up, they tend to show up as extreme cost-per-service rows.*\n",
    "\n",
    "These are “spiky” families. Great for interpretability, not necessarily major drivers of overall spend.\n",
    "\n",
    "**C. The huge spend families are not tail-driven.**\n",
    "\n",
    "Look at big baseline spend families:\n",
    "\n",
    "- Conventional Radiation Treatment\n",
    "\n",
    "    - `overall_share` ~ 9.56%\n",
    "    - `tail_share` ~ 3.48%\n",
    "    - `enrichment_ratio` ~ 0.36 (underrepresented in tail)\n",
    "    - `pct_spend_in_tail` ~ 0.63%\n",
    "\n",
    "- IMRT\n",
    "\n",
    "- `overall_share` ~ 8.32%\n",
    "- `tail_share` ~ 4.84%\n",
    "- `enrichment_ratio` ~ 0.58\n",
    "- `pct_spend_in_tail` ~ 1.0%\n",
    "\n",
    "So our earlier EDA story that “these are major spend families” remains true, and it is not being driven by a few insane tail observations.\n",
    "\n",
    "**D. “No RBCS Family” is mildly tail-enriched but not dominated by the tail.**\n",
    "\n",
    "- `enrichment_ratio` ~ 2.44\n",
    "- `pct_spend_in_tail` ~ 4.22%\n",
    "\n",
    "So `'000'` is not the main tail culprit. It is somewhat overrepresented, but the tail is not primarily a “No RBCS” artifact.\n",
    "\n",
    "**E. Colony Stimulating Factors are meaningfully tail-enriched.**\n",
    "\n",
    "`enrichment_ratio` ~ 7.23\n",
    "`pct_spend_in_tail` ~ 12.5%\n",
    "\n",
    "So this family does have a real upper tail presence and could matter for modeling behavior, depending on what we are predicting and how we evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269",
   "metadata": {},
   "source": [
    "**Interpretation of the tail enrichment analysis**\n",
    "\n",
    "- The top 1% cost-per-service tail is compositionally different from the full dataset.\n",
    "\n",
    "- Tail spend is highly concentrated in PET- Oncology, which accounts for ~58% of tail spend while being ~2.2% of overall spend (about 26x enrichment).\n",
    "\n",
    "- Several procedure families are almost entirely tail when present (embolization, arthroplasty, neurostimulator), but they contribute little to overall spend because their total spend is small.\n",
    "\n",
    "- High-spend baseline families (chemo, IMRT, conventional RT, office E&M) are not tail-dominated, suggesting your primary spend concentration story is robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270",
   "metadata": {},
   "source": [
    "**Implications for modeling**\n",
    "\n",
    "**A.We should keep the tail but evaluate it explicitly**\n",
    "\n",
    "Our enrichement analysis makes the tail interpretable rather than \"noise.\" This is why we should not blindly winsorize away signal.\n",
    "\n",
    "We will\n",
    "- train our model on `log_stdzd_amt_per_service`\n",
    "- add an evaluation slice\n",
    "    - performance on tail rows (`is_top_1pct_stdzd_amt_per_service == True`)\n",
    "    - performance on non-tail rows (`is_top_1pct_stdzd_amt_per_service == False`)\n",
    "This tells us if the model is failing exactly where the cost-outlier story lives. \n",
    "\n",
    "**B. Consider a two-stage modeling option (only if needed)**\n",
    "\n",
    "Because PET is so tail-dominant, we might actually get a better model by doing:\n",
    "1. Classify \"tail vs non-tail\", then\n",
    "2. regress cost within each group\n",
    "\n",
    "This is optional, and will be implemented only if needed. The enrichment analysis justifies this but it is not recommended right away. \n",
    "\n",
    "**C. Feature implications**\n",
    "Because PET is so strong in tail composition, this reinforces that we want strong service-mix controls:\n",
    "- `rbcs_family_desc` (or its higher-level category) MUST be included \n",
    "- `Place_Of_Service` also matters a lot for imaging vs facility pricing patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271",
   "metadata": {},
   "source": [
    "## EDA 5. Place-of-service effects within major families\n",
    "\n",
    "**Plots**\n",
    "\n",
    "For top 8 families by spend:\n",
    "\n",
    "1. Box/violin: `stdzd_amt_per_service` by `Place_Of_Srvc`, faceted by `rbcs_family_desc`\n",
    "2. Stacked bar: share of `services` by `Place_Of_Service` for each `rbcs_family_desc`\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- How much does site-of-care affect cost per service?\n",
    "- Is provider variation partly a “site-of-care mix” story?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby(\"rbcs_family_desc\", as_index=False)\n",
    " .agg(total_stdzd_spend = (\"stdzd_spend\",\"sum\"), sample_size = (\"stdzd_spend\", \"size\"), std_dev_stdzd_spend = (\"stdzd_spend\", \"std\"))\n",
    " .sort_values(\"total_stdzd_spend\", ascending = False)[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8_rbcs_by_spend = (eda_df\n",
    "                       .groupby(\"rbcs_family_desc\", as_index=False)\n",
    "                       .agg(total_stdzd_spend = (\"stdzd_spend\",\"sum\"))\n",
    "                       .sort_values(\"total_stdzd_spend\", ascending = False)[:8][\"rbcs_family_desc\"]\n",
    "                       .to_list())\n",
    "\n",
    "eda_top_8 = eda_df.loc[eda_df[\"rbcs_family_desc\"].isin(top_8_rbcs_by_spend),:]\n",
    "\n",
    "eda_top_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(eda_top_8, row=\"rbcs_family_desc\", height = 5, aspect=1)\n",
    "\n",
    "g.map(sns.violinplot, \"Place_Of_Srvc\", \"log_stdzd_amt_per_service\")\n",
    "\n",
    "g.figure.suptitle(\"Standardized Cost by Place of Service for Top 8 RBCS Families\",  y=1.0, fontsize=11)\n",
    "g.figure.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275",
   "metadata": {},
   "source": [
    "Yes, you did this correctly. A FacetGrid of violin plots by rbcs_family_desc, split by Place_Of_Srvc, is a solid way to answer “how much does site-of-care shift the distribution, within major families” while keeping the outcome on a log scale so the tail does not dominate.\n",
    "\n",
    "Below is how I would read each panel (F vs O), based on the plot you attached.\n",
    "\n",
    "Interpretation by rbcs_family_desc\n",
    "\n",
    "Office E&M. New\n",
    "- F and O are both tightly concentrated (narrow violins), meaning relatively stable “price per service” within this family.\n",
    "- O shows a bit more heterogeneity (you can see multiple bulges / clumps), suggesting multiple billing patterns or code mixes within outpatient for “new” E&M.\n",
    "\n",
    "Office E&M. Established\n",
    "- F and O look very similar in center and spread, with modest tails.\n",
    "- Takeaway: site-of-care does not dramatically shift the distribution here, at least on the log scale.\n",
    "\n",
    "Conventional Radiation Treatment\n",
    "- O is shifted upward vs F and looks a bit wider. That means higher typical log standardized amount per service in outpatient, and possibly more variation.\n",
    "- Takeaway: this family shows a clear POS effect worth keeping as a modeling signal (or at least controlling for).\n",
    "\n",
    "No RBCS Family\n",
    "- This is the most “story-rich” panel.\n",
    "- F looks multimodal and higher overall (several bulges at higher log values).\n",
    "- O has a big mass at much lower log values plus a long tail upward.\n",
    "- This matches what you already found: RBCS 000 is heavily influenced by high-volume injection-style patterns in outpatient, where services explode but implied per-service standardized amount can be low, while facility side can include very different “misc” services with higher per-service costs.\n",
    "\n",
    "Radiation Treatment Planning\n",
    "- O is higher than F (the O violin is centered above F and looks more spread).\n",
    "- Takeaway: another strong POS effect within a radiation-related family.\n",
    "\n",
    "Intensity Modulated Radiation Therapy\n",
    "- This looks weird because the violin collapses into a thin line / minimal body.\n",
    "- That almost always happens when the group has too little variability for KDE to form a distribution, typically due to one of these:\n",
    "\t1.\tVery small n in one or both POS groups, sometimes even n=1.\n",
    "\t2.\tNear-zero variance (many rows share the same or nearly the same log_stdzd_amt_per_service), so KDE degenerates.\n",
    "\t3.\tHeavy discreteness (a few repeated exact values), which can also make a violin look “pinched”.\n",
    "\n",
    "Confirm which one it is with this quick check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = eda_top_8.query(\"rbcs_family_desc == 'Intensity Modulated Radiation Therapy'\")\n",
    "(tmp.groupby(\"Place_Of_Srvc\")\n",
    "   .agg(n=(\"log_stdzd_amt_per_service\",\"size\"),\n",
    "        nunique=(\"log_stdzd_amt_per_service\",\"nunique\"),\n",
    "        min=(\"log_stdzd_amt_per_service\",\"min\"),\n",
    "        p25=(\"log_stdzd_amt_per_service\", lambda s: s.quantile(0.25)),\n",
    "        med=(\"log_stdzd_amt_per_service\",\"median\"),\n",
    "        p75=(\"log_stdzd_amt_per_service\", lambda s: s.quantile(0.75)),\n",
    "        max=(\"log_stdzd_amt_per_service\",\"max\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277",
   "metadata": {},
   "source": [
    "With those counts, a collapsed violin is not what I would expect. We have plenty of rows in both POS groups (F: 6,929. O: 5,792) and thousands of unique values, so this is not a “small n” or “nunique=1” situation.\n",
    "\n",
    "What is happening is that the distribution is extremely concentrated in a very narrow band around ~5.80 on the log scale, especially for F:\n",
    "\t•\tF: p25 5.803, median 5.807, p75 5.808. That is an interquartile range of about 0.004.\n",
    "\t•\tO: also centered around ~5.81 but a bit wider (p25 5.778, p75 5.871), plus a longer upper tail (max 7.34).\n",
    "\n",
    "For the IMRT we should do boxplot + strip sample because the violin plot collapsed due to\n",
    "- the underlying KDE bandwidth ends up small relative to the plot scale, and\n",
    "- you have a tall, thin density spike (lots of mass at nearly the same value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=eda_top_8.query(\"rbcs_family_desc=='Intensity Modulated Radiation Therapy'\"),\n",
    "            x=\"Place_Of_Srvc\", y=\"log_stdzd_amt_per_service\")\n",
    "sns.stripplot(data=eda_top_8.query(\"rbcs_family_desc=='Intensity Modulated Radiation Therapy'\").sample(2000, random_state=0),\n",
    "              x=\"Place_Of_Srvc\", y=\"log_stdzd_amt_per_service\", alpha=0.2, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the plot output to a variable (e.g., 'ax') to capture the axes\n",
    "ax = sns.histplot(\n",
    "    data=eda_top_8,\n",
    "    y=\"rbcs_family_desc\",\n",
    "    hue=\"Place_Of_Srvc\",\n",
    "    weights=\"services\",\n",
    "    multiple=\"fill\",\n",
    "    shrink=0.8,\n",
    ")\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.ylabel(\"RBCS Family Description\")\n",
    "\n",
    "# Move the legend\n",
    "sns.move_legend(\n",
    "    ax, \n",
    "    \"upper left\", # Anchor point within the legend box\n",
    "    bbox_to_anchor=(1, 1), # Coordinates (x, y) relative to the plot area (0,0 bottom-left, 1,1 top-right)\n",
    "    title=\"Place_Of_Srvc\" # Optional: set the legend title\n",
    ")\n",
    "plt.title(\"Place of Service Proportions for Top 8 RBCS Families\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280",
   "metadata": {},
   "source": [
    "Because we used:\n",
    "- `weights=\"services\"`\n",
    "- `multiple=\"fill\"`\n",
    "\n",
    "each family’s bar is normalized to 1.0, and it answers:\n",
    "\n",
    "“For this family, what fraction of total services happened in O vs F?”\n",
    "\n",
    "This is a service-weighted POS mix plot. That is the right way to tell the “site-of-care mix” story.\n",
    "\n",
    "How to interpret it\n",
    "- If a family’s bar is almost all O, then any provider-level differences in that family’s spend are mostly happening in office settings.\n",
    "- If a family’s bar is split or mostly F, then facility settings are a big driver of that family’s utilization and potentially its spend.\n",
    "- Families like radiation treatment and planning often show more facility share, which is exactly the kind of story this plot is designed to surface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281",
   "metadata": {},
   "source": [
    "Let's do the same for the top 1% tail for the `stdzd_amt_per_service`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": [
    "(is_top_1pct_eda_df\n",
    " .groupby(\"rbcs_family_desc\", as_index=False)\n",
    " .agg(total_stdzd_spend = (\"stdzd_spend\",\"sum\"))\n",
    " .assign(pct_total_stdzd_spend = lambda x: x[\"total_stdzd_spend\"]/x[\"total_stdzd_spend\"].sum())\n",
    " .sort_values(\"total_stdzd_spend\", ascending = False)[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283",
   "metadata": {},
   "outputs": [],
   "source": [
    "(is_top_1pct_eda_df\n",
    " .groupby(\"rbcs_family_desc\", as_index=False)\n",
    " .agg(total_services = (\"services\",\"sum\"))\n",
    " .assign(pct_total_services = lambda x: x[\"total_services\"]/x[\"total_services\"].sum())\n",
    " .sort_values(\"total_services\", ascending = False)[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284",
   "metadata": {},
   "source": [
    "## EDA 6. Specialty comparisons (our 5 oncology types)\n",
    "\n",
    "**Plots**\n",
    "\n",
    "- Provider counts: n unique `Rndrng_NPI` by `provider_type` and `Year` (table)\n",
    "- Distribution: `provider_year_stdzd_amt_per_service` by `provider_type` (box)\n",
    "- Risk score distribution, `bene_avg_risk_score`, by `provider_typ`e (box)\n",
    "- `services` distribution by `provider_type` (box)\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- Are specialties fundamentally different in risk, volume, and cost intensity?\n",
    "- Does it justify including provider_type as a feature?\n",
    "- Do we need later stratified evaluation by specialty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.groupby([\"provider_type\", \"Year\"]).agg(npi_count = (\"Rndrng_NPI\", \"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxenplot(\n",
    "    data=eda_df,\n",
    "    x=\"provider_year_stdzd_amt_per_service\",\n",
    "    y=\"provider_type\",\n",
    "    hue=\"provider_type\"\n",
    ")\n",
    "\n",
    "g.set_xlabel(\"Standardized Amount per Service (Provider-Year Grain)\")\n",
    "g.set_ylabel(\"Provider Type\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.loc[eda_df.provider_year_stdzd_amt_per_service>12000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288",
   "metadata": {},
   "outputs": [],
   "source": [
    "py = (eda_df[[\"Rndrng_NPI\",\"Year\",\"provider_type\",\"provider_year_stdzd_amt_per_service\"]]\n",
    "      .drop_duplicates(subset=[\"Rndrng_NPI\",\"Year\"]))\n",
    "\n",
    "sns.boxenplot(\n",
    "    data=py,\n",
    "    x=\"provider_year_stdzd_amt_per_service\",\n",
    "    y=\"provider_type\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.sort_values(\"provider_year_stdzd_amt_per_service\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.loc[py.provider_year_stdzd_amt_per_service>=13492,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM provider_year_features\n",
    "LIMIT 2\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT tot_mdcr_stdzd_amt, tot_srvcs\n",
    "FROM provider_year_features\n",
    "WHERE\n",
    "    Rndrng_NPI=1629222450 AND Year=2022\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes\n",
    "WHERE \n",
    "    Rndrng_NPI=1629222450 \n",
    "    AND Year=2022\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM eda_dataset\n",
    "WHERE \n",
    "    Rndrng_NPI=1629222450 \n",
    "    AND Year=2022\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295",
   "metadata": {},
   "source": [
    "Let's run this to list every HCPCS row for that provider-year, ordered by volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  HCPCS_Cd,\n",
    "  HCPCS_Desc,\n",
    "  Place_Of_Srvc,\n",
    "  Tot_Srvcs,\n",
    "  Avg_Mdcr_Stdzd_Amt,\n",
    "  (Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS stdzd_spend\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes\n",
    "WHERE Rndrng_NPI = 1629222450\n",
    "  AND Year = 2022\n",
    "ORDER BY Tot_Srvcs DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297",
   "metadata": {},
   "source": [
    "Then sanity check that these HCPCS rows sum to 103:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(Tot_Srvcs) AS sum_hcpcs_services,\n",
    "  SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS sum_hcpcs_stdzd_spend\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes\n",
    "WHERE Rndrng_NPI = 1629222450\n",
    "  AND Year = 2022;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299",
   "metadata": {},
   "source": [
    "**There seems to be a mismatch here!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300",
   "metadata": {},
   "source": [
    "Let's investigate the following idea:\n",
    "\n",
    ">CMS suppression (most common)\n",
    "Many HCPCS-level rows are suppressed when beneficiary counts are small (privacy rule). Provider-year totals can still be reported even if many individual HCPCS lines are suppressed. Result: totals look big, visible HCPCS lines look incomplete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301",
   "metadata": {},
   "source": [
    "**Check 1**. Compare provider summary counts vs observable HCPCS counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  MAX(Tot_Srvcs_1) AS tot_srvcs_summary,\n",
    "  COUNT(*) AS n_hcpcs_rows_visible,\n",
    "  SUM(Tot_Srvcs) AS sum_srvcs_visible\n",
    "FROM prov_svc_onco_core_prov_all_rbcs_nppes\n",
    "WHERE Rndrng_NPI=1629222450 AND Year=2022;\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303",
   "metadata": {},
   "source": [
    "**Check 2**. Is the table inherently “partial” for many providers\n",
    "\n",
    "Pick a handful of NPIs and compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  AVG(sum_srvcs_visible * 1.0 / NULLIF(tot_srvcs_summary,0)) AS avg_visible_share\n",
    "FROM (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    MAX(Tot_Srvcs_1) AS tot_srvcs_summary,\n",
    "    SUM(Tot_Srvcs) AS sum_srvcs_visible\n",
    "  FROM prov_svc_onco_core_prov_all_rbcs_nppes\n",
    "  GROUP BY 1,2\n",
    ");\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305",
   "metadata": {},
   "source": [
    "Let's investigate the following idea\n",
    "\n",
    ">The table is filtered to an oncology-core or RBCS-mapped subset\n",
    "The table includes filtering (“onco_core”, “all_rbcs”). If the provider-year totals are coming from the broader provider summary, but the HCPCS lines are only a subset (oncology-related, mapped, or kept after joins), we will also see gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "CREATE OR REPLACE VIEW prov_svc_all_prov_all AS\n",
    "SELECT\n",
    "  ps.*,\n",
    "  p.* EXCLUDE (Rndrng_NPI, Year)\n",
    "FROM prov_svc_all AS ps\n",
    "LEFT JOIN prov_all AS p\n",
    "  ON ps.Rndrng_NPI = p.Rndrng_NPI\n",
    " AND ps.Year = p.Year;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  SUM(Tot_Srvcs) AS sum_hcpcs_services,\n",
    "  SUM(Tot_Srvcs * Avg_Mdcr_Stdzd_Amt) AS sum_hcpcs_stdzd_spend\n",
    "FROM prov_svc_all_prov_all\n",
    "WHERE Rndrng_NPI = 1629222450\n",
    "  AND Year = 2022;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT *\n",
    "FROM prov_svc_all_prov_all\n",
    "WHERE \n",
    "    Rndrng_NPI=1629222450 \n",
    "    AND Year=2022\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309",
   "metadata": {},
   "source": [
    "***Two additional checks that would make this airtight***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310",
   "metadata": {},
   "source": [
    "**Check A**: Is the missing share correlated with small benes?\n",
    "\n",
    "Suppression is usually more common when beneficiary counts are small.\n",
    "\n",
    "If suppression is the driver, avg_visible_share should be lower in the small-benes buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH py AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    MAX(Tot_Benes_1) AS tot_benes_summary,\n",
    "    MAX(Tot_Srvcs_1) AS tot_srvcs_summary,\n",
    "    SUM(Tot_Srvcs)   AS sum_srvcs_visible\n",
    "  FROM prov_svc_all_prov_all\n",
    "  GROUP BY 1, 2\n",
    "),\n",
    "bucketed AS (\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN tot_benes_summary < 11 THEN '<11'\n",
    "      WHEN tot_benes_summary < 50 THEN '11-49'\n",
    "      WHEN tot_benes_summary < 100 THEN '50-99'\n",
    "      ELSE '100+'\n",
    "    END AS benes_bucket,\n",
    "    sum_srvcs_visible * 1.0 / NULLIF(tot_srvcs_summary, 0) AS visible_share\n",
    "  FROM py\n",
    ")\n",
    "SELECT\n",
    "  benes_bucket,\n",
    "  AVG(visible_share) AS avg_visible_share,\n",
    "  APPROX_QUANTILE(visible_share, 0.10) AS p10,\n",
    "  APPROX_QUANTILE(visible_share, 0.50) AS p50,\n",
    "  APPROX_QUANTILE(visible_share, 0.90) AS p90,\n",
    "  COUNT(*) AS n_provider_years\n",
    "FROM bucketed\n",
    "GROUP BY 1\n",
    "ORDER BY\n",
    "  CASE benes_bucket\n",
    "    WHEN '<11' THEN 1\n",
    "    WHEN '11-49' THEN 2\n",
    "    WHEN '50-99' THEN 3\n",
    "    ELSE 4\n",
    "  END;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312",
   "metadata": {},
   "source": [
    "It turns out the hypothesis \"Suppression is usually more common when beneficiary counts are small.\" is false! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313",
   "metadata": {},
   "source": [
    "**Check B**: Identify how extreme this provider-year is relative to others\n",
    "\n",
    "Then check where 35/103 (~0.34) lands in that distribution. My guess is it will be in the “heavily suppressed” tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "\n",
    "\"\"\"\n",
    "WITH py AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    MAX(Tot_Srvcs_1) AS tot_srvcs_summary,\n",
    "    SUM(Tot_Srvcs) AS sum_srvcs_visible\n",
    "  FROM prov_svc_all_prov_all\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "ratio AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    sum_srvcs_visible * 1.0 / NULLIF(tot_srvcs_summary,0) AS visible_share\n",
    "  FROM py\n",
    ")\n",
    "SELECT\n",
    "  MIN(visible_share) AS min_share,\n",
    "  APPROX_QUANTILE(visible_share, 0.05) AS p05,\n",
    "  APPROX_QUANTILE(visible_share, 0.50) AS p50,\n",
    "  APPROX_QUANTILE(visible_share, 0.95) AS p95,\n",
    "  MAX(visible_share) AS max_share\n",
    "FROM ratio;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315",
   "metadata": {},
   "source": [
    "Since there is some level of suppression happening (more for the providers with less beneficiaries but more or less consistently across all beneficiary levels), we should check to see how much of this suppression is happening in our `eda_dataset`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316",
   "metadata": {},
   "source": [
    "Let’s now compute the provider-year visible_shares for the rows that actually enter`eda_dataset` after we apply filters (services ≥ 11, RBCS mapped), and see if the distribution changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317",
   "metadata": {},
   "source": [
    "1) Provider-year visible share for the provider-years that enter eda_dataset\n",
    "\n",
    "That produces one row per provider-year that actually makes it into `eda_dataset`, with `visible_share_eda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH py_eda AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    SUM(services) AS sum_srvcs_in_eda,\n",
    "    COUNT(*)      AS n_eda_rows\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "py_totals AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    tot_srvcs AS tot_srvcs_summary,\n",
    "    tot_benes AS tot_benes_summary\n",
    "  FROM provider_year_features\n",
    ")\n",
    "SELECT\n",
    "  e.Rndrng_NPI,\n",
    "  e.Year,\n",
    "  e.sum_srvcs_in_eda,\n",
    "  t.tot_srvcs_summary,\n",
    "  e.sum_srvcs_in_eda * 1.0 / NULLIF(t.tot_srvcs_summary, 0) AS visible_share_eda,\n",
    "  e.n_eda_rows,\n",
    "  t.tot_benes_summary\n",
    "FROM py_eda e\n",
    "JOIN py_totals t\n",
    "  ON e.Rndrng_NPI = t.Rndrng_NPI\n",
    " AND e.Year = t.Year\n",
    "LIMIT 60;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319",
   "metadata": {},
   "source": [
    "2) Summarize the distribution and compare to our earlier “HCPCS visible share” baseline\n",
    "\n",
    "A) Distribution for the eda_dataset provider-years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH py_eda AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    SUM(services) AS sum_srvcs_in_eda\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    e.Rndrng_NPI,\n",
    "    e.Year,\n",
    "    e.sum_srvcs_in_eda,\n",
    "    p.tot_srvcs AS tot_srvcs_summary,\n",
    "    e.sum_srvcs_in_eda * 1.0 / NULLIF(p.tot_srvcs, 0) AS visible_share_eda\n",
    "  FROM py_eda e\n",
    "  JOIN provider_year_features p\n",
    "    ON e.Rndrng_NPI = p.Rndrng_NPI\n",
    "   AND e.Year = p.Year\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_provider_years,\n",
    "  AVG(visible_share_eda) AS avg_share,\n",
    "  APPROX_QUANTILE(visible_share_eda, 0.05) AS p05,\n",
    "  APPROX_QUANTILE(visible_share_eda, 0.10) AS p10,\n",
    "  APPROX_QUANTILE(visible_share_eda, 0.50) AS p50,\n",
    "  APPROX_QUANTILE(visible_share_eda, 0.90) AS p90,\n",
    "  APPROX_QUANTILE(visible_share_eda, 0.95) AS p95\n",
    "FROM joined;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321",
   "metadata": {},
   "source": [
    "B) Side-by-side comparison: “HCPCS visible share” vs “EDA share”, but on the same provider-years\n",
    "\n",
    "This lets us see how much extra drop is coming from **our filters**, beyond CMS suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH eda_py AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    SUM(services) AS sum_srvcs_in_eda\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "hcpcs_py AS (\n",
    "  SELECT\n",
    "    Rndrng_NPI,\n",
    "    Year,\n",
    "    MAX(Tot_Srvcs_1) AS tot_srvcs_summary,\n",
    "    SUM(Tot_Srvcs)   AS sum_srvcs_visible_hcpcs\n",
    "  FROM prov_svc_all_prov_all\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    e.Rndrng_NPI,\n",
    "    e.Year,\n",
    "    h.tot_srvcs_summary,\n",
    "    h.sum_srvcs_visible_hcpcs,\n",
    "    e.sum_srvcs_in_eda,\n",
    "    h.sum_srvcs_visible_hcpcs * 1.0 / NULLIF(h.tot_srvcs_summary, 0) AS visible_share_hcpcs,\n",
    "    e.sum_srvcs_in_eda        * 1.0 / NULLIF(h.tot_srvcs_summary, 0) AS visible_share_eda\n",
    "  FROM eda_py e\n",
    "  JOIN hcpcs_py h\n",
    "    ON e.Rndrng_NPI = h.Rndrng_NPI\n",
    "   AND e.Year = h.Year\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_provider_years,\n",
    "  AVG(visible_share_hcpcs) AS avg_hcpcs_share,\n",
    "  AVG(visible_share_eda)   AS avg_eda_share,\n",
    "  APPROX_QUANTILE(visible_share_hcpcs, 0.50) AS p50_hcpcs,\n",
    "  APPROX_QUANTILE(visible_share_eda,   0.50) AS p50_eda,\n",
    "  APPROX_QUANTILE(visible_share_hcpcs, 0.90) AS p90_hcpcs,\n",
    "  APPROX_QUANTILE(visible_share_eda,   0.90) AS p90_eda\n",
    "FROM joined;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323",
   "metadata": {},
   "source": [
    "1) The `eda_dataset` provider-years have a “pretty complete” picture, on average\n",
    "\n",
    "From the `visible_share_eda` summary:\n",
    "\n",
    "- **n = 56,804 provider-years**\n",
    "- **avg_share = 0.7849**\n",
    "- **median (p50) = 0.8913**\n",
    "- **p90 = 0.9923**\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- For the provider-years that make it into `eda_dataset`, we typically observe **most** of their annual services. Median provider-year has about **89%** of services represented.\n",
    "- But there is still a left tail. **p10 = 0.3469** means 10% of provider-years only have ~35% or less of their annual services represented in `eda_dataset`. So suppression (and/or the service-line inclusion rules) still causes partial visibility for some provider-years.\n",
    "\n",
    "2) The side-by-side comparison shows us filters are not making visibility worse . If anything, they select “cleaner” provider-years\n",
    "\n",
    "we got:\n",
    "\n",
    "- **`avg_hcpcs_share` = 0.7449**\n",
    "- **`avg_eda_share` = 0.7849**\n",
    "- **`p50_hcpcs` = 0.8661**\n",
    "- **`p50_eda` = 0.8913**\n",
    "- **`p90_hcpcs` = 0.9782**\n",
    "- **`p90_eda` = 0.9922**\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- If our `eda_dataset` filtering were removing a lot of services beyond CMS suppression, we'd expect **`avg_eda_share` < `avg_hcpcs_share`**.\n",
    "- We see the opposite. `eda_share` is higher. That means the provider-years that survive into `eda_dataset` tend to be the ones where a larger portion of total services are observable at the service-line level.\n",
    "\n",
    "**The two nuances not to be missed**\n",
    "\n",
    "**Nuance A: We are conditioning on “provider-years that enter `eda_dataset`”**\n",
    "\n",
    "This is selection. We are not saying suppression is gone overall. We are saying:\n",
    "\n",
    "- “Among provider-years that pass RBCS mapping and services≥11 at the service-line grain, the visible share looks fine.”\n",
    "\n",
    "That’s good, but it also implies our modeling dataset is biased toward provider-years with:\n",
    "\n",
    "- higher volumes\n",
    "- more non-suppressed lines\n",
    "- more mappable services\n",
    "\n",
    "That might be acceptable. We just want to be aware of it.\n",
    "\n",
    "**Nuance B: Our `p95 = 1.0294` is a red flag (shares should not exceed 1)**\n",
    "\n",
    "A share above 1 can happen because:\n",
    "\n",
    "- totals and service-line counts are not strictly comparable (different definitions of “services”), or\n",
    "- duplication/leakage in joins somewhere, or\n",
    "- rounding plus approximate quantiles, but 1.03 is too high for just rounding.\n",
    "\n",
    "This does not invalidate the general pattern, but we should sanity check it.\n",
    "\n",
    "Let's run these two checks:\n",
    "\n",
    "**Check 1**: how many provider-years have share > 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH py_eda AS (\n",
    "  SELECT Rndrng_NPI, Year, SUM(services) AS sum_srvcs_in_eda\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    e.Rndrng_NPI,\n",
    "    e.Year,\n",
    "    e.sum_srvcs_in_eda,\n",
    "    p.tot_srvcs AS tot_srvcs_summary,\n",
    "    e.sum_srvcs_in_eda * 1.0 / NULLIF(p.tot_srvcs, 0) AS share\n",
    "  FROM py_eda e\n",
    "  JOIN provider_year_features p\n",
    "    ON e.Rndrng_NPI=p.Rndrng_NPI AND e.Year=p.Year\n",
    ")\n",
    "SELECT\n",
    "  SUM(CASE WHEN share > 1 THEN 1 ELSE 0 END) AS n_gt_1,\n",
    "  MAX(share) AS max_share\n",
    "FROM joined;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325",
   "metadata": {},
   "source": [
    "**Check 2**: inspect the worst offenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH py_eda AS (\n",
    "  SELECT Rndrng_NPI, Year, SUM(services) AS sum_srvcs_in_eda\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    e.Rndrng_NPI,\n",
    "    e.Year,\n",
    "    e.sum_srvcs_in_eda,\n",
    "    p.tot_srvcs AS tot_srvcs_summary,\n",
    "    e.sum_srvcs_in_eda * 1.0 / NULLIF(p.tot_srvcs, 0) AS share\n",
    "  FROM py_eda e\n",
    "  JOIN provider_year_features p\n",
    "    ON e.Rndrng_NPI=p.Rndrng_NPI AND e.Year=p.Year\n",
    ")\n",
    "SELECT *\n",
    "FROM joined\n",
    "WHERE share > 1\n",
    "ORDER BY share DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327",
   "metadata": {},
   "source": [
    "The three key facts:\n",
    "\n",
    "1. **share > 1 happens a lot**\n",
    "- 4,198 out of 56,804 provider-years (about **7.4%**) have `sum_srvcs_in_eda` > `tot_srvcs_summary`.\n",
    "2. **The maximum is exactly 2.0** (and several near 2)\n",
    "- That pattern (exactly 2x or almost 2x) is a classic signature of **systematic duplication** of service-line rows before we aggregated into `eda_dataset`.\n",
    "3. **`tot_srvcs_summary` comes from provider summary totals**, while `sum_srvcs_in_eda` comes from summing service-line rows.\n",
    "- Provider totals are not “double-counted” by joins because we used `MAX(Tot_Srvcs_1)` in the provider-year table.\n",
    "- Service-line sums can be inflated if the underlying service-line table has duplicate rows for the same “real” HCPCS line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  HCPCS_Cd,\n",
    "  Place_Of_Srvc,\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(Tot_Srvcs) AS sum_srvcs_across_rows,\n",
    "  MAX(Tot_Srvcs) AS max_srvcs_single_row\n",
    "FROM prov_svc_all_prov_all\n",
    "WHERE Rndrng_NPI = 1912087271 AND Year = 2021\n",
    "GROUP BY 1,2\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n_rows DESC, sum_srvcs_across_rows DESC\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329",
   "metadata": {},
   "source": [
    "**Quick sanity check:**\n",
    "\n",
    "we can verify that the problem is “duplication” and not something conceptual by comparing totals:\n",
    "\n",
    "**Compare provider-year totals vs our EDA service sums**\n",
    "\n",
    "If `max_diff` is very large (it likely will be for the big offenders), that reinforces this is not rounding. It is duplicated volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "WITH eda_py AS (\n",
    "  SELECT Rndrng_NPI, Year, SUM(services) AS sum_srvcs_in_eda\n",
    "  FROM eda_dataset\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n,\n",
    "  AVG(sum_srvcs_in_eda - p.tot_srvcs) AS avg_diff,\n",
    "  MAX(sum_srvcs_in_eda - p.tot_srvcs) AS max_diff\n",
    "FROM eda_py e\n",
    "JOIN provider_year_features p\n",
    "  ON e.Rndrng_NPI=p.Rndrng_NPI AND e.Year=p.Year\n",
    "WHERE sum_srvcs_in_eda > p.tot_srvcs;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331",
   "metadata": {},
   "source": [
    "Given what we just observed, the highest-probability source of duplication is our RBCS join (and much less likely the NPPES join). We should interrogate `prov_svc_onco_core_prov_all_rbcs` first, because that is exactly where a one-to-many mapping can silently replicate service-line rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332",
   "metadata": {},
   "source": [
    "Why the RBCS join is suspicious in our exact code \n",
    "\n",
    "```\n",
    "LEFT JOIN rbcs AS r\n",
    "  ON p.HCPCS_Cd = r.HCPCS_Cd\n",
    "```\n",
    "\n",
    "implicitly assumes **`rbcs.HCPCS_Cd` is unique** (one row per HCPCS code). If it is not unique, then one provider-service HCPCS row becomes 2+ rows after the join. That inflates:\n",
    "\n",
    "- `SUM(Tot_Srvcs)` when we later aggregate\n",
    "- `SUM(Avg_Mdcr_Stdzd_Amt * Tot_Srvcs)` (spend numerator)\n",
    "- and therefore can distort service-line rollups and our later `SUM(services)` in `eda_dataset`\n",
    "\n",
    "Our earlier “no duplicates” check was done on `prov_svc_all_prov_all`, which is pre-RBCS, so it is totally consistent to see no duplication there but still see duplication later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333",
   "metadata": {},
   "source": [
    "**Step 1. Let's prove whether RBCS has duplicates per HCPCS code**\n",
    "\n",
    "Let's run this first. It tells us whether our join can replicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rbcs_rows,\n",
    "  COUNT(DISTINCT HCPCS_Cd) AS distinct_hcpcs,\n",
    "  COUNT(*) - COUNT(DISTINCT HCPCS_Cd) AS extra_rows_due_to_duplicates\n",
    "FROM rbcs;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335",
   "metadata": {},
   "source": [
    "Then let's identify the worst duplicate HCPCS codes:\n",
    "\n",
    "If this returns anything, our join is one-to-many for those codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  HCPCS_Cd,\n",
    "  COUNT(*) AS n_rbcs_rows\n",
    "FROM rbcs\n",
    "GROUP BY 1\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n_rbcs_rows DESC\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337",
   "metadata": {},
   "source": [
    "**Step 2. Measure row multiplication directly: before vs after RBCS join**\n",
    "\n",
    "This is the most direct “did the join duplicate rows” check.\n",
    "\n",
    "Pick the same offender provider-year we flagged (or any). For example: Rndrng_NPI=1912087271, Year=2021.\n",
    "\n",
    "2A) Row counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338",
   "metadata": {},
   "source": [
    "If `post_rbcs` has higher row count and higher `SUM(Tot_Srvcs)`, we have confirmed duplication is introduced by RBCS join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  'pre_rbcs' AS stage,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM prov_svc_onco_core_prov_all\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'post_rbcs' AS stage,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM prov_svc_onco_core_prov_all_rbcs\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340",
   "metadata": {},
   "source": [
    "2B) Service totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  'pre_rbcs' AS stage,\n",
    "  SUM(Tot_Srvcs) AS sum_tot_srvcs\n",
    "FROM prov_svc_onco_core_prov_all\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'post_rbcs' AS stage,\n",
    "  SUM(Tot_Srvcs) AS sum_tot_srvcs\n",
    "FROM prov_svc_onco_core_prov_all_rbcs\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342",
   "metadata": {},
   "source": [
    "**Step 3. Identify the exact lines getting duplicated after the RBCS join**\n",
    "\n",
    "Let's do this by comparing the “natural key” of a provider-service line *before* RBCS, then checking how many RBCS matches it gets.\n",
    "\n",
    "A good key for our provider-service HCPCS data is usually:\n",
    "\n",
    "(Rndrng_NPI, Year, HCPCS_Cd, Place_Of_Srvc)\n",
    "\n",
    "(If we want to be extra safe, we can include `HCPCS_Drug_Ind` too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  p.HCPCS_Cd,\n",
    "  p.Place_Of_Srvc,\n",
    "  COUNT(*) AS n_post_join_rows,\n",
    "  SUM(p.Tot_Srvcs) AS sum_srvcs_post_join,\n",
    "  MAX(p.Tot_Srvcs) AS max_srvcs_single\n",
    "FROM prov_svc_onco_core_prov_all_rbcs AS p\n",
    "WHERE p.Rndrng_NPI=1912087271 AND p.Year=2021\n",
    "GROUP BY 1,2\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n_post_join_rows DESC, sum_srvcs_post_join DESC\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344",
   "metadata": {},
   "source": [
    "If we get results here but not in `prov_svc_all_prov_all`, it is basically a smoking gun.\n",
    "\n",
    "Then let's inspect one duplicated HCPCS code and see what differs across the duplicated rows (RBCS columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  Rndrng_NPI, Year, HCPCS_Cd, Place_Of_Srvc, Tot_Srvcs,\n",
    "  RBCS_FamNumb,\n",
    "  RBCS_Id,\n",
    "  RBCS_Latest_Assignment,\n",
    "  RBCS_Analysis_Start_Dt,\n",
    "  RBCS_Analysis_End_Dt,\n",
    "  Alt_Assignment_Method,\n",
    "  RBCS_Id_Ever_Reassigned\n",
    "FROM prov_svc_onco_core_prov_all_rbcs\n",
    "WHERE Rndrng_NPI=1912087271 AND Year=2021\n",
    "  AND HCPCS_Cd = '80502'\n",
    "ORDER BY RBCS_Latest_Assignment DESC, RBCS_Analysis_Start_Dt DESC;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346",
   "metadata": {},
   "source": [
    "## EDA 7. Geography and rurality patterns (without overfitting)\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. Box: stdzd_amt_per_service by state for states with enough rows\n",
    "2. Box: stdzd_amt_per_service by ruca_bucket\n",
    "3. Heatmap or grouped bars:\n",
    "    - average cost by (ruca_bucket, Place_Of_Srvc)\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- Are costs different in rural vs urban settings?\n",
    "- Does standardized amount still show residual geography effects?\n",
    "- Should we keep state and RUCA in the model? (usually yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_stats = (eda_df.groupby(\"state\")\n",
    "  .agg(n=(\"state\",\"size\"))\n",
    "  .reset_index()\n",
    ")\n",
    "\n",
    "eligible_states = state_stats.loc[state_stats[\"n\"] >= 1000, \"state\"]   # pick a threshold\n",
    "plot_df = eda_df[eda_df[\"state\"].isin(eligible_states)]\n",
    "\n",
    "# Optional: keep only top 20 by count for readability\n",
    "top_states = (state_stats[state_stats[\"state\"].isin(eligible_states)]\n",
    "              .sort_values(\"n\", ascending=False)\n",
    "              .head(20)[\"state\"])\n",
    "plot_df = eda_df[eda_df[\"state\"].isin(top_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = (plot_df.groupby(\"state\")[\"log_stdzd_amt_per_service\"]\n",
    "         .median().sort_values(ascending=False).index)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(data=plot_df, x=\"state\", y=\"log_stdzd_amt_per_service\", order=order, showfliers=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"log_stdzd_amt_per_service by state\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = eda_df.groupby(\"ruca_bucket\")[[\"stdzd_spend\",\"services\"]].sum()\n",
    "tmp[\"svc_weighted_stdzd_amt_per_service\"] = tmp[\"stdzd_spend\"] / tmp[\"services\"]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(data=eda_df,\n",
    "                x = \"ruca_bucket\",\n",
    "                y=\"log_stdzd_amt_per_service\")\n",
    "g.set_title(\"Log Standardized Amount per Service by Ruca Bucket\")\n",
    "g.set_xlabel(\"Ruca bucket\")\n",
    "g.set_ylabel(\"Log Standardized amount per service\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = eda_df.groupby([\"ruca_bucket\",\"Place_Of_Srvc\"])[[\"stdzd_spend\",\"services\"]].sum()\n",
    "heatmap_data = (g[\"stdzd_spend\"] / g[\"services\"]).unstack()\n",
    "\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\")\n",
    "plt.title(\"Service-weighted stdzd_amt_per_service by RUCA and POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mat = eda_df.pivot_table(\n",
    "    index=\"ruca_bucket\", columns=\"Place_Of_Srvc\",\n",
    "    values=\"log_stdzd_amt_per_service\", aggfunc=\"size\"\n",
    ")\n",
    "sns.heatmap(count_mat, annot=True, fmt=\"g\")\n",
    "plt.title(\"Row counts by RUCA and POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional masking of categories with less than 200 rows. \n",
    "\n",
    "# counts = eda_df.groupby([\"ruca_bucket\",\"Place_Of_Srvc\"]).size().unstack()\n",
    "# mask = counts < 200\n",
    "# sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355",
   "metadata": {},
   "source": [
    "## EDA 8. Case-mix and feature relationships (risk adjustment proof)\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. Scatter: bene_avg_risk_score vs stdzd_amt_per_service\n",
    "    - color by Place_Of_Srvc or provider_type\n",
    "2. Correlation heatmap (numeric features):\n",
    "    - bene_avg_risk_score, years_since_enumeration, p_*, log_services, log_benes, log_stdzd_amt_per_service\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- Does risk score relate to costs in plausible ways?\n",
    "- Do condition features add extra signal beyond risk score?\n",
    "- Are any features redundant or highly collinear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=eda_df,\n",
    "    x=\"log_stdzd_amt_per_service\",\n",
    "    y=\"bene_avg_risk_score\",\n",
    "    kind=\"scatter\",\n",
    "    row=\"provider_type\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=eda_df,\n",
    "    x=\"log_stdzd_amt_per_service\",\n",
    "    y=\"bene_avg_risk_score\",\n",
    "    kind=\"scatter\",\n",
    "    hue=\"provider_type\",\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=eda_df,\n",
    "    x=\"log_stdzd_amt_per_service\",\n",
    "    y=\"bene_avg_risk_score\",\n",
    "    kind=\"scatter\",\n",
    "    row=\"Place_Of_Srvc\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=eda_df,\n",
    "    x=\"log_stdzd_amt_per_service\",\n",
    "    y=\"bene_avg_risk_score\",\n",
    "    kind=\"scatter\",\n",
    "    hue=\"Place_Of_Srvc\",\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = eda_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in lst if re.findall(\"p_.\", s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in lst if re.findall(\"log_.\", s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the variables\n",
    "cols = [\n",
    "    'bene_avg_risk_score', 'years_since_enumeration', 'p_cancer6', \n",
    "    'p_diabetes', 'p_ckd', 'p_copd', 'p_htn', \n",
    "    'log_services', 'log_benes', 'log_stdzd_amt_per_service'\n",
    "]\n",
    "\n",
    "# 2. Compute the correlation matrix\n",
    "# Replace 'df' with our actual DataFrame name\n",
    "corr_matrix = eda_df[cols].corr()\n",
    "\n",
    "# 3. Create the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    annot=True,          # Show correlation values in cells\n",
    "    cmap='coolwarm',     # Use a diverging color palette (red=pos, blue=neg)\n",
    "    fmt=\".2f\",           # Format values to 2 decimal places\n",
    "    vmin=-1, vmax=1      # Set scale limits for correlation\n",
    ")\n",
    "plt.title('Correlation (Pearson) Heatmap of Beneficiary Risk and Service Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the variables\n",
    "cols = [\n",
    "    'bene_avg_risk_score', 'years_since_enumeration', 'p_cancer6', \n",
    "    'p_diabetes', 'p_ckd', 'p_copd', 'p_htn', \n",
    "    'log_services', 'log_benes', 'log_stdzd_amt_per_service'\n",
    "]\n",
    "\n",
    "# 2. Compute the correlation matrix\n",
    "# Replace 'df' with our actual DataFrame name\n",
    "corr_matrix = eda_df[cols].corr(method=\"spearman\")\n",
    "\n",
    "# 3. Create the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    annot=True,          # Show correlation values in cells\n",
    "    cmap='coolwarm',     # Use a diverging color palette (red=pos, blue=neg)\n",
    "    fmt=\".2f\",           # Format values to 2 decimal places\n",
    "    vmin=-1, vmax=1      # Set scale limits for correlation\n",
    ")\n",
    "plt.title('Correlation (Spearman) Heatmap of Beneficiary Risk and Service Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365",
   "metadata": {},
   "source": [
    "#### **Investigating the standardized cost per service within `eda_df` quantiles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1(s): return s.quantile(0.01)\n",
    "def q5(s): return s.quantile(0.05)\n",
    "def q90(s): return s.quantile(0.90)\n",
    "def p95(s): return s.quantile(0.95)\n",
    "def p99(s): return s.quantile(0.99)\n",
    "\n",
    "eda_df[[\"stdzd_amt_per_service\", \"log_stdzd_amt_per_service\"]].agg(\n",
    "    [\"mean\", \"min\", q1, q5, \"median\", q90, p95, p99, \"max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367",
   "metadata": {},
   "source": [
    "> *Notice: the `log_stdzd_amt_per_service` jumped from ~6.4 to ~10.6 when we go from 99th percentile to max value. This tells us that the top 1% slice has abnormally high log standardized cost per service. We must further characterize the top 1%.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368",
   "metadata": {},
   "source": [
    "**One extra check before finalizing the EDA choice**\n",
    "\n",
    "Because the `max` is so high, it’s worth confirming whether the top tail is driven by:\n",
    "\n",
    "- tiny denominators (services=11 but big spend), or\n",
    "- specific codes / POS, or\n",
    "- data artifacts.\n",
    "\n",
    "A quick diagnostic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.assign(\n",
    "    is_top_1pct = eda_df[\"stdzd_amt_per_service\"] >= eda_df[\"stdzd_amt_per_service\"].quantile(0.99)\n",
    ").groupby(\"is_top_1pct\").agg(\n",
    "    n=(\"stdzd_amt_per_service\",\"size\"),\n",
    "    med_services=(\"services\",\"median\"),\n",
    "    med_std=(\"stdzd_amt_per_service\",\"median\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370",
   "metadata": {},
   "source": [
    "**What this check tells us**\n",
    "\n",
    "1) The extreme tail is real and it is meaningfully different, not just “a few giant values.”\n",
    "- Bottom 99%: median `stdzd_amt_per_service` ≈ `70.3`\n",
    "- Top 1%: median `stdzd_amt_per_service` ≈ `736.7`\n",
    "\n",
    "That is roughly a 10x jump in the typical value inside the top 1%.\n",
    "\n",
    "2) The top 1% tends to occur when service volume is smaller.\n",
    "- Bottom 99%: median services = `142`\n",
    "- Top 1%: median services = `41`\n",
    "\n",
    "This pattern is consistent with “high cost per service often shows up in lower-volume lines,” which is plausible in claims data (rare codes, expensive drugs, certain settings). It also means those points can dominate plots on the raw scale even though they are only 1% of rows.\n",
    "\n",
    "3) It argues against trimming for EDA.\n",
    "If we trimmed (dropped) the top 1%, we would remove 3,184 rows that likely represent a real, high-cost segment. That can bias descriptive patterns. Winsorization keeps them but stops them from flattening our visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371",
   "metadata": {},
   "source": [
    "#### **Let's explicitly do tail analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372",
   "metadata": {},
   "source": [
    "1. **Tail composition. Who is in the tail?**\n",
    "\n",
    "Make the tail interpretable by breaking it down by:\n",
    "\n",
    "- `rbcs_family_desc`\n",
    "- `Place_Of_Srvc`\n",
    "- `provider_type\n",
    "- `state` (or `ruca_bucket`)\n",
    "- `svc_bucket`\n",
    "\n",
    "Do it in three ways because they answer different questions:\n",
    "\n",
    "- **Row share**: “where do tail rows occur”\n",
    "- **Service-weighted**: “where does tail volume sit”\n",
    "- **Spend-weighted**: “where does tail money sit”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"rbcs_family_desc\", as_index=False)\n",
    "           .agg(n_rows=(\"rbcs_family_desc\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"Place_Of_Srvc\", as_index=False)\n",
    "           .agg(n_rows=(\"Place_Of_Srvc\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"provider_type\", as_index=False)\n",
    "           .agg(n_rows=(\"provider_type\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"state\", as_index=False)\n",
    "           .agg(n_rows=(\"state\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"ruca_bucket\", as_index=False)\n",
    "           .agg(n_rows=(\"ruca_bucket\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = eda_df[eda_df[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "base = eda_df\n",
    "\n",
    "summary = (tail.groupby(\"svc_bucket\", as_index=False)\n",
    "           .agg(n_rows=(\"svc_bucket\",\"size\"),\n",
    "                services=(\"services\",\"sum\"),\n",
    "                spend=(\"stdzd_spend\",\"sum\"))\n",
    "           .assign(pct_tail_rows=lambda d: d[\"n_rows\"]/len(tail),\n",
    "                   pct_all_rows=lambda d: d[\"n_rows\"]/len(base),\n",
    "                   pct_tail_services=lambda d: d[\"services\"]/tail[\"services\"].sum(),\n",
    "                   pct_tail_spend=lambda d: d[\"spend\"]/tail[\"stdzd_spend\"].sum())\n",
    "           .sort_values(\"spend\", ascending=False)\n",
    "           .head(20))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379",
   "metadata": {},
   "source": [
    "2. **Tail vs non-tail comparisons on key features**\n",
    "\n",
    "A simple “tail profiling” table is very persuasive:\n",
    "- median risk score\n",
    "- median services, benes\n",
    "- POS mix\n",
    "- rurality mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby(\"is_top_1pct_stdzd_amt_per_service\", as_index=False)\n",
    " .agg(\n",
    "     median_risk_score = (\"bene_avg_risk_score\", \"median\"),\n",
    "     median_services   = (\"services\", \"median\"),\n",
    "     median_benes      = (\"benes\", \"median\")\n",
    "\n",
    " ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby([\"is_top_1pct_stdzd_amt_per_service\",\"Place_Of_Srvc\"], as_index=False)\n",
    " .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby([\"is_top_1pct_stdzd_amt_per_service\",\"ruca_bucket\"], as_index=False)\n",
    " .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in eda_df.columns if re.findall(\"p_\", s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df\n",
    " .groupby(\"is_top_1pct_stdzd_amt_per_service\", as_index=False)\n",
    " .agg(\n",
    "     cancer     = (\"p_cancer6\", \"mean\"),\n",
    "     diabetes   = (\"p_diabetes\", \"mean\"),\n",
    "     ckd        = (\"p_ckd\", \"mean\"),\n",
    "     copd       = (\"p_copd\", \"mean\"),\n",
    "     htn        = (\"p_htn\", \"mean\")\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385",
   "metadata": {},
   "source": [
    "## **EDA 9. Tail verification + modeling guardrails**\n",
    "\n",
    "**Plots**\n",
    "\n",
    "1. One header table. Size and impact of the tail under reliability thresholds: counts and spend share by tail flag x volume bucket\n",
    "2. Tail composition tables. Who shows up in the tail, by key categories: tail enrichment by `rbcs_family_desc`, `Place_Of_Service`, `provider_type`, `state`, and `ruca_bucket`\n",
    "3. Outlier table. A small “human inspection” sample that is high-confidence: tail rows with `services >= 50` sorted by either `stdzd_amt_per_service` (extremity) and `stdzd_spend` (impact)\n",
    "\n",
    "**Questions answered**\n",
    "\n",
    "- What is the tail made of? Is it real? How big is it?\n",
    "- Within the tail, are there patterns that indicate data artifacts, low-reliability noise, or a small number of scenarios that should be treated differently (or at least evaluated differently)?\n",
    "\n",
    "Given our findings (top 1% has median services ~41, and tail spend share is only ~1.7% while services share is ~1.1%), let's make EDA 9 compact and high value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386",
   "metadata": {},
   "source": [
    "**A. One header table. Size and impact of the tail under reliability thresholds:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eda_df.\n",
    " groupby([\"is_top_1pct_stdzd_amt_per_service\", \"svc_bucket\"])\n",
    " .agg(\n",
    "     n_rows = (\"services\",\"size\"),\n",
    "     total_services = (\"services\", \"sum\"),\n",
    "     total_spend = (\"stdzd_spend\",\"sum\"),\n",
    "     med_cost = (\"stdzd_amt_per_service\",\"median\"),\n",
    "     p95_cost = (\"stdzd_amt_per_service\", lambda s: s.quantile(0.95))\n",
    " )\n",
    " .assign(\n",
    "     spend_per_service=lambda d: d[\"total_spend\"] / d[\"total_services\"],\n",
    "     spend_per_row=lambda d: d[\"total_spend\"] / d[\"n_rows\"],\n",
    "     pct_services = lambda d: d[\"total_services\"] / d[\"total_services\"].sum(),\n",
    "     pct_spend = lambda d: d[\"total_spend\"] / d[\"total_spend\"].sum()\n",
    " )\n",
    " .sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388",
   "metadata": {},
   "source": [
    "**What the table is really saying**\n",
    "\n",
    "1) The “mass of the dataset” is high-volume, low-cost-per-service\n",
    "\n",
    "- Look at non-tail, 500+:\n",
    "- pct_services = 0.9728 (97.3% of all services)\n",
    "- pct_spend = 0.8462 (84.6% of all standardized spend)\n",
    "- spend_per_service = 14.23\n",
    "- med_cost = 31.22\n",
    "\n",
    "So our dataset is dominated by very high-volume rows that are cheap per service. That is not a bug. It is a core reality of the data, and it will strongly influence model learning.\n",
    "\n",
    "Big takeaway: most rows represent “routine, high-throughput stuff.”\n",
    "\n",
    "2) Our tail rows are genuinely high cost per service in every volume bucket\n",
    "\n",
    "Compare spend_per_service tail vs non-tail in each bucket:\n",
    "\n",
    "- 11–25: 1103 vs 124 (about 9x)\n",
    "- 25–50: 1168 vs 125 (about 9x)\n",
    "- 50–100: 1184 vs 108 (about 11x)\n",
    "- 100–500: 775 vs 73 (about 11x)\n",
    "- 500+: 732 vs 14 (about 52x)\n",
    "\n",
    "This is the most important conclusion from this table.\n",
    "\n",
    "The tail is not “a small denominator artifact.” Even when services are huge (500+), tail rows remain massively more expensive per service.\n",
    "\n",
    "3) Tail is small in total business terms, but not trivial\n",
    "\n",
    "From your earlier rollup (and consistent here):\n",
    "\n",
    "- Tail is about 1.7% of total spend and about 1.1% of total services overall.\n",
    "\n",
    "Now we can also see where tail spend is coming from:\n",
    "Tail pct_spend by bucket:\n",
    "\n",
    "- 11–25: 0.1148%\n",
    "- 25–50: 0.2203%\n",
    "- 50–100: 0.3347%\n",
    "- 100–500: 0.7150% (largest)\n",
    "- 500+: 0.3461%\n",
    "\n",
    "So tail spend contribution is mostly 100–500, with meaningful contributions from 50–100 and 500+. Low-volume buckets contribute the least.\n",
    "\n",
    "4) spend_per_row tells we “business impact per row,” and it explains why 500+ matters\n",
    "\n",
    "Within each group, spend_per_row rises with services, as expected.\n",
    "\n",
    "For example, tail rows:\n",
    "\n",
    "- 11–25: ~17K spend per row\n",
    "- 25–50: ~42K\n",
    "- 50–100: ~83K\n",
    "- 100–500: ~159K\n",
    "- 500+: ~632K\n",
    "\n",
    "Interpretation: even though there are only 83 tail rows in 500+, each of those rows represents a lot of dollars. So high-volume tail rows are the “high-impact” ones, even if they are rare.\n",
    "\n",
    "5) The subtle but important pattern in non-tail\n",
    "\n",
    "Non-tail spend_per_service drops hard as volume increases:\n",
    "\n",
    "- 11–25: 124\n",
    "- 25–50: 125\n",
    "- 50–100: 108\n",
    "- 100–500: 73\n",
    "- 500+: 14\n",
    "\n",
    "That suggests the high-volume rows tend to be dominated by low-cost-per-service families (we already saw this with RBCS_FamNumb='000' injections and other high-throughput items). This is a dataset composition story, not an arithmetic artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389",
   "metadata": {},
   "source": [
    "> Across every service-volume bucket, top-1% cost rows have much higher standardized spend per service (roughly 9–11x in low-to-mid volume and over 50x in 500+ volume), indicating the tail reflects real high-intensity service lines rather than low-volume noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390",
   "metadata": {},
   "source": [
    "B) Tail composition tables. Who shows up in the tail, by key categories\n",
    "\n",
    "Let's do these as “tail vs overall” shares. Do not do a million plots.\n",
    "\n",
    "Table B1: tail enrichment by `rbcs_family_desc` (we already did) We'll keep it. It is our main “tail is concentrated in these families” proof.\n",
    "\n",
    "Add Table B2–B4: same idea but for POS, specialty, geography\n",
    "\n",
    "These are cheap and very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_enrichment_by(cat):\n",
    "    d = eda_df.copy()\n",
    "    tot_all = d[\"stdzd_spend\"].sum()\n",
    "    tot_tail = d.loc[d[\"is_top_1pct_stdzd_amt_per_service\"], \"stdzd_spend\"].sum()\n",
    "\n",
    "    all_ = d.groupby(cat, as_index=False).agg(spend_all=(\"stdzd_spend\",\"sum\"))\n",
    "    tail_ = (d.loc[d[\"is_top_1pct_stdzd_amt_per_service\"]]\n",
    "               .groupby(cat, as_index=False)\n",
    "               .agg(spend_tail=(\"stdzd_spend\",\"sum\")))\n",
    "\n",
    "    out = (all_.merge(tail_, on=cat, how=\"left\")\n",
    "             .assign(\n",
    "                 spend_tail=lambda x: x[\"spend_tail\"].fillna(0.0),\n",
    "                 overall_share=lambda x: x[\"spend_all\"]/tot_all,\n",
    "                 tail_share=lambda x: np.where(tot_tail>0, x[\"spend_tail\"]/tot_tail, np.nan),\n",
    "                 enrichment=lambda x: x[\"tail_share\"]/x[\"overall_share\"],\n",
    "                 pct_spend_in_tail=lambda x: np.where(x[\"spend_all\"]>0, x[\"spend_tail\"]/x[\"spend_all\"], np.nan),\n",
    "             )\n",
    "             .sort_values(\"enrichment\", ascending=False))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392",
   "metadata": {},
   "source": [
    "These computed columns mean:\n",
    "\n",
    "- `overall_share` = category’s share of all spend\n",
    "- `tail_share` = category’s share of tail spend only\n",
    "- `enrichment` = tail_share / overall_share\n",
    "    - 1 means “overrepresented in the tail (by spend)”\n",
    "    - < 1 means “underrepresented in the tail (by spend)”\n",
    "- `pct_spend_in_tail` = fraction of that category’s spend that sits in the tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_enrichment_by(\"Place_Of_Srvc\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394",
   "metadata": {},
   "source": [
    "- `O` (Office): `enrichment` 1.056 (slightly overrepresented)\n",
    "- `F` (Facility): `enrichment` 0.601 (underrepresented)\n",
    "\n",
    "Takeaways:\n",
    "- Tail spend is **a bit more office-weighted** than the overall spend mix.\n",
    "- But this is not a huge effect. It is “directional,” not a dominant story.\n",
    "- POS is still worth keeping as a feature.\n",
    "- But POS alone is not explaining the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_enrichment_by(\"provider_type\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396",
   "metadata": {},
   "source": [
    "- `Surgical Oncology`: 5.83x\n",
    "- `Gynecological Oncology`: 4.82x\n",
    "- `Radiation Oncology`: 1.39x\n",
    "- `Hematology-Oncology`: 0.76x\n",
    "- `Medical Oncology`: 0.75x\n",
    "\n",
    "Also notice `pct_spend_in_tail`:\n",
    "\n",
    "- `Surgical Oncology`: 10.1% of its spend is in the tail (very high relative to the global tail share, which is ~1.7%).\n",
    "- `Gynecological Oncology`: 8.3% in tail.\n",
    "- `Radiation Oncology`: 2.4% in tail.\n",
    "- `Hematology-Oncology` and `Medical Oncology`: about 1.3% in tail.\n",
    "\n",
    "Takeaways\n",
    "\n",
    "- Tail spend is **strongly enriched** in `Surgical Oncology` and `Gynecological Oncology`.\n",
    "- `Radiation Oncology` is modestly enriched.\n",
    "- `Hematology-Oncology` and `Medical Oncology` are underrepresented in the tail relative to their huge baseline spend share.\n",
    "- This is one of the strongest modeling signals you have found so far.\n",
    "- It argues for:\n",
    "    - Keeping `provider_type` in the model (clearly).\n",
    "    - Considering stratified evaluation by specialty (because the tail behaves differently by specialty).\n",
    "    - Being cautious with global thresholds for “over-expected.” A single rule may be unfair across specialties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_enrichment_by(\"ruca_bucket\").head(20)\n",
    "# (state is fine too, but do top states only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398",
   "metadata": {},
   "source": [
    "- `Urban`: enrichment 1.02 (basically neutral)\n",
    "- `Suburban`: enrichment 0.62\n",
    "- `Rural`: enrichment 0.29\n",
    "- `Unknown`: no tail spend\n",
    "\n",
    "Takeaways\n",
    "\n",
    "- Tail spend is mostly urban, but that is also because nearly all spend is urban. The enrichment is basically 1.\n",
    "- Rural and Suburban are underrepresented in tail spend.\n",
    "- RUCA may matter for baseline differences, but it is not the headline driver of the tail.\n",
    "- Still worth keeping RUCA in the model, but don’t oversell “rural vs urban” as an explanation for the extreme tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_enrichment_by(\"rbcs_family_desc\").head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400",
   "metadata": {},
   "source": [
    "1) Two different questions are mixed in one table\n",
    "\n",
    "A. “What drives the tail (in dollars)?”\n",
    "\n",
    "For that, ignore enrichment at first. Look at tail_share or spend_tail.\n",
    "\n",
    "From your output, the tail is dominated by a few families:\n",
    "\n",
    "- `PET- Oncology`\n",
    "    - tail_share = 0.5808 means ~58.1% of all tail spend is PET.\n",
    "    - pct_spend_in_tail = 0.4501 means ~45.0% of PET’s total spend lives in the tail.\n",
    "\n",
    "- `Injection - Colony Stimulating Factors`\n",
    "    - tail_share = 0.1689 means ~16.9% of tail spend.\n",
    "    - pct_spend_in_tail = 0.1251 means ~12.5% of its spend lives in the tail.\n",
    "\n",
    "- `No RBCS Family`\n",
    "    - tail_share = 0.1021 means ~10.2% of tail spend.\n",
    "\n",
    "- Next tier (still meaningful dollars):\n",
    "    - `Intensity Modulated Radiation Therapy`: tail_share = 0.0484 (about 4.8%)\n",
    "    - `Conventional Radiation Treatment`: tail_share = 0.0348 (about 3.5%)\n",
    "    - `Chemotherapeutic Agent`: tail_share = 0.0263 (about 2.6%)\n",
    "\n",
    "Just those are already roughly:\n",
    "58.1 + 16.9 + 10.2 + 4.8 + 3.5 + 2.6 ≈ 96% of tail spend (ballpark, based on the lines shown)\n",
    "\n",
    "***That’s your main storyline: the tail is not diffuse. It is concentrated in a handful of families.***\n",
    "\n",
    "B. “Which families are disproportionately represented in the tail?”\n",
    "\n",
    "That is what enrichment answers. But enrichment can be misleading when the family is tiny overall.\n",
    "\n",
    "Example:\n",
    "- `Vascular Embolization enrichment` ~57, `pct_spend_in_tail` ~0.99\n",
    "- True statement: “When embolization appears, it is almost always in the tail.”\n",
    "- But it is only spend_all ≈ 6e5, so it is not a big contributor to overall spend or tail spend.\n",
    "So for decision-making, treat enrichment like this:\n",
    "    - High enrichment + big tail spend = important\n",
    "    - High enrichment + tiny spend = interesting edge case, not a driver\n",
    "\n",
    "2) What this reveals and whether it matches expectations\n",
    "\n",
    "Yes, it reveals what we were trying to learn:\n",
    "\n",
    "- The tail is structurally real and interpretable, not random noise.\n",
    "- Family mix is the primary driver of tail composition.\n",
    "- Some high-cost procedure families are “tail heavy” (high enrichment, high `pct_spend_in_tail`).\n",
    "- Some massive families like `Chemotherapeutic Agent` have huge overall spend, but are underrepresented in the tail (`enrichment` = 0.11, `pct_spend_in_tail` = 0.19%).\n",
    "\n",
    "That suggests chemo spend is large because of volume and baseline price, not because it generates many extreme per-service outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401",
   "metadata": {},
   "source": [
    "3) Modeling implications\n",
    "\n",
    "A. Keep `rbcs_family_desc` (or `RBCS_FamNumb`) as a core feature\n",
    "\n",
    "The tail behavior is strongly family-specific. Without this feature, the model will blend very different price regimes.\n",
    "\n",
    "B. Expect interactions\n",
    "\n",
    "The combination of:\n",
    "\n",
    "- `rbcs_family_desc` + `provider_type` + `Place_Of_Srvc`\n",
    "    \n",
    "    is likely where a lot of the signal lives, especially for the tail-heavy families (PET, colony stimulating factors, certain procedures).\n",
    "    \n",
    "\n",
    "C. Consider “two-stage thinking” even if we train one model\n",
    "\n",
    "We do not have to literally build two models, but conceptually:\n",
    "\n",
    "- Stage 1: baseline expected cost by family/POS/specialty/risk\n",
    "- Stage 2: residual variation within family (provider-level effects)\n",
    "\n",
    "This helps we avoid treating PET-like price structure as “outliers” when they are simply a different regime.\n",
    "\n",
    "D. Winsorization is still optional for training, helpful for plots\n",
    "\n",
    "Given our earlier result that the tail is only ~1.7% of spend and ~1.1% of services, we can:\n",
    "\n",
    "- keep raw values for modeling (especially if using log outcome),\n",
    "- use clipped plots (p99) for readability in EDA.\n",
    "\n",
    "\n",
    "\n",
    "4) One improvement to make your narrative bulletproof\n",
    "\n",
    "Right now we are sorting by enrichment, which is great for “overrepresented.” But for storytelling and prioritization we should present **two companion tables**:\n",
    "\n",
    "1. Top families by `spend_tail` or `tail_share`\n",
    "    \n",
    "    (answers: what actually drives tail dollars)\n",
    "    \n",
    "2. Top families by enrichment with a minimum size filter\n",
    "    \n",
    "    Example filter: `overall_share` >= 0.001 or `spend_all` >= 1e7\n",
    "    \n",
    "    (answers: what is disproportionately tail-heavy among meaningful families)\n",
    "    \n",
    "\n",
    "This prevents “tiny but extreme” families from stealing attention.\n",
    "\n",
    "If we want a simple rule:\n",
    "\n",
    "- Use enrichment ranking only after filtering to families with at least, say, **0.1% of total spend**.\n",
    "\n",
    "\n",
    "\n",
    "5) Concrete take-home messages we can write in the notebook\n",
    "\n",
    "- “The top 1% cost-per-service tail is not random. It is concentrated in specific RBCS families.”\n",
    "- “PET- Oncology alone accounts for ~58% of tail spend, followed by Colony Stimulating Factors (~17%) and No RBCS Family (~10%).”\n",
    "- “Several rare procedure families are almost entirely tail spend when they occur, but they contribute little total dollars overall.”\n",
    "- “This supports keeping service family in the model and evaluating performance within the tail-heavy families.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_enrichment_by(\"rbcs_family_desc\").sort_values(\"spend_tail\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403",
   "metadata": {},
   "source": [
    "**What drives tail spend (in dollars)**\n",
    "\n",
    "Our top 20 by `spend_tail` shows a very sharp concentration:\n",
    "\n",
    "1) The tail is overwhelmingly a PET story, then a small handful of families\n",
    "- `PET- Oncology`: `tail_share` = 0.5808\n",
    "    - About 58% of all tail spend comes from PET alone. Also, `pct_spend_in_tail` = 0.4501, meaning 45% of all PET spend sits in the tail. This is both a major tail driver and truly tail-heavy.\n",
    "\n",
    "- `Injection - Colony Stimulating Factors`: `tail_share` = 0.1689\n",
    "    - About 17% of tail spend. `pct_spend_in_tail` = 0.1251 (still meaningfully tail-heavy).\n",
    "\n",
    "- `No RBCS Family`: `tail_share` = 0.1021\n",
    "    - About 10% of tail spend, but only 4.2% of that family’s spend is tail. So it drives tail dollars mostly because it is big overall, not because it is unusually tail-heavy.\n",
    "\n",
    "- Next tier:\n",
    "    - `Intensity Modulated Radiation Therapy`: ~4.8% of tail spend (`pct_spend_in_tail` ~1.0%)\n",
    "    - `Conventional Radiation`: ~3.5% (`pct_spend_in_tail` ~0.6%)\n",
    "    - `Chemotherapeutic Agent`: ~2.6% (`pct_spend_in_tail` ~0.2%)\n",
    "\n",
    "2) A “top 6 families” summary is defensible and strong\n",
    "\n",
    "Just the first six rows:\n",
    "- PET (58.1%)\n",
    "- Colony Stim factors (16.9%)\n",
    "- No RBCS Family (10.2%)\n",
    "- IMRT (4.8%)\n",
    "- Conventional RT (3.5%)\n",
    "- Chemo agent (2.6%)\n",
    "\n",
    "Sum: 58.1 + 16.9 + 10.2 + 4.8 + 3.5 + 2.6 = 96.1% of tail spend (using our printed `tail_shares`).\n",
    "\n",
    "That is a very crisp take-home message.\n",
    "\n",
    "\n",
    "**The “why” behind the pattern**\n",
    "\n",
    "A. Two mechanisms are happening at the same time\n",
    "\n",
    "1. Families that are intrinsically tail-heavy\n",
    "\n",
    "- PET- Oncology (45% of spend in tail)\n",
    "- Injection - Clotting Factors (37% of spend in tail, though smaller dollars)\n",
    "- Mastectomy (22% of spend in tail)\n",
    "- Vascular Embolization (99% in tail, but tiny dollars)\n",
    "\n",
    "2.\tFamilies that are huge overall and therefore contribute some tail dollars even if they are not tail-heavy\n",
    "\n",
    "- Chemo, IMRT, Conventional RT, No RBCS Family\n",
    "These have low `pct_spend_in_tail`, but because their spend_all is enormous, they still contribute meaningful tail spend.\n",
    "\n",
    "This distinction is exactly what our columns enable:\n",
    "- Use tail_share for “tail dollars”\n",
    "- Use `pct_spend_in_tail` and enrichment for “tail intensity”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404",
   "metadata": {},
   "source": [
    "**Finally, let's create a compact table for the top 10 by tail spend with just:**\n",
    "\n",
    "- `rbcs_family_desc`\n",
    "- `tail_share`\n",
    "- `pct_spend_in_tail`\n",
    "- `enrichment`\n",
    "- `spend_tail` (maybe as $M)\n",
    "\n",
    "That one table becomes our single slide or single notebook cell that explains the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_tbl = (\n",
    "    tail_enrichment_by(\"rbcs_family_desc\")\n",
    "    .sort_values(\"spend_tail\", ascending=False)\n",
    "    .loc[:, [\"rbcs_family_desc\", \"tail_share\", \"pct_spend_in_tail\", \"enrichment\", \"spend_tail\"]]\n",
    "    .head(10)\n",
    "    .assign(spend_tail_m=lambda d: d[\"spend_tail\"] / 1e6)\n",
    ")\n",
    "\n",
    "tail_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_tbl_round = tail_tbl.assign(\n",
    "    tail_share=lambda d: d[\"tail_share\"].round(3),\n",
    "    pct_spend_in_tail=lambda d: d[\"pct_spend_in_tail\"].round(3),\n",
    "    enrichment=lambda d: d[\"enrichment\"].round(2),\n",
    "    spend_tail_m=lambda d: d[\"spend_tail_m\"].round(1),\n",
    ").drop(columns=[\"spend_tail\"])\n",
    "\n",
    "tail_tbl_round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407",
   "metadata": {},
   "source": [
    "**What each column means**\n",
    "\n",
    "- `tail_share`\n",
    "    - Within the tail only (top 1% by stdzd_amt_per_service), what fraction of tail dollars come from this family.\n",
    "        - Example: PET- Oncology = 0.581 means 58.1% of all tail spend comes from PET.\n",
    "\n",
    "- `pct_spend_in_tail`\n",
    "    - Within this family’s own total spend, what fraction is contributed by tail rows.\n",
    "        - Example: Vascular Embolization = 0.991 means 99.1% of embolization spend is in tail rows (for our definition of tail).\n",
    "\n",
    "- `enrichment`\n",
    "    - How “overrepresented” the family is in the tail relative to overall.\n",
    "    - It is essentially: `(tail_share / overall_share)`.\n",
    "        - Example: PET- Oncology enrichment 26.00 means PET makes up a much larger share of tail spend than it does of total spend.\n",
    "\n",
    "- `spend_tail_m`\n",
    "    - Tail spend for that family, in $ millions.\n",
    "\n",
    "All of these are internally consistent with the earlier outputs we showed.\n",
    "\n",
    "**What our specific results say**\n",
    "\n",
    "1) The tail is not broad. It is dominated by a few families.\n",
    "\n",
    "If we sum the `tail_share` in our top 10:\n",
    "\n",
    "0.581 + 0.169 + 0.102 + 0.048 + 0.035 + 0.026 + 0.016 + 0.013 + 0.004 + 0.002\n",
    "= 0.996 (about 99.6% of tail spend)\n",
    "\n",
    "So basically, the top 10 families explain almost the entire tail. That is exactly the kind of clean narrative we want.\n",
    "\n",
    "2) PET- Oncology is the main tail story.\n",
    "- $152.3M of tail spend.\n",
    "- 58.1% of tail spend.\n",
    "- Enrichment 26x means it is massively overrepresented in tail dollars.\n",
    "\n",
    "This strongly suggests our tail is not “random weirdness.” It is a real phenomenon concentrated in certain service families.\n",
    "\n",
    "3) “High enrichment” and “high tail spend” are different concepts. You have both.\n",
    "- High tail spend families: PET, Colony Stimulating Factors, No RBCS Family, IMRT, Conventional Radiation.\n",
    "- Highest enrichment families (even if small dollars): Vascular Embolization, Injection Clotting Factors, PET, Mastectomy.\n",
    "\n",
    "Those tiny-dollar but huge-enrichment families are still important because they tell we, “when this family appears, it is often expensive per service.”\n",
    "\n",
    "4) Some large-spend families are actually underrepresented in the tail.\n",
    "- Chemotherapeutic Agent: enrichment 0.11, pct_spend_in_tail 0.002.\n",
    "That means chemo drives lots of overall spend, but it is not usually in our extreme cost-per-service tail. It is a different cost story.\n",
    "- IMRT and Conventional Radiation also have enrichment < 1, meaning they are not tail-heavy relative to their overall footprint, even though they contribute meaningful tail dollars.\n",
    "\n",
    "**Modeling implications**\n",
    "\n",
    "Keep the tail. Do not winsorize for training.\n",
    "\n",
    "Your table screams “structured tail,” not noise.\n",
    "- Tail rows are systematically linked to specific families and POS patterns.\n",
    "- If we clip them for training, we will erase real signal and bias the model toward “average-only” behavior.\n",
    "\n",
    "But for visuals and simple comparisons, we can use a plot-only clip\n",
    "\n",
    "Two-track approach:\n",
    "- Modeling outcome: `log_stdzd_amt_per_service` (no clipping)\n",
    "- EDA plots: optionally show a second version clipped at p99 or p99.5 for readability, clearly labeled “clipped for display only.”\n",
    "\n",
    "Consider adding a simple “tail-prone family” indicator for diagnostics\n",
    "\n",
    "Not necessarily as a final feature, but as a quick check:\n",
    "- a flag like `is_tail_enriched_family` for the top few enrichment families (PET, clotting factors, etc.)\n",
    "\n",
    "This helps we confirm that residuals and errors behave differently in these families.\n",
    "\n",
    "One sentence narrative:\n",
    "\n",
    "> “The cost-per-service tail is highly structured: the top 10 RBCS families explain ~99.6% of tail spend, led by PET-Oncology alone at ~$152M (58% of tail dollars), with several families showing extreme tail concentration (e.g., embolization has ~99% of its spend in tail rows).”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408",
   "metadata": {},
   "source": [
    "## EDA 10. Modeling readiness summary (what EDA implies)\n",
    "\n",
    "This section locks the modeling decisions implied by EDA. It serves as a contract for what will be trained, how it will be evaluated, and how “flagging” will be interpreted.\n",
    "\n",
    "**Dataset grain (unit of analysis):** provider-year-RBCS family-place of service.\n",
    "\n",
    "We explicitly separate:\n",
    "- **Training inclusion rules** (coverage + stability)\n",
    "- **Post-model flagging rules** (higher confidence, higher volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409",
   "metadata": {},
   "source": [
    "10.1 Objective, unit of prediction, and target\n",
    "\n",
    "**Goal:** predict expected cost intensity per service for each provider-year-family-POS slice, adjusting for case-mix and context.\n",
    "\n",
    "**Unit of prediction (row grain):**\n",
    "- Provider (`Rndrng_NPI`)\n",
    "- Year (`Year`)\n",
    "- Service family (`RBCS_FamNumb` / `rbcs_family_desc`)\n",
    "- Place of service (`Place_Of_Srvc`)\n",
    "\n",
    "**Final modeling target:**\n",
    "- `y = log1p(stdzd_amt_per_service)` (i.e., `log_stdzd_amt_per_service`)\n",
    "\n",
    "**Why log target:**\n",
    "- Raw `stdzd_amt_per_service` is heavy-tailed. Log transform stabilizes training while preserving rank and relative differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "target_decision = pd.DataFrame({\n",
    "    \"Decision\": [\n",
    "        \"Outcome for reporting\",\n",
    "        \"Modeling target\",\n",
    "        \"Justification\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        \"stdzd_amt_per_service (raw, $/service)\",\n",
    "        \"log1p(stdzd_amt_per_service) (stored as log_stdzd_amt_per_service)\",\n",
    "        \"Heavy-tailed raw outcome. Log reduces tail dominance and improves stability.\"\n",
    "    ]\n",
    "})\n",
    "target_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411",
   "metadata": {},
   "source": [
    "What it says\n",
    "- Outcome for reporting: stdzd_amt_per_service (raw dollars per service)\n",
    "- Modeling target: log1p(stdzd_amt_per_service) which you already store as log_stdzd_amt_per_service\n",
    "- Justification: raw costs are heavy-tailed, log makes learning stable\n",
    "\n",
    "How to interpret\n",
    "- You are explicitly separating:\n",
    "- what stakeholders want to see and understand (raw dollars), from\n",
    "- what the model needs to learn well (log dollars).\n",
    "- This is a strong and defensible stance because your EDA already proved:\n",
    "- max is huge (tens of thousands),\n",
    "- p99 is hundreds,\n",
    "- median is ~70.\n",
    "\n",
    "Modeling implication\n",
    "- Train the model on log_stdzd_amt_per_service.\n",
    "- When you report results, convert back to dollars carefully:\n",
    "- predicted log-cost -> expm1(pred) gives predicted $/service.\n",
    "- residuals can be measured on log scale (stable) and optionally translated back to $ for interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412",
   "metadata": {},
   "source": [
    "10.2 Final training inclusion rules (EDA-aligned)\n",
    "\n",
    "**Training inclusion filter:**\n",
    "- `services >= 11`\n",
    "- `stdzd_amt_per_service` is not null\n",
    "- `stdzd_amt_per_service >= 0`\n",
    "\n",
    "These rules prioritize reliability (avoid tiny denominators) and avoid invalid cost values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training inclusion mask explicitly (even if eda_df is already filtered)\n",
    "train_mask = (\n",
    "    (eda_df[\"services\"] >= 11) &\n",
    "    (eda_df[\"stdzd_amt_per_service\"].notna()) &\n",
    "    (eda_df[\"stdzd_amt_per_service\"] >= 0)\n",
    ")\n",
    "\n",
    "train_filter_summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Rows in eda_df\",\n",
    "        \"Rows meeting training filter\",\n",
    "        \"Share kept\",\n",
    "        \"Unique NPIs (all)\",\n",
    "        \"Unique NPIs (kept)\",\n",
    "        \"Years present (all)\",\n",
    "        \"Years present (kept)\",\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        len(eda_df),\n",
    "        int(train_mask.sum()),\n",
    "        float(train_mask.mean()),\n",
    "        eda_df[\"Rndrng_NPI\"].nunique(),\n",
    "        eda_df.loc[train_mask, \"Rndrng_NPI\"].nunique(),\n",
    "        sorted(eda_df[\"Year\"].unique().tolist()),\n",
    "        sorted(eda_df.loc[train_mask, \"Year\"].unique().tolist()),\n",
    "    ]\n",
    "})\n",
    "\n",
    "train_filter_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414",
   "metadata": {},
   "source": [
    "The output\n",
    "- Rows in eda_df: 318,322\n",
    "- Rows meeting training filter: 318,322\n",
    "- Share kept: 1.0\n",
    "- Unique NPIs: 20,919\n",
    "- Years: [2021, 2022, 2023]\n",
    "\n",
    "How to interpret\n",
    "- This confirms a key fact: your eda_df is already “training-ready” with respect to your inclusion rules.\n",
    "- Your SQL filter WHERE ps.services >= 11 AND ... already enforced the train mask, so the explicit train_mask does not drop anything.\n",
    "\n",
    "Modeling implication\n",
    "- No additional inclusion filtering is needed in the modeling notebook.\n",
    "- That is good because it prevents “silent changes” between EDA and modeling.\n",
    "\n",
    "Narrative implication\n",
    "- You can state in Notebook 10:\n",
    "“The modeling dataset equals the EDA dataset. No additional exclusions are introduced at modeling time.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415",
   "metadata": {},
   "source": [
    "10.3 Tail policy (keep tail, do not winsorize for training)\n",
    "\n",
    "**Key EDA finding:** the top 1% of `stdzd_amt_per_service` is not a handful of errors. It contains many rows and meaningful service volumes.\n",
    "\n",
    "**Policy:**\n",
    "- Do **not** winsorize labels for training.\n",
    "- Use `log_stdzd_amt_per_service` as the modeling target to handle skew.\n",
    "- Keep `is_top_1pct_stdzd_amt_per_service` as a diagnostic flag for slicing and interpretation.\n",
    "\n",
    "**Visualization note:**\n",
    "- Clipping at p99 is allowed **only for readability in plots**, not for training labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416",
   "metadata": {},
   "source": [
    "**10.3A: Tail footprint (rows, spend, services)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_footprint = (\n",
    "    eda_df\n",
    "    .assign(is_tail=eda_df[\"is_top_1pct_stdzd_amt_per_service\"].astype(bool))\n",
    "    .groupby(\"is_tail\")\n",
    "    .agg(\n",
    "        n_rows=(\"services\", \"size\"),\n",
    "        total_services=(\"services\", \"sum\"),\n",
    "        total_spend=(\"stdzd_spend\", \"sum\"),\n",
    "        med_services=(\"services\", \"median\"),\n",
    "        med_cost=(\"stdzd_amt_per_service\", \"median\"),\n",
    "    )\n",
    "    .assign(\n",
    "        pct_rows=lambda d: d[\"n_rows\"] / d[\"n_rows\"].sum(),\n",
    "        pct_services=lambda d: d[\"total_services\"] / d[\"total_services\"].sum(),\n",
    "        pct_spend=lambda d: d[\"total_spend\"] / d[\"total_spend\"].sum(),\n",
    "    )\n",
    ")\n",
    "\n",
    "tail_footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418",
   "metadata": {},
   "source": [
    "Your output (key numbers)\n",
    "- Tail flag is top 1% of stdzd_amt_per_service by construction.\n",
    "- Non-tail:\n",
    "    - n_rows = 315,138 (99.0%)\n",
    "    - total_services ≈ 925,832,559.3\n",
    "    - total_spend ≈ 1.488e10\n",
    "    - median services = 142\n",
    "    - median cost = ~70.3\n",
    "    - share of spend = 98.27%\n",
    "- Tail:\n",
    "    - n_rows = 3,184 (1.0%)\n",
    "    - total_services = 298,384\n",
    "    - total_spend = 2.621e8\n",
    "    - median services = 41\n",
    "    - median cost = ~736.7\n",
    "    - share of spend = 1.73%\n",
    "    - share of services = 0.032%\n",
    "\n",
    "How to interpret\n",
    "This table answers three “so what?” questions:\n",
    "\n",
    "A) Is the tail large in rows?\n",
    "- It’s exactly 1% (3,184 rows). So it is not a tiny handful, but it is still a small slice.\n",
    "\n",
    "B) Is the tail large in volume?\n",
    "- No. Tail is only 0.032% of services.\n",
    "- That is important: these are high cost per service, not high frequency.\n",
    "\n",
    "C) Is the tail a major share of dollars?\n",
    "- Surprisingly, also not huge: 1.73% of total spend.\n",
    "- That means your dataset’s total spend is driven by the non-tail bulk, even though tail costs look extreme per service.\n",
    "\n",
    "Modeling implication\n",
    "- This strongly supports: no winsorization of labels needed.\n",
    "- The tail is unlikely to dominate training loss when using log target, because:\n",
    "    - it’s only 1% of rows,\n",
    "    - it’s tiny in service volume,\n",
    "    - log compresses extremes further.\n",
    "\n",
    "Evaluation implication\n",
    "- You should still slice metrics by tail vs non-tail, because the model might behave differently there.\n",
    "- But tail is not your “main money story.” It is mainly a “rare high unit cost” story.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419",
   "metadata": {},
   "source": [
    "**10.3B: Tail explanation table (top 10 families by tail spend)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_tbl = (\n",
    "    tail_enrichment_by(\"rbcs_family_desc\")\n",
    "    .sort_values(\"spend_tail\", ascending=False)\n",
    "    .loc[:, [\"rbcs_family_desc\", \"tail_share\", \"pct_spend_in_tail\", \"enrichment\", \"spend_tail\"]]\n",
    "    .head(10)\n",
    "    .assign(spend_tail_m=lambda d: d[\"spend_tail\"] / 1e6)\n",
    "    .assign(\n",
    "        tail_share=lambda d: d[\"tail_share\"].round(3),\n",
    "        pct_spend_in_tail=lambda d: d[\"pct_spend_in_tail\"].round(3),\n",
    "        enrichment=lambda d: d[\"enrichment\"].round(2),\n",
    "        spend_tail_m=lambda d: d[\"spend_tail_m\"].round(1),\n",
    "    )\n",
    "    .drop(columns=[\"spend_tail\"])\n",
    ")\n",
    "\n",
    "tail_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421",
   "metadata": {},
   "source": [
    "This is our “one slide” tail explanation.\n",
    "\n",
    "Let’s interpret each column precisely:\n",
    "\n",
    "-  `tail_share`:\n",
    "\n",
    "“Of all dollars inside the tail, how much is contributed by this family?”\n",
    "\n",
    "Example:\n",
    "- PET-Oncology `tail_share` = 0.581\n",
    "Means 58.1% of all tail spend is PET-Oncology.\n",
    "\n",
    "This is a within-tail composition measure.\n",
    "\n",
    "-  `pct_spend_in_tail`:\n",
    "\n",
    "“Of this family’s total spend overall, what fraction lies in the tail?”\n",
    "\n",
    "Example:\n",
    "- Vascular Embolization `pct_spend_in_tail` = 0.991\n",
    "Means 99.1% of all Vascular Embolization spend occurs in tail rows.\n",
    "\n",
    "This is a within-family concentration measure.\n",
    "\n",
    "- `enrichment`:\n",
    "\n",
    "“How overrepresented is this category inside the tail compared to its overall prevalence?”\n",
    "\n",
    "Formally:\n",
    "- `enrichment` = tail_share / overall_share\n",
    "\n",
    "Example:\n",
    "- PET-Oncology `enrichment` = 26\n",
    "Means PET-Oncology is 26x more concentrated inside the tail than expected if tail mirrored overall spend mix.\n",
    "\n",
    "- `spend_tail_m`:\n",
    "\n",
    "Raw dollars in the tail for that family in millions.\n",
    "\n",
    "Example:\n",
    "- PET-Oncology `spend_tail_m` = 152.3\n",
    "Means PET-Oncology accounts for about $152.3M of tail spend.\n",
    "\n",
    "What the `tail_tbl` tells you\n",
    "- Tail spend is overwhelmingly driven by a few families, especially:\n",
    "- PET-Oncology\n",
    "- Colony Stimulating Factors\n",
    "- No RBCS Family (misc bucket)\n",
    "- Some families have extreme pct_spend_in_tail (like Vascular Embolization) but small dollars overall.\n",
    "\n",
    "Modeling implication\n",
    "- The tail is not “random noise.” It is structured by service type.\n",
    "- That is good news. It means categorical features like `rbcs_family_desc` and `Place_Of_Srvc` can help the model learn expected ranges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422",
   "metadata": {},
   "source": [
    "10.4 Post-model flagging policy (separate from training)\n",
    "\n",
    "Training includes rows with `services >= 11`.\n",
    "\n",
    "For any downstream “flagging” use case (over-expected cost), we should apply stricter volume thresholds to ensure stability:\n",
    "- **Candidate flagging threshold:** `services >= 50` (primary)\n",
    "- **High-confidence slice:** `services >= 100` (sensitivity)\n",
    "\n",
    "We will report model performance and flagging behavior across service-volume buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423",
   "metadata": {},
   "source": [
    "**10.4A: Table A1 (tail flag x svc_bucket)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_a1 = (\n",
    "    eda_df\n",
    "    .groupby([\"is_top_1pct_stdzd_amt_per_service\", \"svc_bucket\"], dropna=False, observed=True)\n",
    "    .agg(\n",
    "        n_rows=(\"services\", \"size\"),\n",
    "        total_services=(\"services\", \"sum\"),\n",
    "        total_spend=(\"stdzd_spend\", \"sum\"),\n",
    "        med_cost=(\"stdzd_amt_per_service\", \"median\"),\n",
    "        p95_cost=(\"stdzd_amt_per_service\", lambda s: s.quantile(0.95)),\n",
    "    )\n",
    "    .assign(\n",
    "        spend_per_service=lambda d: d[\"total_spend\"] / d[\"total_services\"],\n",
    "        spend_per_row=lambda d: d[\"total_spend\"] / d[\"n_rows\"],\n",
    "    )\n",
    "    .assign(\n",
    "        pct_services=lambda d: d[\"total_services\"] / d[\"total_services\"].sum(),\n",
    "        pct_spend=lambda d: d[\"total_spend\"] / d[\"total_spend\"].sum(),\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "table_a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425",
   "metadata": {},
   "source": [
    "This table explains how volume interacts with tail membership.\n",
    "\n",
    "Key patterns to notice\n",
    "\n",
    "A) Most services are in non-tail 500+\n",
    "- Non-tail 500+:\n",
    "    - total_services ≈ 900,902,470\n",
    "    - pct_services ≈ 0.973 (97.3% of all services)\n",
    "    - pct_spend ≈ 0.846 (84.6% of all spend)\n",
    "    - spend_per_service ≈ 14.23\n",
    "\n",
    "Interpretation:\n",
    "- The dataset is dominated by very high volume slices with low $/service.\n",
    "\n",
    "B) Tail rows have much higher spend per service in every bucket\n",
    "\n",
    "- Compare spend per service:\n",
    "    - Non-tail 11-25: ~124\n",
    "    - Tail 11-25: ~1103\n",
    "    - Non-tail 100-500: ~73\n",
    "    - Tail 100-500: ~775\n",
    "    - Non-tail 500+: ~14\n",
    "    - Tail 500+: ~732\n",
    "\n",
    "Interpretation:\n",
    "- Tail is fundamentally a high unit cost regime regardless of volume bucket.\n",
    "\n",
    "C) Tail spend is concentrated in mid-volume buckets, not the ultra-high bucket\n",
    "- Look at tail rows:\n",
    "    - Tail 500+: only 83 rows\n",
    "    - Tail 100-500: 681 rows\n",
    "    - Tail 11-25: 1016 rows\n",
    "\n",
    "Interpretation:\n",
    "- The tail is mostly happening in low to mid volume slices, not the massive 500+ slices.\n",
    "\n",
    "Modeling implication\n",
    "- This supports your split policy:\n",
    "    - train on services >= 11 to have enough data\n",
    "    - flagging at services >= 50 or >= 100 for stability\n",
    "- It also suggests:\n",
    "    - if you later do any “confidence scoring,” services volume should be part of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426",
   "metadata": {},
   "source": [
    "**10.4B: Flagging thresholds slice sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_slices = pd.DataFrame({\n",
    "    \"Slice\": [\"services >= 11 (train)\", \"services >= 50 (flagging)\", \"services >= 100 (high confidence)\"],\n",
    "    \"Rows\": [\n",
    "        int((eda_df[\"services\"] >= 11).sum()),\n",
    "        int((eda_df[\"services\"] >= 50).sum()),\n",
    "        int((eda_df[\"services\"] >= 100).sum()),\n",
    "    ],\n",
    "    \"Share of rows\": [\n",
    "        float((eda_df[\"services\"] >= 11).mean()),\n",
    "        float((eda_df[\"services\"] >= 50).mean()),\n",
    "        float((eda_df[\"services\"] >= 100).mean()),\n",
    "    ],\n",
    "    \"Share of spend\": [\n",
    "        float(eda_df.loc[eda_df[\"services\"] >= 11, \"stdzd_spend\"].sum() / eda_df[\"stdzd_spend\"].sum()),\n",
    "        float(eda_df.loc[eda_df[\"services\"] >= 50, \"stdzd_spend\"].sum() / eda_df[\"stdzd_spend\"].sum()),\n",
    "        float(eda_df.loc[eda_df[\"services\"] >= 100, \"stdzd_spend\"].sum() / eda_df[\"stdzd_spend\"].sum()),\n",
    "    ],\n",
    "})\n",
    "flag_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428",
   "metadata": {},
   "source": [
    "Your output\n",
    "- services >= 50 includes:\n",
    "    - 70.0% of rows\n",
    "    - 97.6% of spend\n",
    "- services >= 100 includes:\n",
    "    - 55.7% of rows\n",
    "    - 95.0% of spend\n",
    "\n",
    "How to interpret\n",
    "- Moving from 11 to 50 removes 30% of rows but almost no spend.\n",
    "- That is a strong argument that “flagging” should happen at >= 50:\n",
    "    - fewer noisy small slices,\n",
    "    - you still cover almost all dollars.\n",
    "\n",
    "Modeling implication\n",
    "- Keep training on 11.\n",
    "- Use >= 50 for “provider-facing” flags.\n",
    "- Use >= 100 for “high confidence” flags.\n",
    "\n",
    "This is a clean and defensible tiering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429",
   "metadata": {},
   "source": [
    "10.5 Final feature list (categorical vs numeric)\n",
    "\n",
    "We define the final candidate feature list based on EDA:\n",
    "- categorical context (service family, POS, provider type, geography, rurality)\n",
    "- numeric case-mix and intensity (risk score, log volume, comorbidity proportions, experience)\n",
    "\n",
    "We also document excluded columns (leakage, targets, or derived totals not appropriate for the intended modeling objective)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430",
   "metadata": {},
   "source": [
    "**10.5A: Define final feature lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features (to encode)\n",
    "cat_features = [\n",
    "    \"rbcs_family_desc\",    # or use \"RBCS_FamNumb\" instead, but pick one consistently\n",
    "    \"Place_Of_Srvc\",\n",
    "    \"provider_type\",\n",
    "    \"state\",\n",
    "    \"ruca_bucket\",\n",
    "]\n",
    "\n",
    "# Numeric features\n",
    "num_features = [\n",
    "    \"bene_avg_risk_score\",\n",
    "    \"years_since_enumeration\",\n",
    "    \"log_services\",\n",
    "    \"log_benes\",\n",
    "    \"p_cancer6\", \"p_diabetes\", \"p_ckd\", \"p_copd\", \"p_htn\",\n",
    "]\n",
    "\n",
    "# Final target\n",
    "target_col = \"log_stdzd_amt_per_service\"\n",
    "\n",
    "# Exclusions (documented)\n",
    "excluded = [\n",
    "    # raw cost outcomes besides target\n",
    "    \"stdzd_amt_per_service\", \"allowed_amt_per_service\", \"payment_amt_per_service\", \"submitted_charge_per_service\",\n",
    "    # totals derived from outcomes (spend columns)\n",
    "    \"stdzd_spend\", \"allowed_spend\", \"payment_spend\", \"submitted_spend\",\n",
    "    # flags/buckets used for slicing, not for training features\n",
    "    \"is_top_1pct_stdzd_amt_per_service\", \"svc_bucket\", \"services_bins\", \"services_custom\", \"services_custom2\",\n",
    "    # provider-year totals (often avoided to prevent scale leakage; can revisit intentionally later)\n",
    "    \"tot_mdcr_stdzd_amt\",\n",
    "]\n",
    "\n",
    "features_table = pd.DataFrame({\n",
    "    \"Type\": ([\"categorical\"] * len(cat_features)) + ([\"numeric\"] * len(num_features)) + ([\"target\"] * 1),\n",
    "    \"Column\": cat_features + num_features + [target_col]\n",
    "})\n",
    "\n",
    "features_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432",
   "metadata": {},
   "source": [
    "This is your intended modeling feature set.\n",
    "\n",
    "Categorical features\n",
    "- `rbcs_family_desc`\n",
    "- `Place_Of_Srvc`\n",
    "- `provider_type`\n",
    "- `state`\n",
    "- `ruca_bucket`\n",
    "\n",
    "Interpretation:\n",
    "- These explain systematic price differences due to:\n",
    "    - what service is being delivered,\n",
    "    - where it is delivered,\n",
    "    - what specialty is delivering it,\n",
    "    - geography and rurality.\n",
    "\n",
    "Numeric features\n",
    "- risk and experience:\n",
    "    - `bene_avg_risk_score`\n",
    "    - `years_since_enumeration`\n",
    "- exposure/intensity controls (log):\n",
    "    - `log_services`\n",
    "    - `log_benes`\n",
    "- case mix proportions:\n",
    "    - `p_cancer6`, `p_diabetes`, `p_ckd`, `p_copd`, `p_htn`\n",
    "\n",
    "Interpretation:\n",
    "- This is a classic “risk adjustment + context” set.\n",
    "- You are not leaking the target because you excluded spend totals and other cost measures.\n",
    "\n",
    "Modeling implication\n",
    "- You should decide one thing now:\n",
    "    - `rbcs_family_desc` vs `RBCS_FamNumb`\n",
    "    - Pick one and use consistently (ID is often cleaner, desc is often fine too)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433",
   "metadata": {},
   "source": [
    "**10.5B: Quick availability check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = [c for c in (cat_features + num_features + [target_col]) if c not in eda_df.columns]\n",
    "missing_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435",
   "metadata": {},
   "source": [
    "missing_cols\n",
    "\n",
    "Output: []\n",
    "\n",
    "Interpretation\n",
    "- Everything you plan to model exists in your dataframe.\n",
    "- This prevents “modeling notebook surprises.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436",
   "metadata": {},
   "source": [
    "10.6 Split plan and leakage checks\n",
    "\n",
    "**Planned temporal split:**\n",
    "- Train: 2021–2022\n",
    "- Test: 2023\n",
    "\n",
    "We will also quantify provider overlap between train and test:\n",
    "- How many NPIs appear in both periods (seen providers)?\n",
    "- How many NPIs are test-only (cold-start providers)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437",
   "metadata": {},
   "source": [
    "**10.6A: Create split masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = [2021, 2022]\n",
    "test_years = [2023]\n",
    "\n",
    "mask_train = eda_df[\"Year\"].isin(train_years)\n",
    "mask_test = eda_df[\"Year\"].isin(test_years)\n",
    "\n",
    "split_counts = pd.DataFrame({\n",
    "    \"Split\": [\"train\", \"test\"],\n",
    "    \"Years\": [train_years, test_years],\n",
    "    \"Rows\": [int(mask_train.sum()), int(mask_test.sum())],\n",
    "    \"Unique NPIs\": [eda_df.loc[mask_train, \"Rndrng_NPI\"].nunique(), eda_df.loc[mask_test, \"Rndrng_NPI\"].nunique()],\n",
    "    \"Spend share\": [\n",
    "        float(eda_df.loc[mask_train, \"stdzd_spend\"].sum() / eda_df[\"stdzd_spend\"].sum()),\n",
    "        float(eda_df.loc[mask_test, \"stdzd_spend\"].sum() / eda_df[\"stdzd_spend\"].sum()),\n",
    "    ],\n",
    "})\n",
    "split_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439",
   "metadata": {},
   "source": [
    "Your output\n",
    "- Train:\n",
    "    - 213,296 rows\n",
    "    - 19,838 NPIs\n",
    "    - 66.6% spend\n",
    "- Test:\n",
    "    - 105,026 rows\n",
    "    - 19,226 NPIs\n",
    "    - 33.4% spend\n",
    "\n",
    "Interpretation\n",
    "- You have a healthy split. About one-third of dollars are in the test year.\n",
    "- The train and test have similar provider counts, which is good for generalization tests.\n",
    "\n",
    "Modeling implication\n",
    "- This is a realistic production-like test: learn patterns from earlier years, apply to the next year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440",
   "metadata": {},
   "source": [
    "**10.6B: Provider overlap (leakage / generalization check)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_train = set(eda_df.loc[mask_train, \"Rndrng_NPI\"].unique().tolist())\n",
    "npi_test = set(eda_df.loc[mask_test, \"Rndrng_NPI\"].unique().tolist())\n",
    "\n",
    "overlap = npi_train.intersection(npi_test)\n",
    "test_only = npi_test - npi_train\n",
    "\n",
    "provider_overlap_tbl = pd.DataFrame({\n",
    "    \"Metric\": [\"Train NPIs\", \"Test NPIs\", \"Overlap NPIs\", \"Test-only NPIs\"],\n",
    "    \"Value\": [len(npi_train), len(npi_test), len(overlap), len(test_only)],\n",
    "    \"Share of test NPIs\": [\n",
    "        np.nan,\n",
    "        1.0,\n",
    "        len(overlap)/len(npi_test) if len(npi_test) else np.nan,\n",
    "        len(test_only)/len(npi_test) if len(npi_test) else np.nan,\n",
    "    ]\n",
    "})\n",
    "provider_overlap_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442",
   "metadata": {},
   "source": [
    "Your output\n",
    "- Test NPIs: 19,226\n",
    "- Overlap with train: 18,145 (94.38%)\n",
    "- Test-only: 1,081 (5.62%)\n",
    "\n",
    "Interpretation\n",
    "- Most test providers were seen in train. That means your evaluation is mostly:\n",
    "    - “new year for known providers” (easier)\n",
    "- But you still have a meaningful cold-start set:\n",
    "    - 1,081 providers\n",
    "\n",
    "Modeling implication\n",
    "- You should report performance separately for:\n",
    "    - seen providers (in train)\n",
    "    - unseen providers (test-only)\n",
    "\n",
    "Because those are different deployment realities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443",
   "metadata": {},
   "source": [
    "**10.7 Planned evaluation metrics and slices**\n",
    "\n",
    "**Primary metrics (on log target):**\n",
    "- MAE on `log_stdzd_amt_per_service`\n",
    "- RMSE on `log_stdzd_amt_per_service`\n",
    "\n",
    "**Reporting slices (diagnostics + fairness + stability):**\n",
    "- by `provider_type`\n",
    "- by `Place_Of_Srvc`\n",
    "- by `ruca_bucket`\n",
    "- by service-volume bucket (`svc_bucket`)\n",
    "- by tail flag (`is_top_1pct_stdzd_amt_per_service`, diagnostic only)\n",
    "\n",
    "We will compute these slices on the **test year** (2023) and optionally compare against train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444",
   "metadata": {},
   "source": [
    "**10.7A: Planned slice keys table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plan = pd.DataFrame({\n",
    "    \"Category\": [\n",
    "        \"Primary metrics\",\n",
    "        \"Target scale\",\n",
    "        \"Core slices (report)\",\n",
    "        \"Stability slices (flagging)\",\n",
    "        \"Tail diagnostic\"\n",
    "    ],\n",
    "    \"Plan\": [\n",
    "        \"MAE, RMSE\",\n",
    "        \"log_stdzd_amt_per_service (log1p)\",\n",
    "        \"provider_type, Place_Of_Srvc, ruca_bucket, state\",\n",
    "        \"svc_bucket and services>=50 / >=100 subsets\",\n",
    "        \"Compare tail vs non-tail behavior without changing labels\"\n",
    "    ]\n",
    "})\n",
    "eval_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446",
   "metadata": {},
   "source": [
    "This is the written plan. The main implication is the slicing discipline.\n",
    "\n",
    "Modeling implication\n",
    "- Even a good average MAE can hide:\n",
    "    - a big error for one specialty,\n",
    "    - or systematic underprediction in facility setting.\n",
    "- Slices are not “nice to have.” They are how you prove risk adjustment is working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447",
   "metadata": {},
   "source": [
    "**10.8 Modeling readiness summary table (final contract)**\n",
    "\n",
    "This final table summarizes the modeling choices implied by EDA and tail analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiness_contract = pd.DataFrame({\n",
    "    \"Decision Area\": [\n",
    "        \"Dataset grain\",\n",
    "        \"Final modeling target\",\n",
    "        \"Training inclusion\",\n",
    "        \"Tail handling\",\n",
    "        \"Visualization-only clipping\",\n",
    "        \"Post-model flagging threshold\",\n",
    "        \"Features (categorical)\",\n",
    "        \"Features (numeric)\",\n",
    "        \"Split plan\",\n",
    "        \"Evaluation slices\"\n",
    "    ],\n",
    "    \"Final Choice\": [\n",
    "        \"provider-year-RBCS family-place of service\",\n",
    "        \"log_stdzd_amt_per_service = log1p(stdzd_amt_per_service)\",\n",
    "        \"services >= 11; stdzd_amt_per_service not null and >= 0\",\n",
    "        \"Keep tail; do not winsorize labels; use tail flag for diagnostics\",\n",
    "        \"Allow p99 clipping for readability in plots only\",\n",
    "        \"Flagging candidates evaluated on services >= 50 (and >= 100 sensitivity)\",\n",
    "        \", \".join(cat_features),\n",
    "        \", \".join(num_features),\n",
    "        \"Train 2021–2022, Test 2023\",\n",
    "        \"provider_type, Place_Of_Srvc, ruca_bucket, svc_bucket, tail flag (diagnostic)\"\n",
    "    ],\n",
    "    \"Why defensible\": [\n",
    "        \"Matches EDA grain and planned use case\",\n",
    "        \"Controls heavy tail while preserving signal\",\n",
    "        \"Reliability threshold reduces denominator noise\",\n",
    "        \"Tail appears real and interpretable (not pure error). Log target handles skew\",\n",
    "        \"Prevents misleading plots without altering training distribution\",\n",
    "        \"Reduces false positives from low-volume instability\",\n",
    "        \"Captures key context (service, POS, specialty, geography, rurality)\",\n",
    "        \"Captures case-mix + intensity + experience + comorbidity composition\",\n",
    "        \"Temporal generalization is the real-world test\",\n",
    "        \"Ensures interpretability and stability across key segments\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "readiness_contract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449",
   "metadata": {},
   "source": [
    "This is your “final decision table.” It ties together all EDA conclusions into a fixed plan.\n",
    "\n",
    "Interpretation\n",
    "- This is the single best artifact to prevent scope drift.\n",
    "- It will make your writeup defensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450",
   "metadata": {},
   "source": [
    "**The data frame for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = cat_features + num_features + [target_col, \"Year\", \"Rndrng_NPI\", \"services\", \"stdzd_amt_per_service\"]\n",
    "\n",
    "model_df = eda_df.loc[train_mask, model_cols].copy()\n",
    "\n",
    "train_df = model_df[model_df[\"Year\"].isin(train_years)].copy()\n",
    "test_df = model_df[model_df[\"Year\"].isin(test_years)].copy()\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452",
   "metadata": {},
   "source": [
    "Output\n",
    "- Train: (213,296, 19)\n",
    "- Test: (105,026, 19)\n",
    "\n",
    "Interpretation\n",
    "- 19 columns includes:\n",
    "    - features + target + Year + NPI + services + raw cost\n",
    "- This is a manageable size.\n",
    "\n",
    "Modeling implication\n",
    "- You are ready to encode categoricals and fit a baseline model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453",
   "metadata": {},
   "source": [
    "**Missingness of features used in modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_missing = (\n",
    "    model_df[cat_features + num_features + [target_col]]\n",
    "    .isna()\n",
    "    .mean()\n",
    "    .mul(100)\n",
    "    .sort_values(ascending=False)\n",
    "    .rename(\"pct_missing\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\"})\n",
    ")\n",
    "feature_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455",
   "metadata": {},
   "source": [
    "This is the one you should pay attention to before training.\n",
    "\n",
    "You have missingness in:\n",
    "- `p_copd`: 4.59%\n",
    "- `p_ckd`: 2.05%\n",
    "- `p_diabetes`: 1.15%\n",
    "- `p_cancer6`: 0.86%\n",
    "- `years_since_enumeration`: 0.45%\n",
    "- `p_htn`: 0.05%\n",
    "Everything else: 0%\n",
    "\n",
    "Interpret each variable’s missingness and what it implies\n",
    "\n",
    "- `p_copd` (4.59% missing)\n",
    "    - This is the highest missingness among your features.\n",
    "    - Likely causes:\n",
    "        - certain provider-year records lack the COPD percentage due to suppression, reporting rules, or merge gaps.\n",
    "    - Modeling risk:\n",
    "        - dropping rows would throw away ~4.6% of your data for one feature.\n",
    "    - Recommended handling:\n",
    "        - impute missing with a neutral value (commonly 0) plus a missingness indicator, or\n",
    "        - impute with median and add indicator.\n",
    "    - Why indicator matters:\n",
    "    - missingness might correlate with provider type or geography, so the “missing” itself can carry signal.\n",
    "\n",
    "- p_ckd (2.05% missing)\n",
    "    - Similar logic, lower magnitude.\n",
    "    - You should handle it the same way as p_copd for consistency.\n",
    "\n",
    "- `p_diabetes` (1.15% missing)\n",
    "    - Small but non-trivial.\n",
    "    - Same treatment.\n",
    "\n",
    "- `p_cancer6` (0.86% missing)\n",
    "    - Small. Same treatment.\n",
    "    - This one is especially sensitive conceptually in oncology, so do not silently drop rows.\n",
    "\n",
    "- `years_since_enumeration` (0.45% missing)\n",
    "    - This is “provider experience proxy.”\n",
    "    - Missingness likely means:\n",
    "        - NPI enumeration date missing upstream, or mapping failed.\n",
    "    - Modeling risk:\n",
    "        - leaving it missing can break some models.\n",
    "    - Handling:\n",
    "        - impute median and add missingness flag is the safest.\n",
    "\n",
    "- `p_htn` (0.05% missing)\n",
    "    - Very small. Still handle systematically (same imputation pattern).\n",
    "    - Consistency matters. You do not want special-case logic for one feature.\n",
    "\n",
    "- All categoricals have 0% missing\n",
    "    - That is excellent. It means your slicing features are complete.\n",
    "    - Especially important for:\n",
    "        - `provider_type`, `Place_Of_Srvc`, `ruca_bucket`.\n",
    "\n",
    "- `bene_avg_risk_score` has 0% missing\n",
    "    - This is great because it is typically your primary adjustment feature.\n",
    "\n",
    "Modeling implication\n",
    "- You need a missingness strategy as part of Notebook 10 or the first modeling notebook.\n",
    "- The best practice approach here is:\n",
    "\n",
    "1.\tFor each numeric feature with missing:\n",
    "\n",
    "•\tcreate `is_missing_<feature>` indicator\n",
    "\n",
    "2.\tImpute missing values:\n",
    "\n",
    "•\teither 0 (for percentage fields) or median\n",
    "\n",
    "3.\tKeep the indicator in the model\n",
    "\n",
    "This preserves rows, avoids bias from dropping, and allows missingness patterns to be learned.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicare-provider-benchmarking-engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
